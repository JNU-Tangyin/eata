"""
å®éªŒæ‰§è¡Œå™¨

è´Ÿè´£æ‰§è¡Œå¯¹æ¯”å®éªŒï¼Œæ”¶é›†ç»“æœï¼Œç”ŸæˆæŠ¥å‘Šã€‚
"""

import time
import json
import pandas as pd
from typing import Dict, List, Any, Optional
from datetime import datetime
import os

import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.config_manager import ConfigManager
from core.base_algorithm import BaseAlgorithm


class ExperimentRunner:
    """å®éªŒæ‰§è¡Œå™¨"""
    
    def __init__(self, config_manager: ConfigManager, output_dir: str = "comparison_results"):
        """
        åˆå§‹åŒ–å®éªŒæ‰§è¡Œå™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
            output_dir: ç»“æœè¾“å‡ºç›®å½•
        """
        self.config_manager = config_manager
        self.output_dir = output_dir
        self.results = []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # æ•°æ®åŠ è½½å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self.data_cache = {}
    
    def load_data(self, stock: str) -> pd.DataFrame:
        """
        åŠ è½½è‚¡ç¥¨æ•°æ®
        
        Args:
            stock: è‚¡ç¥¨ä»£ç 
            
        Returns:
            è‚¡ç¥¨æ•°æ®DataFrame
        """
        if stock in self.data_cache:
            return self.data_cache[stock]
        
        try:
            # å°è¯•ä½¿ç”¨ç°æœ‰çš„æ•°æ®åŠ è½½é€»è¾‘
            sys.path.append('..')
            from data import DataStorage
            
            # ä½¿ç”¨DataStorageç›´æ¥æŸ¥è¯¢æ•°æ®åº“
            storage = DataStorage()
            
            # ç›´æ¥ä»raw_dataè¡¨æŸ¥è¯¢è‚¡ç¥¨æ•°æ®
            query = f"SELECT * FROM raw_data WHERE code = '{stock}' ORDER BY date"
            df = pd.read_sql_query(query, storage.conn)
            
            if len(df) == 0:
                raise ValueError(f"æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°è‚¡ç¥¨ {stock} çš„æ•°æ®")
            
            # ç¡®ä¿æœ‰å¿…è¦çš„åˆ—
            required_cols = ['close', 'open', 'high', 'low', 'volume']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                print(f"è­¦å‘Š: ç¼ºå°‘åˆ— {missing_cols}ï¼Œå°†ä½¿ç”¨closeä»·æ ¼å¡«å……")
                for col in missing_cols:
                    if col != 'volume':
                        df[col] = df['close']
                    else:
                        df[col] = 1000000  # é»˜è®¤æˆäº¤é‡
            
            # è®¾ç½®æ—¥æœŸç´¢å¼•
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)
            
            print(f"æˆåŠŸåŠ è½½ {stock} æ•°æ®: {len(df)} æ¡è®°å½•")
            self.data_cache[stock] = df
            return df
            
        except Exception as e:
            print(f"åŠ è½½æ•°æ®å¤±è´¥ {stock}: {e}")
            # è¿”å›æ¨¡æ‹Ÿæ•°æ®
            import numpy as np
            dates = pd.date_range('2020-01-01', periods=1000, freq='D')
            
            # ç”Ÿæˆæ›´çœŸå®çš„è‚¡ä»·æ•°æ®
            np.random.seed(42)  # å›ºå®šéšæœºç§å­
            returns = np.random.normal(0.001, 0.02, 1000)  # æ—¥æ”¶ç›Šç‡
            prices = [100]  # åˆå§‹ä»·æ ¼
            for ret in returns:
                prices.append(prices[-1] * (1 + ret))
            
            df = pd.DataFrame({
                'close': prices[1:],  # å»æ‰åˆå§‹ä»·æ ¼
                'open': [p * 0.999 for p in prices[1:]],  # å¼€ç›˜ä»·ç•¥ä½
                'high': [p * 1.01 for p in prices[1:]],   # æœ€é«˜ä»·ç•¥é«˜
                'low': [p * 0.99 for p in prices[1:]],    # æœ€ä½ä»·ç•¥ä½
                'volume': np.random.randint(500000, 2000000, 1000)
            }, index=dates)
            
            self.data_cache[stock] = df
            return df
    
    def run_single_experiment(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¿è¡Œå•ä¸ªå®éªŒ
        
        Args:
            config: å®éªŒé…ç½®
            
        Returns:
            å®éªŒç»“æœ
        """
        start_time = time.time()
        
        try:
            # åˆ›å»ºç®—æ³•å®ä¾‹
            algorithm_class = config['algorithm_class']
            algorithm = algorithm_class(config)
            
            # åŠ è½½æ•°æ®
            data = self.load_data(config['dataset'])
            
            # æ‰§è¡Œå®éªŒ
            result = algorithm.evaluate(data)
            
            # æ·»åŠ å®éªŒä¿¡æ¯ï¼ˆç§»é™¤ä¸å¯åºåˆ—åŒ–çš„å†…å®¹ï¼‰
            clean_config = {k: v for k, v in config.items() if k != 'algorithm_class'}
            result.update({
                'experiment_id': f"{config['algorithm']}_{config['dataset']}_{int(time.time())}",
                'timestamp': datetime.now().isoformat(),
                'experiment_time': time.time() - start_time,
                'data_size': len(data)
            })
            # ç¡®ä¿configå¯åºåˆ—åŒ–
            if 'config' in result:
                result['config'] = clean_config
            
            return result
            
        except Exception as e:
            import traceback
            error_details = f"{str(e)}\n{traceback.format_exc()}"
            print(f"å®éªŒå¤±è´¥è¯¦æƒ…: {error_details}")
            
            clean_config = {k: v for k, v in config.items() if k != 'algorithm_class'}
            return {
                'experiment_id': f"FAILED_{config['algorithm']}_{config['dataset']}_{int(time.time())}",
                'algorithm': config['algorithm'],
                'dataset': config['dataset'],
                'config': clean_config,
                'success': False,
                'error': str(e),
                'error_details': error_details,
                'experiment_time': time.time() - start_time,
                'timestamp': datetime.now().isoformat()
            }
    
    def run_all_experiments(self, max_experiments: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è¿è¡Œæ‰€æœ‰å®éªŒ
        
        Args:
            max_experiments: æœ€å¤§å®éªŒæ•°é‡ï¼ŒNoneè¡¨ç¤ºè¿è¡Œå…¨éƒ¨
            
        Returns:
            æ‰€æœ‰å®éªŒç»“æœ
        """
        # è·å–å®éªŒé…ç½®
        if max_experiments and max_experiments <= 20:
            configs = self.config_manager.get_quick_configs(max_experiments)
        else:
            configs = list(self.config_manager.get_experiment_configs())
            if max_experiments:
                configs = configs[:max_experiments]
        
        total_experiments = len(configs)
        print(f"ğŸš€ å¼€å§‹è¿è¡Œ {total_experiments} ä¸ªå¯¹æ¯”å®éªŒ")
        print("=" * 60)
        
        self.results = []
        
        for i, config in enumerate(configs, 1):
            print(f"\nğŸ“Š å®éªŒ {i}/{total_experiments}: {config['algorithm']} - {config['dataset']}")
            print(f"   é…ç½®: lookback={config.get('lookback')}, lookahead={config.get('lookahead')}, "
                  f"stride={config.get('stride')}, depth={config.get('depth')}")
            
            # è¿è¡Œå®éªŒ
            result = self.run_single_experiment(config)
            self.results.append(result)
            
            # æ˜¾ç¤ºç»“æœ
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸï¼ˆåªè¦å®éªŒå®Œæˆå°±è®¤ä¸ºæˆåŠŸï¼Œå³ä½¿æ”¶ç›Šä¸º0ï¼‰
            is_success = result.get('success', True)  # é»˜è®¤æˆåŠŸï¼Œé™¤éæ˜ç¡®æ ‡è®°ä¸ºå¤±è´¥
            
            if is_success:
                print(f"   âœ… æˆåŠŸ: æ”¶ç›Š{result.get('total_return', 0):.2%}, "
                      f"å¤æ™®{result.get('sharpe_ratio', 0):.2f}, "
                      f"ç”¨æ—¶{result.get('experiment_time', 0):.1f}s")
            else:
                error_msg = result.get('error', 'Unknown error')
                if 'error_details' in result:
                    # åªæ˜¾ç¤ºé”™è¯¯çš„ç¬¬ä¸€è¡Œï¼Œé¿å…è¿‡é•¿
                    error_lines = result['error_details'].split('\n')
                    if len(error_lines) > 1:
                        error_msg = f"{error_msg} ({error_lines[1].strip()[:50]}...)"
                print(f"   âŒ å¤±è´¥: {error_msg}")
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            if i % 5 == 0:
                self.save_results(intermediate=True)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.save_results(intermediate=False)
        
        print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ! æ€»ç”¨æ—¶: {sum(r.get('experiment_time', 0) for r in self.results):.1f}s")
        
        return self.results
    
    def save_results(self, intermediate: bool = False):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        suffix = "intermediate" if intermediate else "final"
        filename = f"comparison_results_{suffix}_{timestamp}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {filepath}")
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        if not self.results:
            return "æ²¡æœ‰å®éªŒç»“æœ"
        
        # åˆ†æç»“æœï¼ˆä¿®å¤æˆåŠŸåˆ¤æ–­é€»è¾‘ï¼‰
        def is_successful(result):
            return result.get('success', True)  # é»˜è®¤æˆåŠŸï¼Œé™¤éæ˜ç¡®æ ‡è®°ä¸ºå¤±è´¥
        
        successful_results = [r for r in self.results if is_successful(r)]
        failed_results = [r for r in self.results if not is_successful(r)]
        
        report = []
        report.append("ğŸ† EATA-RL å¯¹æ¯”å®éªŒæŠ¥å‘Š")
        report.append("=" * 60)
        
        # æ€»ä½“ç»Ÿè®¡
        report.append(f"\nğŸ“Š å®éªŒç»Ÿè®¡:")
        report.append(f"   æ€»å®éªŒæ•°: {len(self.results)}")
        report.append(f"   æˆåŠŸå®éªŒ: {len(successful_results)}")
        report.append(f"   å¤±è´¥å®éªŒ: {len(failed_results)}")
        report.append(f"   æˆåŠŸç‡: {len(successful_results)/len(self.results)*100:.1f}%")
        
        if successful_results:
            # æŒ‰ç®—æ³•åˆ†ç»„
            by_algorithm = {}
            for result in successful_results:
                algo = result.get('algorithm', 'Unknown')
                if algo not in by_algorithm:
                    by_algorithm[algo] = []
                by_algorithm[algo].append(result)
            
            # ç®—æ³•æ€§èƒ½å¯¹æ¯”
            report.append(f"\nğŸ¯ ç®—æ³•æ€§èƒ½å¯¹æ¯”:")
            report.append("-" * 80)
            report.append(f"{'ç®—æ³•':<12} {'å¹´åŒ–æ”¶ç›Š':<12} {'å¤æ™®æ¯”ç‡':<12} {'æœ€å¤§å›æ’¤':<12} {'ç”¨æ—¶':<10} {'çª—å£æ•°':<10}")
            report.append("-" * 80)
            
            for algo, results in by_algorithm.items():
                # å–ç¬¬ä¸€ä¸ªç»“æœçš„é…ç½®ä¿¡æ¯ï¼ˆå‡è®¾åŒä¸€ç®—æ³•çš„é…ç½®ç›¸åŒï¼‰
                first_result = results[0]
                config = first_result.get('config', {})
                
                lookback = config.get('lookback', '-')
                lookahead = config.get('lookahead', '-')
                stride = config.get('stride', '-')
                depth = config.get('depth', '-')
                windows = config.get('windows', '-')
                
                # è®¡ç®—å¹³å‡å€¼
                avg_ann_return = np.mean([r.get('annualized_return', 0) for r in results])
                avg_sharpe = np.mean([r.get('sharpe_ratio', 0) for r in results])
                avg_drawdown = np.mean([r.get('max_drawdown', 0) for r in results])
                avg_time = np.mean([r.get('experiment_time', 0) for r in results])
                
                report.append(f"{algo:<12} {avg_ann_return:<12.2%} {avg_sharpe:<12.2f} {avg_drawdown:<12.2%} {avg_time:<10.1f}s {windows:<10}")
            
            report.append("-" * 80)
            
            # æœ€ä½³ç»“æœ
            best_result = max(successful_results, key=lambda x: x.get('total_return', 0))
            report.append(f"\nğŸ† æœ€ä½³ç»“æœ:")
            report.append(f"   ç®—æ³•: {best_result.get('algorithm')}")
            report.append(f"   æ•°æ®é›†: {best_result.get('dataset')}")
            report.append(f"   æ€»æ”¶ç›Š: {best_result.get('total_return', 0):.2%}")
            report.append(f"   å¤æ™®æ¯”ç‡: {best_result.get('sharpe_ratio', 0):.2f}")
            report.append(f"   æœ€å¤§å›æ’¤: {best_result.get('max_drawdown', 0):.2%}")
        
        if failed_results:
            report.append(f"\nâŒ å¤±è´¥å®éªŒåˆ†æ:")
            failure_reasons = {}
            for result in failed_results:
                error = result.get('error', 'Unknown')
                if error not in failure_reasons:
                    failure_reasons[error] = 0
                failure_reasons[error] += 1
            
            for error, count in failure_reasons.items():
                report.append(f"   {error}: {count}æ¬¡")
        
        report_text = "\n".join(report)
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(self.output_dir, f"comparison_report_{timestamp}.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(f"ğŸ“‹ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report_text


# å¯¼å…¥numpyç”¨äºè®¡ç®—
import numpy as np
