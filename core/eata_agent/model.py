
import time
from collections import defaultdict
from collections import deque

import numpy as np

from . import score
from . import symbolics
from .mcts import MCTS #ä»mctsæ¥å…¥MCTSç±»
from .network import PVNetCtx #ä»networkæ¥å…¥PVNetCtxç±»

#modelå°±æ˜¯æœ€ç›´æ¥çš„ä¸mctsã€networkè¿æ¥çš„åœ°æ–¹
class Model:
    def __init__(self, args):
        # Directly assign properties from the args object to the instance variables
        self.symbolic_lib = args.symbolic_lib
        self.max_len = args.max_len
        self.max_module_init = args.max_module_init
        self.num_transplant = args.num_transplant
        self.num_runs = args.num_runs
        self.eta = args.eta
        self.num_aug = args.num_aug
        self.exploration_rate = args.exploration_rate
        self.transplant_step = args.transplant_step
        self.norm_threshold = args.norm_threshold
        self.device = args.device
      #  åˆå§‹åŒ–ç¯å¢ƒï¼šæ ¹æ® main.py ä¼ å…¥çš„argså‚æ•°ï¼Œè®¾ç½®æ‰€æœ‰è¶…å‚æ•°  å¾ˆç†Ÿæ‚‰æ˜ç™½äº†

        # è‡ªåŠ¨æ¨æ–­nå’ŒlookBACK
        self.n = None #å…ˆç”¨ç©ºå€¼é¡¶ä¸€ä¸‹å­ næ˜¯è¾“å…¥æ•°æ®çš„ç»´åº¦ï¼ˆç‰¹å¾æ•°ï¼‰
        self.lookBACK = 1  # HOTFIX: å¼ºåˆ¶å›çœ‹ä¸º1ï¼Œä»è€Œè®©å˜é‡å¯¹åº”ä¸åŒçš„ç‰¹å¾(x0,x1..)ï¼Œè€Œä¸æ˜¯æ—¶é—´æ­¥
        # ä»…NEMoTSè‡ªåŠ¨ç”Ÿæˆå¤šå˜é‡å¤šæ­¥grammar
        if self.symbolic_lib == 'NEMoTS':
            # å°è¯•ä»argsæˆ–æ•°æ®æ¨æ–­n
            if hasattr(args, 'n_vars'):
                self.n = args.n_vars
            else:
                self.n = None  # è¿è¡Œæ—¶å†æ¨æ–­ åœ¨åé¢runä¸­
            # åŠ¨æ€ç”Ÿæˆgrammarï¼ˆå¦‚næœªçŸ¥åˆ™é¦–æ¬¡runæ—¶å†ç”Ÿæˆï¼‰
            def gen_multivar_grammar(n, lookBACK):
                terminals = [f'A->x{i}' for i in range(n*lookBACK)]
                #æ ¹æ®è¾“å…¥æ•°æ®çš„ç»´åº¦ n (ç‰¹å¾æ•°) å’Œ lookBACK (å›çœ‹çª—å£é•¿åº¦)ï¼ŒåŠ¨æ€åˆ›å»ºâ€œç»ˆç«¯â€ç¬¦å·ï¼Œå³å˜é‡ï¼Œå¦‚ x0,x1,x2, ...ã€‚
                ops = ['A->A+A', 'A->A-A', 'A->A*A', 'A->A/A', 'A->cos(A)', 'A->sin(A)', 'A->exp(A)', 'A->A*C', 'A->log(A)', 'A->sqrt(A)']
                #å¯ä»¥ä»è¿™æ·»åŠ æ•°å­¦è¿ç®—ï¼Œå¢åŠ æç‚¹çš„é€‰æ‹©æ€§
                return ops + terminals
            #ç„¶åå°†è¿™äº›å˜é‡ä¸å›ºå®šçš„æ•°å­¦è¿ç®—ï¼ˆopsï¼‰ç»“åˆï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è¯­æ³•è§„åˆ™åº“ self.base_grammarã€‚
            if self.n is not None:
                self.base_grammar = gen_multivar_grammar(self.n, self.lookBACK) #å°±å½¢æˆäº†è¯­æ³•è§„åˆ™åº“self.base_grammarã€‚
                
            else:
                self.base_grammar = []  # runæ—¶å†ç”Ÿæˆ å¦‚æœåˆå§‹åŒ–æ—¶ä¸çŸ¥é“ nï¼Œå®ƒä¼šç•™åˆ° run æ–¹æ³•ä¸­ç¬¬ä¸€æ¬¡æ‹¿åˆ°æ•°æ®æ—¶å†ç”Ÿæˆã€‚åœ¨runä¸­
                
        else:
            self.base_grammar = symbolics.rule_map[self.symbolic_lib]
            #å…¶ä»–æƒ…å†µè¯­æ³•åº“ç›´æ¥è°ƒç”¨Symbolicsä¸­å®šä¹‰çš„è¯­æ³•åº“ ï¼ˆå¯ä»¥ä¿®æ”¹Symbolicsçš„rule_map

        # æ”¯æŒå¤–éƒ¨æ³¨å…¥å…±äº«ç½‘ç»œ
        if hasattr(args, 'shared_network') and args.shared_network is not None:
            self.p_v_net_ctx = args.shared_network
        else:
            self.p_v_net_ctx = PVNetCtx(self.base_grammar, self.num_transplant, self.device)
           #åˆå§‹åŒ–ç­–ç•¥-ä»·å€¼ç¥ç»ç½‘ç»œã€‚å®ƒä¼šæ£€æŸ¥æ˜¯å¦ä»å¤–éƒ¨ä¼ å…¥äº†ä¸€ä¸ªå…±äº«ç½‘ç»œï¼Œå¦‚æœæ²¡æœ‰ï¼Œå°±å®ä¾‹åŒ–ä¸€ä¸ª PVNetCtxå¯¹è±¡ã€‚PVNetCtx æ¥è‡ª network.pyï¼Œæ˜¯çœŸæ­£çš„ PyTorch æ¨¡å‹ã€‚
        #è¿™ä¹Ÿç®—æ˜¯ä¸€ä¸ªæ¥å£å§ ä¸æ˜¯ï¼Œä»networkä¸­å¯¼å…¥äº†PVNetCtx
        self.nt_nodes = symbolics.ntn_map[self.symbolic_lib]
        self.score_with_est = score.score_with_est
        self.simple_mae_score = score.simple_mae_score
        self.data_buffer = deque(maxlen=64)  # è°ƒæ•´ä¸ºé€‚åˆçŸ­æœŸæµ‹è¯•çš„å¤§å°
        #nt_nodes: è·å–éç»ˆç«¯èŠ‚ç‚¹ï¼ˆNon-terminal nodesï¼‰ï¼Œåœ¨è¯­æ³•æ ‘ä¸­é€šå¸¸ä»£è¡¨è¿ç®—æ“ä½œã€‚
        # `score_with_est`: æŒ‡å®šç”¨äºè¯„ä¼°è¡¨è¾¾å¼å¥½åçš„è¯„åˆ†å‡½æ•°*ï¼Œè¯¥å‡½æ•°æ¥è‡ª score.pyã€‚
    #  *   data_buffer: åˆ›å»ºä¸€ä¸ªå›ºå®šé•¿åº¦çš„é˜Ÿåˆ—ï¼Œç”¨ä½œç»éªŒå›æ”¾æ± ã€‚

        self.aug_grammars_counter = defaultdict(lambda: 0)


#ï¼æ‰§è¡Œç¬¦å·å›å½’ä»»åŠ¡çš„å…¥å£ï¼ŒåŒ…å«äº†ç®—æ³•çš„æ ¸å¿ƒå¾ªç¯
    def run(self, X, y=None, previous_best_tree=None, alpha=None, variant_exploration_rate=None):
        #é€šè¿‡è¿™é‡Œçš„æ“ä½œï¼Œå¤–éƒ¨æ¥å£ï¼Œç”±engineä¸­çš„simulateæ–¹æ³•è°ƒç”¨
        # assert X.size(0) == 1 # æ³¨é‡Šæ‰æ­¤è¡Œï¼Œä»¥å…è®¸å¤„ç†æ¥è‡ªæ»‘åŠ¨çª—å£çš„æ‰¹æ•°æ®
        #ä¸€ä¸ªæ–­è¨€ï¼Œç¡®ä¿æ¯æ¬¡åªå¤„ç†ä¸€ä¸ªæ•°æ®æ ·æœ¬ï¼ˆbatch_size ä¸º 1ï¼‰ã€‚è¿™æ˜¯å› ä¸º MCTSæœç´¢æ˜¯é’ˆå¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œçš„
        
        # åŠ¨æ€ç”Ÿæˆbase_grammarï¼ˆé˜²æ­¢åˆå§‹åŒ–æ—¶næœªçŸ¥å¯¼è‡´grammarä¸ºç©ºï¼‰
        if self.symbolic_lib == 'NEMoTS' and (self.base_grammar is None or len(self.base_grammar) == 0):
            X_ = X.squeeze(0)
            
            if X_.ndim == 2:
                # The number of features 'n' is always the second dimension (columns)
                n = X_.shape[1]
                self.n = n
            elif X_.ndim == 1:
                raise ValueError(f"æ— æ³•ä» X_ shape {X_.shape} æ¨æ–­ nï¼Œè¯·æ£€æŸ¥è¾“å…¥æ•°æ® shapeï¼")
            else:
                raise ValueError(f"æœªçŸ¥çš„ X_ shape: {X_.shape}ï¼Œæ— æ³•æ¨æ–­ nï¼")
            #ä¸Šé¢å°±æ˜¯ä¸€ä¸ªè¯¦ç»†æ¨æ–­nçš„è¿‡ç¨‹æ­¥éª¤ å¯¹åº”çš„å°±ä¼šåˆå§‹åŒ–æ—¶ä¸çŸ¥é“nï¼Œåœ¨è¿™é‡Œç”Ÿæˆ
            def gen_multivar_grammar(n, lookBACK):
                terminals = [f'A->x{i}' for i in range(n*lookBACK)]
                ops = ['A->A+A', 'A->A-A', 'A->A*A', 'A->A/A', 'A->cos(A)', 'A->sin(A)', 'A->exp(A)', 'A->A*C', 'A->log(A)', 'A->sqrt(A)']
                return ops + terminals
            self.base_grammar = gen_multivar_grammar(self.n, self.lookBACK)
            # HOTFIX: Re-initialize the network context with the newly generated base_grammar
            self.p_v_net_ctx = PVNetCtx(self.base_grammar, self.num_transplant, self.device)
            #è¿™éƒ¨åˆ†ä»£ç ç”¨äºåŠ¨æ€ç”Ÿæˆè¯­æ³•*ã€‚å¦‚æœåœ¨ __init__ åˆå§‹åŒ–æ—¶æ²¡æœ‰ç¡®å®šè¾“å…¥æ•°æ®çš„ç‰¹å¾ç»´åº¦ nï¼Œå°±åœ¨è¿™é‡Œæ ¹æ®ç¬¬ä¸€æ¬¡ä¼ å…¥çš„æ•°æ® X çš„å½¢çŠ¶æ¥æ¨æ–­ nï¼Œ
            # ç„¶åè°ƒç”¨å†…éƒ¨å‡½æ•° gen_multivar_grammar ç”Ÿæˆ MCTSæœç´¢æ—¶éœ€è¦éµå¾ªçš„è¯­æ³•è§„åˆ™ self.base_grammarã€‚è¿™æ˜¯è®©æ¨¡å‹é€‚åº”ä¸åŒç»´åº¦è¾“å…¥æ•°æ®çš„å…³é”®
            #è¿™é‡Œå¯ä»¥å¢åŠ è¯­æ³•è§„åˆ™
            # ä½¿ç”¨__init__ä¸­å·²åˆå§‹åŒ–çš„self.p_v_net_ctxï¼Œä¸éœ€è¦å†æ¬¡åˆå§‹åŒ–
            



             ##è¿™é‡Œä¸»è¦æ˜¯å¯¹æ•°æ®çš„å¤„ç† å±•å¹³è¾“å…¥ åˆ°162è¡Œ
        # è‡ªåŠ¨æ¨æ–­nå’ŒlookBACK
        if self.symbolic_lib == 'NEMoTS':
            # X shape: [1, lookBACK, n] or [1, n, lookBACK]
            X_ = X.squeeze(0)
            if (self.base_grammar is None or len(self.base_grammar) == 0) and X_.ndim == 2:
                if X_.shape[0] == self.lookBACK:
                    n = X_.shape[1]
                else:
                    n = X_.shape[0]
                self.n = n
                def gen_multivar_grammar(n, lookBACK):
                    terminals = [f'A->x{i}' for i in range(n*lookBACK)]
                    ops = ['A->A+A', 'A->A-A', 'A->A*A', 'A->A/A', 'A->cos(A)', 'A->sin(A)', 'A->exp(A)', 'A->A*C', 'A->log(A)', 'A->sqrt(A)']
                    return ops + terminals
                self.base_grammar = gen_multivar_grammar(self.n, self.lookBACK)

            # --- Data Preparation for Scoring and Network Input ---
            X_np = X.cpu().numpy()
            y_np = y.cpu().numpy() # This is the lookahead y, not used for MCTS scoring

            # The `y_np` (lookahead) is for final evaluation, not for building the scoring data for MCTS.
            # We create a target from the input data `X_np` itself for MCTS to learn the underlying dynamics.
            # We'll create a 1-step-ahead prediction task for the first feature (index 0).
            X_for_scoring = X_np[:-1]  # Use first N-1 steps of X as input features
            y_for_scoring = X_np[1:, 0]   # Use the next step's value of the first feature as the target

            # Transpose X to be (n_features, n_timesteps)
            X_transposed = X_for_scoring.T
            # Reshape y to be (1, n_timesteps)
            y_reshaped = y_for_scoring.reshape(1, -1)

            # Create supervision_data for the scoring function. Now dimensions match.
            supervision_data = np.vstack([X_transposed, y_reshaped])

            # For network input, it expects a flattened sequence
            X_flat = X_np.reshape(-1)
            time_idx = np.arange(X_flat.shape[0])
            input_data = np.vstack([time_idx, X_flat])
            
        else:#å¦ä¸€å¥—æ•°æ®å¤„ç†é€»è¾‘
            if y is not None:
                X = X.squeeze(0)
                y = y.squeeze(0)
                time_idx = np.arange(X.size(0) + y.shape[0])
                input_data = np.vstack([time_idx[:X.size(0)], X])
                supervision_data = np.vstack([time_idx, np.concatenate([X, y])])
            else:
                X = X.squeeze(0)
                time_idx = np.arange(X.size(0))
                input_data = np.vstack([time_idx[:X.size(0)], X])
                supervision_data = np.vstack([time_idx, X])
#è®²è§£: æ•°æ®é¢„å¤„ç†ã€‚è¿™éƒ¨åˆ†ä»£ç å°† PyTorch å¼ é‡ `X` å’Œ `y` è½¬æ¢æˆ NumPy æ•°ç»„ï¼Œå¹¶æ„é€ æˆ MCTS å’Œè¯„åˆ†å‡½æ•°æ‰€éœ€è¦çš„æ ¼å¼ã€‚`input_data`é€šå¸¸åªåŒ…å«è¾“å…¥åºåˆ—ï¼Œè€Œ `supervision_data` åŒ…å«è¾“å…¥å’Œè¾“å‡ºåºåˆ—ï¼Œç”¨äºæœ€ç»ˆçš„è¯„åˆ†ã€‚å¯¹äº NEMoTSï¼Œå®ƒä¼šå°†å¤šç»´æ—¶åºæ•°æ®å±•å¹³ï¼ˆflattenï¼‰*ã€‚


        all_times = []
        all_eqs = []
        test_scores = []
        final_best_tree = None
        all_mcts_records = [] # ç”¨äºæ”¶é›†æ‰€æœ‰MCTSè®°å½•

        module_grow_step = (self.max_len - self.max_module_init) / self.num_transplant

        for i_test in range(self.num_runs):
            best_solution = ('nothing', 0)

            exploration_rate = self.exploration_rate
            max_module = self.max_module_init
            reward_his = []
            best_modules = []
            aug_grammars = []

            start_time = time.time()

            self.p_v_net_ctx.reset_grammar_vocab_name()

            # æ ¹æ®å˜ä½“å‚æ•°é€‰æ‹©è¯„åˆ†å‡½æ•°ï¼ˆç§»åˆ°å¾ªç¯å¤–ï¼Œç¡®ä¿æ€»æ˜¯ç”Ÿæ•ˆï¼‰
            score_func = self.score_with_est  # é»˜è®¤è¯„åˆ†å‡½æ•°
            if hasattr(self, '_variant_reward_function'):
                if self._variant_reward_function == 'simple_mae':
                    score_func = self.simple_mae_score
                    print(f"   ğŸ¯ ä½¿ç”¨ç®€å•MAEè¯„åˆ†å‡½æ•°")
            
            # æ ¹æ®å˜ä½“å‚æ•°é€‰æ‹©æ¢ç´¢ç‡ï¼ˆç§»åˆ°å¾ªç¯å¤–ï¼Œç¡®ä¿æ€»æ˜¯ç”Ÿæ•ˆï¼‰
            # ğŸ”§ æ–¹æ¡ˆ1ï¼šå‚æ•°åŒ–æ–¹æ³•è°ƒç”¨ - ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å˜ä½“å‚æ•°
            if variant_exploration_rate is not None:
                exploration_rate = variant_exploration_rate
                print(f"   ğŸ”§ ä½¿ç”¨ä¼ å…¥çš„å˜ä½“exploration_rate = {exploration_rate}")
            else:
                # å‘åå…¼å®¹ï¼šä¿æŒåŸæœ‰é€»è¾‘
                exploration_rate = self.exploration_rate  # é»˜è®¤æ¢ç´¢ç‡
                
                # æ£€æŸ¥Modelå±‚é¢çš„å˜ä½“å‚æ•°
                if hasattr(self, '_variant_exploration_rate'):
                    exploration_rate = self._variant_exploration_rate
                    print(f"   ğŸ” ä½¿ç”¨æ¨¡å‹å˜ä½“exploration_rate = {exploration_rate}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é€šè¿‡argsä¼ é€’çš„å˜ä½“å‚æ•°ï¼ˆä»SlidingWindowNEMoTSä¼ é€’ï¼‰
                elif hasattr(self, 'args') and hasattr(self.args, 'exploration_rate'):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å˜ä½“è®¾ç½®çš„å€¼ï¼ˆä¸ç­‰äºé»˜è®¤å€¼ï¼‰
                    default_exploration_rate = 1 / (2**0.5)  # é»˜è®¤å€¼
                    if abs(self.args.exploration_rate - default_exploration_rate) > 1e-6:
                        exploration_rate = self.args.exploration_rate
                        print(f"   ğŸ” ä»argsä½¿ç”¨å˜ä½“exploration_rate = {exploration_rate}")
                else:
                    print(f"   ğŸ”§ ä½¿ç”¨é»˜è®¤exploration_rate = {exploration_rate}")

            for i_itr in range(self.num_transplant):
                
                # å¼ºåˆ¶è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºä¼ é€’ç»™MCTSçš„exploration_rateå€¼
                print(f"ğŸ” [å¼ºåˆ¶è°ƒè¯•] åˆ›å»ºMCTSæ—¶çš„exploration_rate: {exploration_rate}")
                print(f"ğŸ” [å¼ºåˆ¶è°ƒè¯•] é»˜è®¤exploration_rate: {1/(2**0.5)}")
                print(f"ğŸ” [å¼ºåˆ¶è°ƒè¯•] æ˜¯å¦ä½¿ç”¨å˜ä½“å€¼: {abs(exploration_rate - 1/(2**0.5)) > 1e-6}")
                
                mcts_block = MCTS(data_sample=supervision_data,
                                  base_grammars=self.base_grammar,
                                  aug_grammars=[x[0] for x in sorted(self.aug_grammars_counter.items(), key=lambda item: item[1], reverse=True)[:20]],
                                  nt_nodes=self.nt_nodes,
                                  max_len=self.max_len,
                                  max_module=max_module,
                                  aug_grammars_allowed=self.num_aug,
                                  func_score=score_func,
                                  exploration_rate=exploration_rate,
                                  eta=self.eta,
                                  initial_tree=previous_best_tree)

                buffer_size = self.data_buffer.maxlen
                current_buffer_size = len(self.data_buffer)
                
                # ä½¿ç”¨ä¼ å…¥çš„alphaå‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹åŠ¨æ€è®¡ç®—é€»è¾‘
                if alpha is not None:
                    # ä½¿ç”¨å˜ä½“ä¼ å…¥çš„alphaå€¼ï¼Œä¸å—ç¼“å†²åŒºå¤§å°å½±å“
                    mcts_alpha = alpha
                    print(f"   ğŸ”§ ä½¿ç”¨å˜ä½“alphaå‚æ•°: {mcts_alpha} (å›ºå®šå€¼ï¼Œä¸å—ç¼“å†²åŒºå½±å“)")
                else:
                    # æ¢å¤åŸå§‹åŠ¨æ€è®¡ç®—é€»è¾‘
                    warmup = int(buffer_size * 0.1)
                    if current_buffer_size < warmup:
                        mcts_alpha = 0.0  # æ¢å¤åŸå§‹é€»è¾‘ï¼šåˆå§‹é˜¶æ®µä½¿ç”¨0.0
                    else:
                        mcts_alpha = min(1.0, (current_buffer_size - warmup) / (buffer_size - warmup))
                    print(f"   ğŸ”§ ä½¿ç”¨åŠ¨æ€è®¡ç®—alpha: {mcts_alpha} (åŸºäºç¼“å†²åŒºå¤§å° {current_buffer_size}/{buffer_size})")

                # ğŸ¯ ä¸ºMCTSå®ä¾‹è®¾ç½®æ¶ˆèå®éªŒæ¨¡å¼æ ‡è®°
                if hasattr(self, '_ablation_experiment_mode') and self._ablation_experiment_mode:
                    mcts_block._ablation_experiment_mode = True
                    print(f"   âœ… MCTSå®ä¾‹æ¶ˆèå®éªŒæ¨¡å¼å·²è®¾ç½®")
                
                new_best_tree_node, current_solution, good_modules, records = mcts_block.run(
                    input_data,
                    self.transplant_step,
                    network=self.p_v_net_ctx,
                    num_play=10,
                    print_flag=True,
                    use_network=True,
                    alpha=mcts_alpha,
                    buffer_size=buffer_size,
                    current_buffer_size=current_buffer_size
                )

                # ä¿®å¤ï¼šå…ˆè½¬æ¢zipå¯¹è±¡ä¸ºåˆ—è¡¨ï¼Œé¿å…é‡å¤æ¶ˆè€—
                records_list = list(records) if records else []
                all_mcts_records.extend(records_list[:]) # æ”¶é›†è®°å½•ï¼Œè€Œä¸æ˜¯ç›´æ¥å­˜å…¥buffer
                
                # ä¿®å¤ï¼šç›´æ¥å­˜å‚¨ç»éªŒåˆ°ç¼“å†²åŒºï¼Œè®©åŠ¨æ€alphaèƒ½æ­£å¸¸å·¥ä½œ
                if records_list:
                    self.data_buffer.extend(records_list)
                    print(f"   ğŸ“¦ å­˜å‚¨ {len(records_list)} æ¡ç»éªŒåˆ°ç¼“å†²åŒºï¼Œå½“å‰å¤§å°: {len(self.data_buffer)}/{self.data_buffer.maxlen}")

                if not best_modules:
                    best_modules = good_modules
                else:
                    best_modules = sorted(list(set(best_modules + good_modules)), key=lambda x: x[1])

                aug_grammars = [x[0] for x in best_modules[-self.num_aug:]]
                for grammar in aug_grammars:
                    self.aug_grammars_counter[grammar] += 1

                reward_his.append(best_solution[1])

                if current_solution[1] > best_solution[1]:
                    best_solution = current_solution
                    final_best_tree = new_best_tree_node

                max_module += module_grow_step
                exploration_rate *= 5

                test_score = \
                    self.score_with_est(score.simplify_eq(best_solution[0]), 0, supervision_data, eta=self.eta)[0]

            all_eqs.append(score.simplify_eq(best_solution[0]))
            test_scores.append(test_score)

            eq_out = score.simplify_eq(best_solution[0])
            if self.symbolic_lib == 'NEMoTS':
                print(f'å˜é‡æ˜ å°„: {[f"x{i}" for i in range(self.n*self.lookBACK)]}')
            print('\n{} tests complete after {} iterations.'.format(i_test + 1, i_itr + 1))
            print('best solution: {}'.format(eq_out))
            print('test score: {}'.format(test_score))
            print()

        policy = None
        reward = reward_his[-1] if len(reward_his) > 0 else None
        
        # ä¿®å¤å¹¶æ¿€æ´»æ­£ç¡®çš„è¿”å›è¯­å¥ï¼Œå¹¶å¢åŠ  all_mcts_records ä½œä¸ºè¿”å›å€¼
        return all_eqs, all_times, test_scores, all_mcts_records, policy, reward, final_best_tree


    #moduleå°±æ˜¯è¯­æ³•å¢å¼ºæœ€ç›´æ¥çš„åˆ©ç”¨å¯¹è±¡ï¼šå­ç»“æ„  ä¼šè¢«æ·»åŠ åˆ°è¯­æ³•å¢åŠ åº“å½“ä¸­ #ç»†èŠ‚è¿˜æ˜¯åœ¨mctsä»£ç å½“ä¸­
