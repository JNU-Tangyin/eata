import copy

import torch
import torch.nn as nn
import torch.nn.functional as F
  ###ï¼ï¼ï¼ network.py å®šä¹‰äº†ä¸¤ä¸ªæ ¸å¿ƒç±»ï¼š
  #1.  PVNet: ä¸€ä¸ªç»§æ‰¿è‡ª torch.nn.Module çš„å®é™…ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚å®ƒåŒ…å«åµŒå…¥å±‚ã€LSTMå±‚å’Œå…¨è¿æ¥å±‚ï¼Œè´Ÿè´£å…·ä½“çš„è®¡ç®—ã€‚
  #2.  PVNetCtx: ä¸€ä¸ªä¸Šä¸‹æ–‡/æ§åˆ¶å™¨ç±»ã€‚å®ƒåŒ…è£…äº† PVNetï¼Œå¹¶ä¸ºé¡¹ç›®ä¸­çš„å…¶ä»–éƒ¨åˆ†ï¼ˆä¸»è¦æ˜¯
  #mcts.pyï¼‰æä¾›äº†ä¸€ä¸ªå¹²å‡€ã€ç»Ÿä¸€çš„æ¥å£ã€‚å®ƒè´Ÿè´£å¤„ç†æ•°æ®æ ¼å¼çš„è½¬æ¢ï¼ˆä¾‹å¦‚ï¼Œå°†å­—ç¬¦ä¸²è¡¨è¾¾å¼è½¬æ¢ä¸ºç½‘ç»œèƒ½ç†è§£çš„å¼ é‡ï¼‰å’Œè¯æ±‡è¡¨çš„ç®¡ç†ã€‚

  #è¿™é‡Œä¸»è¦æ˜¯å€ŸåŠ©torch.nnåº“è¿›è¡Œå¿«é€Ÿçš„æ„å»ºå’Œè®­ç»ƒç¥ç»ç½‘ç»œ
  #moduleæ˜¯è¯¥åº“æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ï¼Œæä¾›æ·±åº¦å­¦ä¹ ä¸­å¸¸ç”¨çš„å„ç±»å±‚
class PVNet(nn.Module):
    def __init__(self, grammar_vocab, num_transplant, hidden_dim=16):
        #nn.initæ¨¡å—å¯æä¾›å„ç§å‚æ•°çš„åˆå§‹åŒ–æ–¹æ³•
        super(PVNet, self).__init__()
        self.grammar_vocab = grammar_vocab
        self.num_transplant = num_transplant
        self.embedding_table = nn.Embedding(len(self.grammar_vocab), hidden_dim) #åµŒå…¥å±‚
        #åˆ›å»ºLSTMé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ
        self.lstm_state = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True)
        self.lstm_seq = nn.LSTM(input_size=1, hidden_size=hidden_dim, num_layers=2, batch_first=True)
        #åˆ›å»ºä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLP)
        self.mlp = nn.Sequential(nn.Linear(hidden_dim * 2, hidden_dim * 2, bias=True),
                                 nn.ReLU(),
                                 nn.Linear(hidden_dim * 2, hidden_dim * 2, bias=True))

        self.dist_out = nn.Linear(hidden_dim * 2, len(self.grammar_vocab) + num_transplant - 2)
        self.value_out = nn.Linear(hidden_dim * 2, 1)
        self.profit_out = nn.Linear(hidden_dim * 2, 1)

    def forward(self, seq, state_idx, need_embeddings=True):
        #å®šä¹‰äº†æ•°æ®åœ¨ç½‘ç»œä¸­çš„æµåŠ¨æ–¹å¼ï¼ˆå‰å‘ä¼ æ’­ï¼‰
        if need_embeddings:
            state = self.embedding_table(state_idx.long())
        else:
            state = state_idx

        seq = seq.unsqueeze(-1)
        out_state, _ = self.lstm_state(state)
        out_seq, _ = self.lstm_seq(seq)

        out = torch.cat([out_state[:, -1, :], out_seq[:, -1, :]], dim=-1)
        out = self.mlp(out)
        raw_dist_out = self.dist_out(out)
        raw_dist_out = torch.where(torch.isnan(raw_dist_out), torch.zeros_like(raw_dist_out), raw_dist_out)
        
        # ğŸ¯ æ¶æ„çº§å˜ä½“æ³¨å…¥ï¼šä»…åœ¨æ¶ˆèå®éªŒæ¨¡å¼ä¸‹ç”Ÿæ•ˆ
        value_out = self.value_out(out)
        profit_out = self.profit_out(out)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ¶ˆèå®éªŒæ¨¡å¼
        import os
        ablation_mode = os.getenv('ABLATION_EXPERIMENT_MODE', '').lower() == 'true'
        return raw_dist_out, value_out, profit_out

#ä¸mctsç»Ÿä¸€çš„æ¥å£ çœŸæ­£è°ƒç”¨çš„part
class PVNetCtx:
   # å®šä¹‰ä¸€ä¸ªåä¸ºPVNetCtxçš„ç±»ã€‚å®ƒä¸æ˜¯ä¸€ä¸ªnn.Moduleï¼Œè€Œæ˜¯ä¸€ä¸ªæ§åˆ¶å™¨æˆ–åŒ…è£…å™¨ï¼Œè´Ÿè´£ç®¡ç†PVNetå®ä¾‹å¹¶æä¾›æ–¹ä¾¿çš„æ¥å£ã€‚
    def __init__(self, grammars, num_transplant, device):
        self.device = device
        self.base_grammars = grammars
        self.num_transplant = num_transplant
        
        # Initial setup
        self.grammar_vocab = ['f->A'] + self.base_grammars + ['placeholder' + str(i) for i in range(self.num_transplant)]
        self.grammar_vocab_backups = copy.deepcopy(self.grammar_vocab)
        self.symbol2idx = {symbol: idx for idx, symbol in enumerate(self.grammar_vocab)}
        self.pv_net = PVNet(self.grammar_vocab, self.num_transplant).to(self.device)

    def policy_value(self, seq, state):
        
        assert seq.shape[0] > 1, f"seq shape error: {seq.shape}, should have at least 2 rows"
        state_list = state.split(",")
        state_idx = torch.Tensor([self.symbol2idx[item] for item in state_list]).to(self.device)
        seq = torch.Tensor(seq).to(self.device)
        raw_dist_out, value_out, profit_out = self.pv_net(seq[1, :].unsqueeze(0), state_idx.unsqueeze(0))
        return raw_dist_out, value_out, profit_out
   #è¿”å›æ¦‚ç‡å’Œä»·å€¼

    def process_state(self, state):
        unknown_counter = 0
        for i in range(len(state)):
            if state[i] not in self.grammar_vocab:
                state[i] = "placeholder" + str(unknown_counter)
                unknown_counter += 1
        return state

    def policy_value_batch(self, seqs, states):
        for idx, seq in enumerate(seqs):
            seqs[idx] = torch.Tensor(seq).to(self.device)

        states_list = []
        for idx, state in enumerate(states):
            state_list = state.split(",")
            processed_state_list = self.process_state(state_list)
            state_idx = torch.Tensor([self.symbol2idx[item] for item in processed_state_list]).to(self.device)
            state_emb = self.pv_net.embedding_table(state_idx.long())
            states_list.append(state_emb)
        max_len = max(state.shape[0] for state in states_list)
        for idx, state in enumerate(states_list):
            if state.shape[0] < max_len:
                states_list[idx] = F.pad(state, (0, 0, 0, max_len - state.shape[0]), "constant", 0)

        states = torch.stack(states_list).to(self.device)
        seqs = torch.stack(seqs).to(self.device)
        raw_dist_out, value_out, profit_out = self.pv_net(seqs, states, False)
        return raw_dist_out, value_out, profit_out

    def update_grammar_vocab_name(self, aug_grammars):
        # Rebuild the vocabulary with the base and augmented grammars
        self.grammar_vocab = ['f->A'] + self.base_grammars + aug_grammars
        
        # Rebuild the symbol-to-index mapping
        self.symbol2idx = {symbol: idx for idx, symbol in enumerate(self.grammar_vocab)}
        
        # Re-initialize the network to resize the layers according to the new vocabulary size
        self.pv_net = PVNet(self.grammar_vocab, self.num_transplant).to(self.device)
        
        # ğŸ¯ é‡å»ºç½‘ç»œåæ¢å¤å˜ä½“æ¨¡å¼è®¾ç½®
        if hasattr(self, '_variant_mode'):
            self.pv_net._variant_mode = self._variant_mode
            print(f"DEBUG: Network rebuilt with variant mode: {self._variant_mode}")
        else:
            print(f"DEBUG: Network rebuilt without variant mode")
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä»ç¯å¢ƒå˜é‡æ¨æ–­å˜ä½“æ¨¡å¼
            import os
            if os.getenv('ABLATION_EXPERIMENT_MODE', '').lower() == 'true':
                print(f"DEBUG: Ablation mode detected but no variant mode set on PVNetCtx")
        
        print(f"DEBUG: Network rebuilt. New vocab size: {len(self.grammar_vocab)}, New policy output size: {self.pv_net.dist_out.out_features}")

    def reset_grammar_vocab_name(self):
        self.grammar_vocab = copy.deepcopy(self.grammar_vocab_backups)
