import pandas as pd
import numpy as np
# ä½¿ç”¨è‡ªå®šä¹‰æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
# import pandas_ta as ta
import os
from pathlib import Path

# ç¡®ä¿DATA_DIRæ˜¯ç›¸å¯¹äºŽé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[2]
DATA_DIR = PROJECT_ROOT / "data"

# ç»Ÿä¸€æ—¶é—´é…ç½®
def get_time_periods():
    """èŽ·å–ç»Ÿä¸€çš„æ—¶é—´é…ç½®"""
    return {
        'train': {'start': '2010-01-01', 'end': '2017-12-31'},
        'valid': {'start': '2018-01-01', 'end': '2019-12-31'},
        'test': {'start': '2020-01-01', 'end': '2022-12-12'}
    }

# ä¿ç•™æ—§é…ç½®ä½œä¸ºå¤‡ä»½ï¼ˆå·²å¼ƒç”¨ï¼‰
TRAIN_START_DATE = "2009-01-01"
TRAIN_END_DATE = "2020-12-31"
TEST_START_DATE = "2021-01-01"
TEST_END_DATE = "2023-12-31"

def load_real_stock_data(ticker: str, db_path: str = "stock.db", 
                        start_date: str = None, end_date: str = None) -> pd.DataFrame:
    """
    ä»Žæ•°æ®åº“åŠ è½½çœŸå®žè‚¡ç¥¨æ•°æ®ï¼Œé™åˆ¶åœ¨åˆç†çš„åŽ†å²æ—¶é—´èŒƒå›´å†…
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç  (e.g., 'AAPL')
        db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        start_date: å¼€å§‹æ—¥æœŸï¼Œé»˜è®¤ä½¿ç”¨TRAIN_START_DATE
        end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä½¿ç”¨2024-06-30 (é¿å…æœªæ¥æ•°æ®)
        
    Returns:
        pd.DataFrame: åŒ…å«è‚¡ç¥¨æ•°æ®çš„DataFrame
    """
    import sqlite3
    import os
    
    # è®¾ç½®é»˜è®¤çš„æ—¶é—´èŒƒå›´ - é¿å…ä½¿ç”¨æœªæ¥æ•°æ®
    if start_date is None:
        start_date = TRAIN_START_DATE  # "2009-01-01"
    if end_date is None:
        end_date = "2024-06-30"  # é¿å…ä½¿ç”¨æœªæ¥æ•°æ®
    
    # æž„å»ºæ•°æ®åº“è·¯å¾„
    if not os.path.isabs(db_path):
        # ç›¸å¯¹è·¯å¾„ï¼Œä»Žé¡¹ç›®æ ¹ç›®å½•å¼€å§‹
        project_root = Path(__file__).resolve().parents[2]
        db_path = project_root / db_path
    
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"Database file not found: {db_path}")
    
    # è¿žæŽ¥æ•°æ®åº“å¹¶æŸ¥è¯¢æ•°æ®
    conn = sqlite3.connect(db_path)
    
    query = """
    SELECT date, open, high, low, close, volume, 0 as amount 
    FROM stock_data 
    WHERE ticker = ? AND date >= ? AND date <= ?
    ORDER BY date
    """
    
    df = pd.read_sql_query(query, conn, params=(ticker, start_date, end_date))
    conn.close()
    
    if df.empty:
        raise ValueError(f"No data found for ticker: {ticker} in range {start_date} to {end_date}")
    
    # æ·»åŠ tickeråˆ—
    df['ticker'] = ticker
    
    # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
    df['date'] = pd.to_datetime(df['date'])
    
    print(f"ðŸ“Š åŠ è½½ {ticker} æ•°æ®: {len(df)} æ¡è®°å½•")
    print(f"ðŸ“… æ—¶é—´èŒƒå›´: {df['date'].min().date()} åˆ° {df['date'].max().date()}")
    
    return df


def load_and_preprocess_data(dataset_name: str, ticker: str) -> pd.DataFrame:
    """
    Loads a single stock's data, preprocesses it, and adds technical indicators.

    :param dataset_name: The name of the dataset directory (e.g., 'djia30').
    :param ticker: The stock ticker symbol (e.g., 'AAPL').
    :return: A pandas DataFrame with technical indicators.
    """
    # ä¼˜å…ˆå°è¯•ä»Žæ•°æ®åº“åŠ è½½çœŸå®žæ•°æ®
    try:
        df = load_real_stock_data(ticker)
        print(f"âœ… ä»Žæ•°æ®åº“åŠ è½½çœŸå®žè‚¡ç¥¨æ•°æ®: {ticker}")
    except (FileNotFoundError, ValueError) as e:
        print(f"âš ï¸  æ— æ³•ä»Žæ•°æ®åº“åŠ è½½ {ticker}: {e}")
        print(f"ðŸ”„ å°è¯•ä»ŽCSVæ–‡ä»¶åŠ è½½...")
        
        # å›žé€€åˆ°åŽŸæ¥çš„CSVæ–‡ä»¶åŠ è½½æ–¹å¼
        file_path = DATA_DIR / dataset_name / f"{ticker}.csv"
        if not file_path.exists():
            raise FileNotFoundError(f"Data file not found: {file_path}")
        df = pd.read_csv(file_path)

    # The finrl library expects date column to be named 'date'
    # and other columns to be in lowercase.
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    # ç¡®ä¿æ”¶ç›˜ä»·åˆ—å­˜åœ¨å¹¶ç»Ÿä¸€å‘½åä¸º 'close'
    close_col = None
    for col in df.columns:
        if 'close' in col.lower():  # åŒ¹é… 'close' æˆ– 'close_{ticker}'
            close_col = col
            break

    if close_col is None:
        raise ValueError(f"No close price column found for {ticker}")

    # é‡å‘½åæ”¶ç›˜ä»·åˆ—ä¸º 'close'
    df = df.rename(columns={close_col: 'close'})
    
    # éªŒè¯å…³é”®ä»·æ ¼åˆ—æ˜¯å¦å­˜åœ¨NaN
    if 'Close' in df.columns and df['Close'].isna().any():
        print(f"WARNING: {ticker} has {df['Close'].isna().sum()} NaN values in Close column")
    
    # å¯¹ä»·æ ¼åˆ—é‡‡ç”¨å‰å‘å¡«å……è€Œéžç®€å•å¡«0
    price_cols = ['Open', 'High', 'Low', 'Close']
    price_cols_lower = [col.lower() for col in price_cols]
    for col in price_cols:
        if col in df.columns and df[col].isna().any():
            # ä½¿ç”¨å‰å‘å¡«å……è€Œéžå¡«0ï¼Œä¿æŒä»·æ ¼è¿žç»­æ€§
            df[col] = df[col].fillna(method='ffill')
            # å¦‚æžœå‰å‘å¡«å……åŽä»æœ‰NaNï¼ˆé€šå¸¸æ˜¯å¼€å§‹å¤„ï¼‰ï¼Œä½¿ç”¨åŽå‘å¡«å……
            df[col] = df[col].fillna(method='bfill')
            # å¦‚æžœä»æœ‰NaNï¼Œè¯´æ˜Žæ•°æ®è´¨é‡æœ‰é—®é¢˜ï¼Œè®°å½•è­¦å‘Š
            if df[col].isna().any():
                print(f"WARNING: {ticker} still has {df[col].isna().sum()} NaN values in {col} after forward/backward filling")
    
    # å¯¹éžä»·æ ¼åˆ—ä½¿ç”¨æ›´å®‰å…¨çš„å¡«å……æ–¹å¼
    df.fillna(0, inplace=True)
    
    df = df.rename(columns={"Date": "date"})
    df.columns = [x.lower().strip() for x in df.columns]

    # Convert date column to datetime objects
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(by='date').reset_index(drop=True)

    # Add ticker column for multi-stock processing
    df['ticker'] = ticker



    return df

def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """
    Adds technical indicators to the dataframe.

    :param df: The input DataFrame with stock data.
    :return: DataFrame with added technical indicators.
    """
    df = df.copy()
    
    # MACDæŒ‡æ ‡
    ema_12 = df['close'].ewm(span=12).mean()
    ema_26 = df['close'].ewm(span=26).mean()
    df['macd_12_26_9'] = ema_12 - ema_26
    df['macds_12_26_9'] = df['macd_12_26_9'].ewm(span=9).mean()
    df['macdh_12_26_9'] = df['macd_12_26_9'] - df['macds_12_26_9']
    
    # RSIæŒ‡æ ‡
    def calculate_rsi(prices, window=14):
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    df['rsi_6'] = calculate_rsi(df['close'], 6)
    df['rsi_12'] = calculate_rsi(df['close'], 12)
    df['rsi_14'] = calculate_rsi(df['close'], 14)
    
    # ç§»åŠ¨å¹³å‡çº¿
    df['sma_20'] = df['close'].rolling(20).mean()
    df['sma_50'] = df['close'].rolling(50).mean()
    df['ema_20'] = df['close'].ewm(span=20).mean()
    
    # å¸ƒæž—å¸¦
    sma_20 = df['close'].rolling(20).mean()
    std_20 = df['close'].rolling(20).std()
    df['bb_upper'] = sma_20 + (std_20 * 2)
    df['bb_lower'] = sma_20 - (std_20 * 2)
    df['bb_middle'] = sma_20
    
    # ä»·æ ¼å˜åŒ–çŽ‡
    df['price_change'] = df['close'].pct_change()
    df['price_change_5'] = df['close'].pct_change(5)
    df['price_change_10'] = df['close'].pct_change(10)
    
    # æˆäº¤é‡æŒ‡æ ‡
    if 'volume' in df.columns:
        df['volume_sma_20'] = df['volume'].rolling(20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma_20']
    
    # æ³¢åŠ¨çŽ‡
    df['volatility_20'] = df['close'].rolling(20).std()
    
    # å¡«å……NaNå€¼
    df = df.ffill().bfill().fillna(0)
    
    return df

def get_split_data(df: pd.DataFrame):
    """
    Splits the data into training and testing sets.

    :param df: The full DataFrame.
    :return: A tuple of (train_df, test_df).
    """
    # ç¡®ä¿æ—¥æœŸåˆ—ç±»åž‹æ­£ç¡®
    if not pd.api.types.is_datetime64_any_dtype(df['date']):
        df['date'] = pd.to_datetime(df['date'])
    
    train_df = df[(df.date >= TRAIN_START_DATE) & (df.date <= TRAIN_END_DATE)]
    test_df = df[(df.date >= TEST_START_DATE) & (df.date <= TEST_END_DATE)]
    
    # å†æ¬¡éªŒè¯åˆ†å‰²åŽçš„æ•°æ®é›†æ˜¯å¦æœ‰ä»·æ ¼åˆ—çš„NaNå€¼
    price_cols = ['open', 'high', 'low', 'close']
    for col in price_cols:
        if col in train_df.columns:
            nan_count = train_df[col].isna().sum()
            if nan_count > 0:
                print(f"WARNING: Training set has {nan_count} NaN values in {col} column after split")
    
    return train_df, test_df

def run_vectorized_backtest(df, signal_col='signal'):
    """å‘é‡åŒ–å›žæµ‹å‡½æ•°"""
    signals = df[signal_col].values
    returns = df['close'].pct_change().fillna(0).values
    
    # è®¡ç®—ç­–ç•¥æ”¶ç›Š
    strategy_returns = signals[:-1] * returns[1:]  # ä¿¡å·æ»žåŽä¸€æœŸ
    
    # è®¡ç®—ç´¯ç§¯æ”¶ç›Š
    cumulative_returns = np.cumprod(1 + strategy_returns) - 1
    total_return = cumulative_returns[-1] if len(cumulative_returns) > 0 else 0
    
    # è®¡ç®—å¹´åŒ–æ”¶ç›ŠçŽ‡
    if len(strategy_returns) > 0:
        # å‡è®¾æ•°æ®æ˜¯æ—¥é¢‘ï¼Œä¸€å¹´252ä¸ªäº¤æ˜“æ—¥
        trading_days = len(strategy_returns)
        years = trading_days / 252
        annualized_return = (1 + total_return) ** (1/years) - 1 if years > 0 else 0
    else:
        annualized_return = 0
    
    # è®¡ç®—å¤æ™®æ¯”çŽ‡
    if len(strategy_returns) > 0 and np.std(strategy_returns) > 0:
        sharpe_ratio = np.mean(strategy_returns) / np.std(strategy_returns) * np.sqrt(252)
    else:
        sharpe_ratio = 0
    
    # è®¡ç®—æœ€å¤§å›žæ’¤
    cumulative_curve = np.cumprod(1 + strategy_returns)
    running_max = np.maximum.accumulate(cumulative_curve)
    drawdown = (cumulative_curve - running_max) / running_max
    max_drawdown = np.min(drawdown) if len(drawdown) > 0 else 0
    
    metrics = pd.Series({
        'total_return': total_return,
        'annualized_return': annualized_return,
        'sharpe_ratio': sharpe_ratio,
        'max_drawdown': abs(max_drawdown),
        'num_trades': np.sum(np.abs(np.diff(signals)))
    })
    
    backtest_results = df.copy()
    backtest_results['strategy_return'] = np.concatenate([[0], strategy_returns])
    backtest_results['cumulative_return'] = np.concatenate([[0], cumulative_returns])
    
    return metrics, backtest_results


if __name__ == '__main__':
    # Example usage:
    print("Testing data_utils.py...")
    try:
        # 1. Load data for a sample stock
        aapl_df = load_and_preprocess_data('djia30', 'AAPL')
        print("\nLoaded AAPL data:")
        print(aapl_df.head())

        # 2. Add technical indicators
        aapl_tech_df = add_technical_indicators(aapl_df)
        print("\nAAPL data with technical indicators:")
        print(aapl_tech_df.head())
        print("\nColumns:", aapl_tech_df.columns.tolist())

        # 3. Split data
        train_data, test_data = get_split_data(aapl_tech_df)
        print(f"\nTraining data shape: {train_data.shape}")
        print(f"Testing data shape: {test_data.shape}")
        print("\nScript executed successfully.")

    except Exception as e:
        print(f"An error occurred: {e}")


def load_csv_stock_data(ticker: str):
    """
    ä»ŽCSVæ–‡ä»¶åŠ è½½è‚¡ç¥¨æ•°æ®
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        
    Returns:
        pd.DataFrame: åŒ…å«è‚¡ç¥¨æ•°æ®çš„DataFrame
    """
    import os
    from pathlib import Path
    
    # CSVæ–‡ä»¶è·¯å¾„ - ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„dataæ–‡ä»¶å¤¹
    project_root = Path(__file__).resolve().parents[3]
    csv_path = project_root / "data" / f"{ticker}.csv"
    
    if not csv_path.exists():
        raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
    
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_path)
    
    # æ ‡å‡†åŒ–åˆ—å
    column_mapping = {
        'Date': 'date',
        'Open': 'open',
        'High': 'high',
        'Low': 'low',
        'Close': 'close',
        'Volume': 'volume',
        'Adj Close': 'adj_close'
    }
    
    # é‡å‘½ååˆ—
    df = df.rename(columns=column_mapping)
    
    # ç¡®ä¿dateåˆ—æ˜¯datetimeç±»åž‹ï¼Œå¤„ç†DD-MM-YYYYæ ¼å¼
    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y', errors='coerce')
    
    # å¦‚æžœä¸Šé¢å¤±è´¥ï¼Œå°è¯•å…¶ä»–å¸¸è§æ ¼å¼
    if df['date'].isna().any():
        df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')
    
    # ç¡®ä¿æ•°å€¼åˆ—æ˜¯floatç±»åž‹
    numeric_columns = ['open', 'high', 'low', 'close', 'volume']
    if 'adj_close' in df.columns:
        numeric_columns.append('adj_close')
    
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # åˆ é™¤åŒ…å«NaNçš„è¡Œ
    df = df.dropna()
    
    # æŒ‰æ—¥æœŸæŽ’åº
    df = df.sort_values('date').reset_index(drop=True)
    
    # æ·»åŠ tickeråˆ—
    df['ticker'] = ticker
    
    # éªŒè¯å¿…è¦çš„åˆ—å­˜åœ¨
    required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
    
    print(f"âœ… CSVæ•°æ®åŠ è½½å®Œæˆ - {ticker}: {len(df)} æ¡è®°å½•ï¼Œæ—¶é—´èŒƒå›´: {df['date'].min()} åˆ° {df['date'].max()}")
    
    return df

def load_data_with_unified_split(ticker: str, data_source='csv'):
    """
    ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®åŠ è½½å’Œåˆ’åˆ†æ•°æ®
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        data_source: æ•°æ®æºç±»åž‹ ('csv' æˆ– 'db')
        
    Returns:
        tuple: (train_data, valid_data, test_data)
    """
    if data_source == 'csv':
        df = load_csv_stock_data(ticker)
    else:
        df = load_real_stock_data(ticker)

    # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
    df = add_technical_indicators(df)

    # ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®è¿›è¡Œæ•°æ®åˆ’åˆ†
    time_config = get_time_periods()
    df['date'] = pd.to_datetime(df['date'])
    
    train_data = df[(df['date'] >= time_config['train']['start']) & (df['date'] <= time_config['train']['end'])].copy()
    valid_data = df[(df['date'] >= time_config['valid']['start']) & (df['date'] <= time_config['valid']['end'])].copy()
    test_data = df[(df['date'] >= time_config['test']['start']) & (df['date'] <= time_config['test']['end'])].copy()

    print(f"æ•°æ®åˆ’åˆ†å®Œæˆ - {ticker}:")
    print(f"  è®­ç»ƒé›†: {len(train_data)} æ¡è®°å½• ({train_data['date'].min()} åˆ° {train_data['date'].max()})")
    print(f"  éªŒè¯é›†: {len(valid_data)} æ¡è®°å½• ({valid_data['date'].min()} åˆ° {valid_data['date'].max()})")
    print(f"  æµ‹è¯•é›†: {len(test_data)} æ¡è®°å½• ({test_data['date'].min()} åˆ° {test_data['date'].max()})")

    return train_data, valid_data, test_data

def get_unified_test_data(ticker: str, data_source='csv'):
    """
    èŽ·å–ç»Ÿä¸€æµ‹è¯•æœŸæ•°æ®
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        data_source: æ•°æ®æºç±»åž‹ ('csv' æˆ– 'db')
        
    Returns:
        pd.DataFrame: æµ‹è¯•æœŸæ•°æ®
    """
    if data_source == 'csv':
        df = load_csv_stock_data(ticker)
    else:
        df = load_real_stock_data(ticker)
    
    # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
    df = add_technical_indicators(df)
    
    # èŽ·å–æµ‹è¯•æœŸæ•°æ®
    test_data = get_test_data(df)
    
    print(f"âœ… ç»Ÿä¸€æµ‹è¯•æ•°æ®åŠ è½½å®Œæˆ: {len(test_data)} æ¡è®°å½•ï¼Œæ—¶é—´èŒƒå›´: {test_data['date'].min()} åˆ° {test_data['date'].max()}")
    
    return test_data

