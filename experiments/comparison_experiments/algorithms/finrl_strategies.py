"""

FinRLå®˜æ–¹ä»“åº“: https://github.com/AI4Finance-Foundation/FinRL
FinRLè®ºæ–‡: "FinRL: Deep Reinforcement Learning Framework to Automate Trading in Quantitative Finance"
"""

import os
import sys
import warnings
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
import logging
from datetime import datetime, timedelta

# æ­»é”é˜²æŠ¤ - è®¾ç½®çº¿ç¨‹æ•°ä¸º1
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # ç¦ç”¨GPUé¿å…CUDAæ­»é”
os.environ['PYTHONUNBUFFERED'] = '1'
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
os.environ['MKL_THREADING_LAYER'] = 'sequential'
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'

# ç¦ç”¨ä¸å¿…è¦çš„è­¦å‘Šï¼Œä½†ä¿ç•™é‡è¦é”™è¯¯ä¿¡æ¯
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

try:
    # FinRLæ ¸å¿ƒæ¨¡å—
    import finrl
    from finrl import config
    from finrl.config import INDICATORS
    from finrl.config_tickers import DOW_30_TICKER
    
    # FinRLç¯å¢ƒå’Œé¢„å¤„ç†
    from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv
    from finrl.meta.preprocessor.yahoodownloader import YahooDownloader
    from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split
    
    # FinRLæ™ºèƒ½ä½“
    from finrl.agents.stablebaselines3.models import DRLAgent
    from finrl.meta.data_processor import DataProcessor
    
    # Stable Baselines3 (FinRLçš„æ ¸å¿ƒä¾èµ–)
    from stable_baselines3 import PPO, A2C, DDPG, SAC, TD3
    from stable_baselines3.common.vec_env import DummyVecEnv
    from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise
    from stable_baselines3.common.callbacks import BaseCallback
    
    print("âœ… FinRLåŸç‰ˆæ¡†æ¶å¯¼å…¥æˆåŠŸ")
    try:
        print(f"ğŸ“¦ FinRLç‰ˆæœ¬: {finrl.__version__}")
    except AttributeError:
        print("ğŸ“¦ FinRLç‰ˆæœ¬: å·²å®‰è£… (ç‰ˆæœ¬ä¿¡æ¯ä¸å¯ç”¨)")
    
    # è®¾ç½®PyTorchçº¿ç¨‹æ•°é˜²æ­¢æ­»é”
    try:
        import torch
        torch.set_num_threads(1)
        print("ğŸ”’ PyTorchçº¿ç¨‹æ•°å·²è®¾ç½®ä¸º1 (é˜²æ­»é”)")
    except ImportError:
        pass
    
except ImportError as e:
    print("âŒ FinRLåŸç‰ˆæ¡†æ¶å¯¼å…¥å¤±è´¥ï¼")
    print(f"é”™è¯¯è¯¦æƒ…: {e}")
    print("\nğŸ”§ è§£å†³æ–¹æ¡ˆ:")
    print("1. å®‰è£…FinRL: pip install finrl")
    print("2. å®‰è£…ä¾èµ–: pip install stable-baselines3[extra]")
    print("3. å®‰è£…æ•°æ®æº: pip install yfinance")
    print("4. æ£€æŸ¥Pythonç‰ˆæœ¬ >= 3.8")
    raise ImportError("FinRLåŸç‰ˆæ¡†æ¶æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…FinRLåŠå…¶ä¾èµ–")


class AuthenticFinRLConfig:
    """FinRLåŸç‰ˆé…ç½® - ä½¿ç”¨å®˜æ–¹æ¨èå‚æ•°"""
    
    def __init__(self):
        # FinRLå®˜æ–¹æ¨èçš„æŠ€æœ¯æŒ‡æ ‡
        self.TECHNICAL_INDICATORS = [
            'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 
            'dx_30', 'close_30_sma', 'close_60_sma'
        ]
        
        # FinRLå®˜æ–¹ç¯å¢ƒå‚æ•°
        self.ENV_PARAMS = {
            "hmax": 100,                    # æœ€å¤§æŒä»“é‡
            "initial_amount": 1000000,      # åˆå§‹èµ„é‡‘
            "buy_cost_pct": 0.001,          # ä¹°å…¥æ‰‹ç»­è´¹
            "sell_cost_pct": 0.001,         # å–å‡ºæ‰‹ç»­è´¹
            "reward_scaling": 1e-4,         # å¥–åŠ±ç¼©æ”¾
            "print_verbosity": 5            # æ—¥å¿—è¯¦ç»†ç¨‹åº¦
        }
        
        # FinRLå®˜æ–¹ç®—æ³•å‚æ•°
        self.ALGORITHM_PARAMS = {
            'PPO': {
                'n_steps': 2048,
                'ent_coef': 0.01,
                'learning_rate': 0.00025,
                'batch_size': 128,
                'gamma': 0.99,
                'gae_lambda': 0.95,
                'clip_range': 0.2,
                'max_grad_norm': 0.5
            },
            'A2C': {
                'learning_rate': 0.0007,
                'n_steps': 5,
                'gamma': 0.99,
                'gae_lambda': 1.0,
                'ent_coef': 0.01,
                'vf_coef': 0.25,
                'max_grad_norm': 0.5
            },
            'SAC': {
                'learning_rate': 0.0003,
                'buffer_size': 100000,
                'learning_starts': 100,
                'batch_size': 256,
                'tau': 0.005,
                'gamma': 0.99,
                'train_freq': 1,
                'gradient_steps': 1,
                'ent_coef': 'auto'
            },
            'TD3': {
                'learning_rate': 0.001,
                'buffer_size': 1000000,
                'learning_starts': 25000,
                'batch_size': 100,
                'tau': 0.005,
                'gamma': 0.99,
                'train_freq': (1, "episode"),
                'gradient_steps': -1,
                'policy_delay': 2,
                'target_policy_noise': 0.2,
                'target_noise_clip': 0.5
            },
            'DDPG': {
                'learning_rate': 0.001,
                'buffer_size': 1000000,
                'learning_starts': 100,
                'batch_size': 100,
                'tau': 0.005,
                'gamma': 0.99,
                'train_freq': (1, "episode"),
                'gradient_steps': -1
            }
        }


class AuthenticFinRLDataProcessor:
    """FinRLåŸç‰ˆæ•°æ®å¤„ç†å™¨ - ä½¿ç”¨å®˜æ–¹æ•°æ®å¤„ç†æµç¨‹"""
    
    def __init__(self):
        self.config = AuthenticFinRLConfig()
        
    def prepare_data(self, df: pd.DataFrame, ticker: str, 
                    start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """ä½¿ç”¨FinRLå®˜æ–¹æ•°æ®å¤„ç†æµç¨‹"""
        
        print(f"ğŸ“Š ä½¿ç”¨FinRLåŸç‰ˆæ•°æ®å¤„ç†å™¨å¤„ç† {ticker} æ•°æ®...")
        
        # 1. æ•°æ®æ ¼å¼æ ‡å‡†åŒ– - ä¸¥æ ¼æŒ‰ç…§FinRLè¦æ±‚
        processed_df = self._standardize_data_format(df, ticker)
        
        # 2. ä½¿ç”¨FinRLå®˜æ–¹ç‰¹å¾å·¥ç¨‹
        processed_df = self._apply_finrl_feature_engineering(processed_df)
        
        # 3. æ•°æ®éªŒè¯ - ç¡®ä¿ç¬¦åˆFinRLæ ‡å‡†
        self._validate_finrl_data(processed_df)
        
        print(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæœ€ç»ˆæ•°æ®å½¢çŠ¶: {processed_df.shape}")
        return processed_df
    
    def _standardize_data_format(self, df: pd.DataFrame, ticker: str) -> pd.DataFrame:
        """æ ‡å‡†åŒ–ä¸ºFinRLæ ¼å¼"""
        
        finrl_df = df.copy()
        
        # ç¡®ä¿å¿…éœ€åˆ—å­˜åœ¨
        required_columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'tic']
        
        # å¤„ç†æ—¥æœŸåˆ—
        if 'date' not in finrl_df.columns:
            if isinstance(finrl_df.index, pd.DatetimeIndex):
                finrl_df.reset_index(inplace=True)
                finrl_df.rename(columns={'index': 'date'}, inplace=True)
            else:
                raise ValueError("æ•°æ®å¿…é¡»åŒ…å«æ—¥æœŸä¿¡æ¯")
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        finrl_df['date'] = pd.to_datetime(finrl_df['date'])
        
        # æ·»åŠ è‚¡ç¥¨ä»£ç 
        finrl_df['tic'] = ticker
        
        # éªŒè¯OHLCVæ•°æ®å®Œæ•´æ€§
        ohlcv_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in ohlcv_columns:
            if col not in finrl_df.columns:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„åˆ—: {col}")
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        if finrl_df[ohlcv_columns].isnull().any().any():
            raise ValueError("OHLCVæ•°æ®åŒ…å«ç¼ºå¤±å€¼")
        
        # ç¡®ä¿ä»·æ ¼æ•°æ®çš„é€»è¾‘ä¸€è‡´æ€§
        invalid_rows = (finrl_df['high'] < finrl_df['low']) | \
                      (finrl_df['high'] < finrl_df['close']) | \
                      (finrl_df['low'] > finrl_df['close'])
        
        if invalid_rows.any():
            print(f"âš ï¸ å‘ç° {invalid_rows.sum()} è¡Œä»·æ ¼æ•°æ®ä¸ä¸€è‡´ï¼Œå·²ä¿®æ­£")
            # ä¿®æ­£ä¸ä¸€è‡´çš„æ•°æ®
            finrl_df.loc[invalid_rows, 'high'] = finrl_df.loc[invalid_rows, ['open', 'close']].max(axis=1)
            finrl_df.loc[invalid_rows, 'low'] = finrl_df.loc[invalid_rows, ['open', 'close']].min(axis=1)
        
        # æŒ‰FinRLè¦æ±‚æ’åº
        finrl_df = finrl_df.sort_values(['date', 'tic']).reset_index(drop=True)
        
        return finrl_df[required_columns]
    
    def _apply_finrl_feature_engineering(self, df: pd.DataFrame) -> pd.DataFrame:
        """åº”ç”¨FinRLå®˜æ–¹ç‰¹å¾å·¥ç¨‹"""
        
        print("ğŸ”§ åº”ç”¨FinRLå®˜æ–¹ç‰¹å¾å·¥ç¨‹...")
        
        # ä½¿ç”¨FinRLå®˜æ–¹FeatureEngineer
        fe = FeatureEngineer(
            use_technical_indicator=True,
            tech_indicator_list=self.config.TECHNICAL_INDICATORS,
            use_vix=False,  # å•è‚¡ç¥¨ä¸ä½¿ç”¨VIX
            use_turbulence=False,  # å•è‚¡ç¥¨ä¸ä½¿ç”¨turbulence
            user_defined_feature=False
        )
        
        # åº”ç”¨ç‰¹å¾å·¥ç¨‹
        processed_df = fe.preprocess_data(df)
        
        print(f"ğŸ“ˆ æ·»åŠ äº† {len(self.config.TECHNICAL_INDICATORS)} ä¸ªæŠ€æœ¯æŒ‡æ ‡")
        return processed_df
    
    def _validate_finrl_data(self, df: pd.DataFrame):
        """éªŒè¯æ•°æ®æ˜¯å¦ç¬¦åˆFinRLæ ‡å‡†"""
        
        # æ£€æŸ¥å¿…éœ€åˆ—
        required_cols = ['date', 'open', 'high', 'low', 'close', 'volume', 'tic']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"ç¼ºå°‘FinRLå¿…éœ€åˆ—: {missing_cols}")
        
        # æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡
        for indicator in self.config.TECHNICAL_INDICATORS:
            if indicator not in df.columns:
                raise ValueError(f"ç¼ºå°‘æŠ€æœ¯æŒ‡æ ‡: {indicator}")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if df.isnull().any().any():
            null_cols = df.columns[df.isnull().any()].tolist()
            raise ValueError(f"æ•°æ®åŒ…å«ç¼ºå¤±å€¼: {null_cols}")
        
        print("âœ… æ•°æ®éªŒè¯é€šè¿‡ï¼Œç¬¦åˆFinRLæ ‡å‡†")


class AuthenticFinRLAgent:
    """FinRLåŸç‰ˆæ™ºèƒ½ä½“ - ä½¿ç”¨å®˜æ–¹DRLAgent"""
    
    def __init__(self, algorithm: str = 'PPO'):
        self.algorithm = algorithm
        self.config = AuthenticFinRLConfig()
        self.model = None
        self.env = None
        
        if algorithm not in self.config.ALGORITHM_PARAMS:
            raise ValueError(f"ä¸æ”¯æŒçš„ç®—æ³•: {algorithm}")
    
    def create_environment(self, df: pd.DataFrame) -> DummyVecEnv:
        """åˆ›å»ºFinRLå®˜æ–¹äº¤æ˜“ç¯å¢ƒ"""
        
        print(f"ğŸ—ï¸ åˆ›å»ºFinRLå®˜æ–¹äº¤æ˜“ç¯å¢ƒ...")
        
        # è®¡ç®—çŠ¶æ€ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´
        stock_dimension = len(df.tic.unique())
        state_space = 1 + 2 * stock_dimension + len(self.config.TECHNICAL_INDICATORS) * stock_dimension
        action_space = stock_dimension
        
        # ä½¿ç”¨FinRLå®˜æ–¹ç¯å¢ƒå‚æ•°
        env_kwargs = {
            "hmax": self.config.ENV_PARAMS["hmax"],
            "initial_amount": self.config.ENV_PARAMS["initial_amount"],
            "num_stock_shares": [0] * stock_dimension,  # åˆå§‹æŒè‚¡æ•°é‡
            "buy_cost_pct": [self.config.ENV_PARAMS["buy_cost_pct"]] * stock_dimension,
            "sell_cost_pct": [self.config.ENV_PARAMS["sell_cost_pct"]] * stock_dimension,
            "reward_scaling": self.config.ENV_PARAMS["reward_scaling"],
            "state_space": state_space,
            "action_space": action_space,
            "tech_indicator_list": self.config.TECHNICAL_INDICATORS,
            "print_verbosity": self.config.ENV_PARAMS["print_verbosity"],
            "stock_dim": stock_dimension  # æ·»åŠ ç¼ºå¤±çš„stock_dimå‚æ•°
        }
        
        # åˆ›å»ºFinRLå®˜æ–¹ç¯å¢ƒ
        env = StockTradingEnv(df=df, **env_kwargs)
        
        # åŒ…è£…ä¸ºå‘é‡åŒ–ç¯å¢ƒ
        env = DummyVecEnv([lambda: env])
        
        print(f"âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ - çŠ¶æ€ç©ºé—´: {state_space}, åŠ¨ä½œç©ºé—´: {action_space}")
        
        self.env = env
        return env
    
    def train(self, env: DummyVecEnv, total_timesteps: int = 50000) -> Any:
        """ä½¿ç”¨FinRLå®˜æ–¹è®­ç»ƒæµç¨‹"""
        
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒFinRL {self.algorithm} æ¨¡å‹...")
        
        # è·å–ç®—æ³•å‚æ•°
        algo_params = self.config.ALGORITHM_PARAMS[self.algorithm].copy()
        
        # åˆ›å»ºæ¨¡å‹
        if self.algorithm == 'PPO':
            model = PPO("MlpPolicy", env, verbose=0, **algo_params)
        elif self.algorithm == 'A2C':
            model = A2C("MlpPolicy", env, verbose=0, **algo_params)
        elif self.algorithm == 'SAC':
            # SACé€šå¸¸éœ€è¦æ›´å¤šè®­ç»ƒæ­¥æ•°
            model = SAC("MlpPolicy", env, verbose=0, **algo_params)
        elif self.algorithm == 'TD3':
            # TD3éœ€è¦å™ªå£°
            n_actions = env.action_space.shape[-1]
            action_noise = NormalActionNoise(
                mean=np.zeros(n_actions), 
                sigma=0.1 * np.ones(n_actions)
            )
            model = TD3("MlpPolicy", env, action_noise=action_noise, verbose=0, **algo_params)
        elif self.algorithm == 'DDPG':
            # DDPGéœ€è¦å™ªå£°
            n_actions = env.action_space.shape[-1]
            action_noise = OrnsteinUhlenbeckActionNoise(
                mean=np.zeros(n_actions),
                sigma=0.1 * np.ones(n_actions)
            )
            model = DDPG("MlpPolicy", env, action_noise=action_noise, verbose=0, **algo_params)
        
        # è®­ç»ƒæ¨¡å‹
        model.learn(total_timesteps=total_timesteps)
        
        print(f"âœ… {self.algorithm} æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        self.model = model
        return model
    
    def backtest(self, test_env: DummyVecEnv, test_df: pd.DataFrame = None) -> Tuple[pd.Series, pd.DataFrame]:
        """ä½¿ç”¨FinRLå®˜æ–¹å›æµ‹æµç¨‹"""
        
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train()æ–¹æ³•")
        
        print(f"ğŸ“Š å¼€å§‹FinRL {self.algorithm} å›æµ‹...")
        
        # é‡ç½®ç¯å¢ƒ
        obs = test_env.reset()
        
        # å­˜å‚¨å›æµ‹ç»“æœ
        portfolio_values = []
        actions_taken = []
        dates = []
        
        done = False
        step_count = 0
        
        # è®°å½•åˆå§‹èµ„äº§ä»·å€¼
        if hasattr(test_env.envs[0], 'asset_memory') and test_env.envs[0].asset_memory:
            initial_value = test_env.envs[0].asset_memory[-1]
            portfolio_values.append(initial_value)
            actions_taken.append(0)  # åˆå§‹åŠ¨ä½œä¸º0
            dates.append(0)
        
        while not done:
            # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹åŠ¨ä½œ
            action, _states = self.model.predict(obs, deterministic=True)
            
            # æ‰§è¡ŒåŠ¨ä½œ
            obs, rewards, done, info = test_env.step(action)
            
            # åœ¨æ‰§è¡ŒåŠ¨ä½œåè®°å½•èµ„äº§ä»·å€¼
            if hasattr(test_env.envs[0], 'asset_memory') and test_env.envs[0].asset_memory:
                portfolio_value = test_env.envs[0].asset_memory[-1]
                portfolio_values.append(portfolio_value)
                actions_taken.append(action[0] if isinstance(action, np.ndarray) else action)
                
                # è®°å½•æ—¥æœŸ
                if hasattr(test_env.envs[0], 'date'):
                    dates.append(test_env.envs[0].date)
                else:
                    dates.append(step_count + 1)
            
            step_count += 1
            
            # é˜²æ­¢æ— é™å¾ªç¯
            if step_count > 10000:
                print("âš ï¸ å›æµ‹æ­¥æ•°è¶…è¿‡é™åˆ¶ï¼Œå¼ºåˆ¶ç»“æŸ")
                break
        
        if not portfolio_values:
            raise ValueError("å›æµ‹è¿‡ç¨‹ä¸­æœªæ”¶é›†åˆ°æœ‰æ•ˆæ•°æ®")
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯: æ”¶é›†åˆ° {len(portfolio_values)} ä¸ªèµ„äº§ä»·å€¼")
        if len(portfolio_values) > 0:
            print(f"ğŸ” åˆå§‹èµ„äº§: {portfolio_values[0]:.2f}")
            print(f"ğŸ” æœ€ç»ˆèµ„äº§: {portfolio_values[-1]:.2f}")
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        if len(portfolio_values) < 2:
            print("âš ï¸ èµ„äº§ä»·å€¼æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            returns = pd.Series([0])
            total_return = 0
            annualized_return = 0
        else:
            # æ£€æŸ¥èµ„äº§ä»·å€¼æ˜¯å¦å®Œå…¨æ²¡æœ‰å˜åŒ–
            unique_values = set(portfolio_values)
            if len(unique_values) == 1:
                print("âš ï¸ æ£€æµ‹åˆ°èµ„äº§ä»·å€¼å®Œå…¨æ²¡æœ‰å˜åŒ–ï¼Œå¯èƒ½æ˜¯FinRLç¯å¢ƒé—®é¢˜")
                print(f"ğŸ” æ‰€æœ‰èµ„äº§ä»·å€¼éƒ½æ˜¯: {portfolio_values[0]:.2f}")
                returns = pd.Series([0])
                total_return = 0
                annualized_return = 0
                final_portfolio_value = portfolio_values[0]
            else:
                # æ£€æŸ¥æœ€åä¸€ä¸ªå€¼æ˜¯å¦è¢«é‡ç½®ä¸ºåˆå§‹å€¼
                if len(portfolio_values) > 2 and portfolio_values[-1] == portfolio_values[0]:
                    print("âš ï¸ æ£€æµ‹åˆ°ç¯å¢ƒé‡ç½®ï¼Œä½¿ç”¨å€’æ•°ç¬¬äºŒä¸ªå€¼ä½œä¸ºæœ€ç»ˆèµ„äº§")
                    final_portfolio_value = portfolio_values[-2]
                    # ç§»é™¤æœ€åä¸€ä¸ªé‡ç½®å€¼
                    portfolio_values = portfolio_values[:-1]
                else:
                    final_portfolio_value = portfolio_values[-1]
            
                returns = pd.Series(portfolio_values).pct_change().dropna()
                
                # å¹´åŒ–æ”¶ç›Šç‡ - ä½¿ç”¨ä¿®æ­£åçš„æœ€ç»ˆä»·å€¼
                total_return = (final_portfolio_value / portfolio_values[0]) - 1
                trading_days = len(portfolio_values)
                if trading_days > 1:
                    annualized_return = (1 + total_return) ** (252 / trading_days) - 1
                else:
                    annualized_return = total_return
            
            print(f"ğŸ” æ”¶ç›Šè®¡ç®—: åˆå§‹={portfolio_values[0]:.2f}, æœ€ç»ˆ={final_portfolio_value:.2f}")
            print(f"ğŸ” æ€»æ”¶ç›Š: {total_return:.4f} ({total_return*100:.2f}%)")
            print(f"ğŸ” å¹´åŒ–æ”¶ç›Š: {annualized_return:.4f} ({annualized_return*100:.2f}%)")
        
        # å…¶ä»–æŒ‡æ ‡
        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0
        max_drawdown = self._calculate_max_drawdown(portfolio_values)
        volatility = returns.std() * np.sqrt(252)
        
        # åˆ›å»ºæŒ‡æ ‡Series
        metrics = pd.Series({
            'annualized_return': annualized_return,
            'total_return': total_return,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'volatility': volatility,
            'num_trades': len([a for a in actions_taken if np.abs(a).sum() > 0.01]),
            'final_portfolio_value': final_portfolio_value if 'final_portfolio_value' in locals() else portfolio_values[-1],
            'algorithm': self.algorithm
        })
        
        # åˆ›å»ºå›æµ‹ç»“æœDataFrame - ç¡®ä¿é•¿åº¦ä¸€è‡´
        if test_df is not None:
            min_length = min(len(test_df), len(portfolio_values), len(actions_taken))
            date_index = test_df.index[:min_length]
        else:
            min_length = min(len(portfolio_values), len(actions_taken))
            date_index = range(min_length)
            
        backtest_results = pd.DataFrame({
            'date': date_index,
            'portfolio_value': portfolio_values[:min_length],
            'returns': returns[:min_length] if len(returns) >= min_length else [0] * min_length,
            'actions': actions_taken[:min_length]
        })
        
        print(f"âœ… å›æµ‹å®Œæˆ - å¹´åŒ–æ”¶ç›Š: {annualized_return:.2%}, å¤æ™®æ¯”ç‡: {sharpe_ratio:.3f}")
        
        return metrics, backtest_results
    
    def _calculate_max_drawdown(self, portfolio_values: List[float]) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        peak = portfolio_values[0]
        max_dd = 0
        
        for value in portfolio_values:
            if value > peak:
                peak = value
            dd = (peak - value) / peak
            if dd > max_dd:
                max_dd = dd
        
        return max_dd


class AuthenticFinRLRunner:
    """FinRLåŸç‰ˆè¿è¡Œå™¨ - å®Œæ•´çš„FinRLå·¥ä½œæµç¨‹"""
    
    def __init__(self):
        self.data_processor = AuthenticFinRLDataProcessor()
        self.supported_algorithms = ['PPO', 'A2C', 'SAC', 'TD3', 'DDPG']
    
    def run_finrl_strategy(self, algorithm: str, train_df: pd.DataFrame, 
                          test_df: pd.DataFrame, ticker: str = 'STOCK',
                          total_timesteps: int = 50000,
                          **kwargs) -> Tuple[pd.Series, pd.DataFrame]:
        """è¿è¡Œå®Œæ•´çš„FinRLç­–ç•¥ - ä½¿ç”¨åŸç‰ˆæ¡†æ¶"""
        
        if algorithm.upper() not in self.supported_algorithms:
            raise ValueError(f"ä¸æ”¯æŒçš„ç®—æ³•: {algorithm}. æ”¯æŒçš„ç®—æ³•: {self.supported_algorithms}")
        
        algorithm = algorithm.upper()
        print(f"ğŸš€ è¿è¡ŒFinRLåŸç‰ˆ {algorithm} ç­–ç•¥ - è‚¡ç¥¨: {ticker}")
        
        try:
            # 1. æ•°æ®é¢„å¤„ç† - ä½¿ç”¨FinRLå®˜æ–¹æµç¨‹
            print("ğŸ“Š æ­¥éª¤1: æ•°æ®é¢„å¤„ç†...")
            train_processed = self.data_processor.prepare_data(train_df, ticker)
            test_processed = self.data_processor.prepare_data(test_df, ticker)
            
            # 2. åˆ›å»ºæ™ºèƒ½ä½“
            print("ğŸ¤– æ­¥éª¤2: åˆ›å»ºFinRLæ™ºèƒ½ä½“...")
            agent = AuthenticFinRLAgent(algorithm)
            
            # 3. åˆ›å»ºè®­ç»ƒç¯å¢ƒ
            print("ğŸ—ï¸ æ­¥éª¤3: åˆ›å»ºè®­ç»ƒç¯å¢ƒ...")
            train_env = agent.create_environment(train_processed)
            
            # 4. è®­ç»ƒæ¨¡å‹
            print("ğŸš€ æ­¥éª¤4: è®­ç»ƒæ¨¡å‹...")
            model = agent.train(train_env, total_timesteps)
            
            # 5. åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
            print("ğŸ§ª æ­¥éª¤5: åˆ›å»ºæµ‹è¯•ç¯å¢ƒ...")
            test_env = agent.create_environment(test_processed)
            
            # 6. å›æµ‹
            print("ğŸ“Š æ­¥éª¤6: æ‰§è¡Œå›æµ‹...")
            metrics, backtest_results = agent.backtest(test_env, test_df)
            
            print(f"âœ… FinRL {algorithm} ç­–ç•¥æ‰§è¡Œå®Œæˆ!")
            return metrics, backtest_results
            
        except Exception as e:
            print(f"âŒ FinRL {algorithm} ç­–ç•¥æ‰§è¡Œå¤±è´¥: {e}")
            raise


# å…¨å±€FinRLè¿è¡Œå™¨å®ä¾‹
authentic_finrl_runner = AuthenticFinRLRunner()

# å¯¼å‡ºå‡½æ•° - ä¸baseline.pyå…¼å®¹
def run_finrl_ppo_strategy(train_df: pd.DataFrame, test_df: pd.DataFrame, 
                          ticker: str = 'STOCK', **kwargs) -> Tuple[pd.Series, pd.DataFrame]:
    """FinRLåŸç‰ˆPPOç­–ç•¥"""
    return authentic_finrl_runner.run_finrl_strategy('PPO', train_df, test_df, ticker, **kwargs)

def run_finrl_a2c_strategy(train_df: pd.DataFrame, test_df: pd.DataFrame, 
                          ticker: str = 'STOCK', **kwargs) -> Tuple[pd.Series, pd.DataFrame]:
    """FinRLåŸç‰ˆA2Cç­–ç•¥"""
    return authentic_finrl_runner.run_finrl_strategy('A2C', train_df, test_df, ticker, **kwargs)

def run_finrl_sac_strategy(train_df: pd.DataFrame, test_df: pd.DataFrame, 
                          ticker: str = 'STOCK', **kwargs) -> Tuple[pd.Series, pd.DataFrame]:
    """FinRLåŸç‰ˆSACç­–ç•¥"""
    # SACéœ€è¦æ›´å¤šè®­ç»ƒæ­¥æ•°
    kwargs.setdefault('total_timesteps', 100000)
    return authentic_finrl_runner.run_finrl_strategy('SAC', train_df, test_df, ticker, **kwargs)

def run_finrl_td3_strategy(train_df: pd.DataFrame, test_df: pd.DataFrame, 
                          ticker: str = 'STOCK', **kwargs) -> Tuple[pd.Series, pd.DataFrame]:
    """FinRLåŸç‰ˆTD3ç­–ç•¥"""
    return authentic_finrl_runner.run_finrl_strategy('TD3', train_df, test_df, ticker, **kwargs)

def run_finrl_ddpg_strategy(train_df: pd.DataFrame, test_df: pd.DataFrame, 
                           ticker: str = 'STOCK', **kwargs) -> Tuple[pd.Series, pd.DataFrame]:
    """FinRLåŸç‰ˆDDPGç­–ç•¥"""
    # DDPGéœ€è¦æ›´å¤šè®­ç»ƒæ­¥æ•°
    kwargs.setdefault('total_timesteps', 100000)
    return authentic_finrl_runner.run_finrl_strategy('DDPG', train_df, test_df, ticker, **kwargs)


if __name__ == "__main__":
    # æµ‹è¯•FinRLåŸç‰ˆé›†æˆ
    print("ğŸ§ª æµ‹è¯•FinRLåŸç‰ˆé›†æˆ...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    dates = pd.date_range(start='2022-01-01', end='2023-12-31', freq='D')
    n_days = len(dates)
    
    # ç”ŸæˆçœŸå®çš„è‚¡ä»·æ•°æ®
    returns = np.random.normal(0.001, 0.02, n_days)
    prices = 100 * np.cumprod(1 + returns)
    
    test_data = pd.DataFrame({
        'date': dates,
        'open': prices * (1 + np.random.normal(0, 0.005, n_days)),
        'high': prices * (1 + np.abs(np.random.normal(0, 0.01, n_days))),
        'low': prices * (1 - np.abs(np.random.normal(0, 0.01, n_days))),
        'close': prices,
        'volume': np.random.randint(1000000, 10000000, n_days)
    })
    
    # ç¡®ä¿ä»·æ ¼é€»è¾‘æ­£ç¡®
    test_data['high'] = np.maximum(test_data['high'], test_data['close'])
    test_data['low'] = np.minimum(test_data['low'], test_data['close'])
    
    # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
    split_point = int(len(test_data) * 0.7)
    train_data = test_data.iloc[:split_point]
    test_data = test_data.iloc[split_point:]
    
    try:
        print("ğŸš€ æµ‹è¯•FinRL PPOç­–ç•¥...")
        metrics, results = run_finrl_ppo_strategy(train_data, test_data, 'TEST', total_timesteps=1000)
        
        print("âœ… FinRLåŸç‰ˆé›†æˆæµ‹è¯•æˆåŠŸ!")
        print(f"ğŸ“Š å¹´åŒ–æ”¶ç›Š: {metrics['annualized_return']:.2%}")
        print(f"ğŸ“ˆ å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.3f}")
        print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {metrics['max_drawdown']:.2%}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥FinRLå®‰è£…æ˜¯å¦æ­£ç¡®")
