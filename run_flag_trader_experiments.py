#!/usr/bin/env python3
"""
FLAG-TRADERé£æ ¼å¯¹æ¯”å®éªŒè¿è¡Œå™¨
FLAG-TRADER Style Comparison Experiment Runner

åŠŸèƒ½ï¼š
1. è¿è¡ŒEATA vs FinRL vs InvestorBenchçš„å…¨é¢å¯¹æ¯”å®éªŒ
2. å¤ç°FLAG-TRADERè®ºæ–‡ä¸­çš„å®éªŒè®¾ç½®
3. ç”Ÿæˆå­¦æœ¯è®ºæ–‡çº§åˆ«çš„ç»“æœåˆ†æ
4. æ”¯æŒå¤šç§å®éªŒé…ç½®å’Œè¯„ä¼°æŒ‡æ ‡

å‚è€ƒè®ºæ–‡: FLAG-TRADER: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading

ä½¿ç”¨æ–¹æ³•:
python run_flag_trader_experiments.py --experiment_type full
python run_flag_trader_experiments.py --experiment_type finrl_only
python run_flag_trader_experiments.py --experiment_type llm_only
"""

import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
import argparse
from datetime import datetime
import json
import time
from typing import Dict, List, Tuple, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

try:
    from comparison_experiments.algorithms.baseline import BaselineRunner
    from comparison_experiments.algorithms.data_utils import get_available_tickers
    from experiment_pipeline import ExperimentPipeline
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨EATAé¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


class FlagTraderExperimentRunner:
    """FLAG-TRADERé£æ ¼å®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, base_dir="/Users/zjt/Desktop/EATA-RL-main"):
        self.base_dir = Path(base_dir)
        self.results_dir = self.base_dir / "flag_trader_results"
        self.results_dir.mkdir(exist_ok=True)
        
        # å®éªŒé…ç½® - åŸºäºFLAG-TRADERè®ºæ–‡
        self.experiment_configs = {
            'full': {
                'name': 'Full Comparison (EATA vs FinRL vs InvestorBench)',
                'strategies': [
                    'eata',  # æˆ‘ä»¬çš„æ–¹æ³•
                    # ä¼ ç»ŸåŸºçº¿
                    'buy_and_hold', 'macd',
                    # æœºå™¨å­¦ä¹ åŸºçº¿
                    'lstm', 'transformer', 'lightgbm',
                    # FinRLå¼ºåŒ–å­¦ä¹ æ–¹æ³•
                    'finrl_ppo', 'finrl_a2c', 'finrl_sac', 'finrl_td3',
                    # InvestorBench LLMæ–¹æ³•
                    'investorbench_gpt35', 'investorbench_gpt4'
                ],
                'description': 'å®Œæ•´å¯¹æ¯”å®éªŒï¼ŒåŒ…å«æ‰€æœ‰ç±»å‹çš„åŸºçº¿æ–¹æ³•'
            },
            'finrl_focus': {
                'name': 'FinRL Focused Comparison',
                'strategies': [
                    'eata',
                    'finrl_ppo', 'finrl_a2c', 'finrl_sac', 'finrl_td3', 'finrl_ddpg',
                    'buy_and_hold', 'ppo'  # å¯¹ç…§ç»„
                ],
                'description': 'ä¸“æ³¨äºFinRLå¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„å¯¹æ¯”'
            },
            'llm_focus': {
                'name': 'LLM Focused Comparison',
                'strategies': [
                    'eata',
                    'investorbench_gpt35', 'investorbench_gpt4', 
                    'investorbench_llama2', 'investorbench_finbert',
                    'transformer', 'lstm'  # å¯¹ç…§ç»„
                ],
                'description': 'ä¸“æ³¨äºLLMæ–¹æ³•çš„å¯¹æ¯”'
            },
            'academic': {
                'name': 'Academic Paper Comparison',
                'strategies': [
                    'eata',  # æå‡ºçš„æ–¹æ³•
                    'finrl_ppo', 'finrl_sac',  # FinRLä»£è¡¨
                    'investorbench_gpt35',  # LLMä»£è¡¨
                    'transformer', 'lstm',  # æ·±åº¦å­¦ä¹ åŸºçº¿
                    'buy_and_hold', 'macd'  # ä¼ ç»ŸåŸºçº¿
                ],
                'description': 'å­¦æœ¯è®ºæ–‡æ ‡å‡†å¯¹æ¯”å®éªŒ'
            }
        }
        
        # æµ‹è¯•è‚¡ç¥¨ - é€‰æ‹©ä¸åŒå¸‚åœºç‰¹å¾çš„è‚¡ç¥¨
        self.test_tickers = {
            'tech_growth': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA'],
            'finance': ['JPM', 'BAC', 'WFC', 'GS', 'MS'],
            'diverse': ['AAPL', 'JPM', 'JNJ', 'XOM', 'WMT']
        }
        
        # å®éªŒå‚æ•°
        self.experiment_params = {
            'lookback': 50,
            'lookahead': 10,
            'stride': 1,
            'depth': 300,
            'num_runs': 3  # æ¯ä¸ªé…ç½®è¿è¡Œ3æ¬¡å–å¹³å‡
        }
    
    def run_experiment_suite(self, experiment_type: str = 'academic',
                           ticker_set: str = 'diverse',
                           custom_tickers: Optional[List[str]] = None,
                           **kwargs) -> Dict:
        """è¿è¡Œå®éªŒå¥—ä»¶"""
        
        if experiment_type not in self.experiment_configs:
            raise ValueError(f"ä¸æ”¯æŒçš„å®éªŒç±»å‹: {experiment_type}")
        
        config = self.experiment_configs[experiment_type]
        tickers = custom_tickers or self.test_tickers.get(ticker_set, self.test_tickers['diverse'])
        
        print(f"ğŸš€ å¯åŠ¨FLAG-TRADERé£æ ¼å®éªŒ: {config['name']}")
        print(f"ğŸ“Š å®éªŒé…ç½®: {config['description']}")
        print(f"ğŸ“ˆ æµ‹è¯•è‚¡ç¥¨: {tickers}")
        print(f"ğŸ”§ æµ‹è¯•ç­–ç•¥: {config['strategies']}")
        print("=" * 80)
        
        # æ›´æ–°å®éªŒå‚æ•°
        params = self.experiment_params.copy()
        params.update(kwargs)
        
        # è¿è¡Œå®éªŒ
        start_time = time.time()
        results = self._run_baseline_experiments(
            strategies=config['strategies'],
            tickers=tickers,
            **params
        )
        
        experiment_time = time.time() - start_time
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = self.results_dir / f"flag_trader_results_{experiment_type}_{timestamp}.json"
        
        experiment_summary = {
            'experiment_type': experiment_type,
            'experiment_config': config,
            'tickers': tickers,
            'parameters': params,
            'experiment_time': experiment_time,
            'timestamp': timestamp,
            'results': results
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(experiment_summary, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nâœ… å®éªŒå®Œæˆï¼è€—æ—¶: {experiment_time/60:.1f} åˆ†é’Ÿ")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜: {results_file}")
        
        # ç”Ÿæˆå¿«é€ŸæŠ¥å‘Š
        self._generate_quick_report(experiment_summary)
        
        return experiment_summary
    
    def _run_baseline_experiments(self, strategies: List[str], tickers: List[str], 
                                 num_runs: int = 3, **params) -> Dict:
        """è¿è¡ŒåŸºçº¿å®éªŒ"""
        
        runner = BaselineRunner()
        all_results = {}
        
        total_experiments = len(tickers) * len(strategies) * num_runs
        completed = 0
        
        for ticker in tickers:
            print(f"\nğŸ“Š å¤„ç†è‚¡ç¥¨: {ticker}")
            ticker_results = {}
            
            # è·å–è‚¡ç¥¨æ•°æ® (è¿™é‡Œéœ€è¦å®ç°æ•°æ®è·å–é€»è¾‘)
            try:
                df = self._get_stock_data(ticker)
                if df is None or len(df) < 100:
                    print(f"âš ï¸ {ticker} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                    continue
                
                print(f"ğŸ“ˆ æ•°æ®é‡: {len(df)} æ¡è®°å½•")
                
                # è¿è¡Œæ‰€æœ‰ç­–ç•¥
                strategy_results = runner.run_all_strategies(
                    df=df,
                    ticker=ticker,
                    train_ratio=0.7,
                    selected_strategies=strategies
                )
                
                # å¤šæ¬¡è¿è¡Œå–å¹³å‡ (å¯¹äºéœ€è¦è®­ç»ƒçš„ç­–ç•¥)
                if num_runs > 1:
                    strategy_results = self._run_multiple_times(
                        runner, df, ticker, strategies, num_runs
                    )
                
                ticker_results = strategy_results
                completed += len(strategies)
                
                progress = (completed / total_experiments) * 100
                print(f"ğŸ“Š æ€»ä½“è¿›åº¦: {completed}/{total_experiments} ({progress:.1f}%)")
                
            except Exception as e:
                print(f"âŒ {ticker} å®éªŒå¤±è´¥: {e}")
                continue
            
            all_results[ticker] = ticker_results
        
        return all_results
    
    def _run_multiple_times(self, runner: BaselineRunner, df: pd.DataFrame, 
                           ticker: str, strategies: List[str], num_runs: int) -> Dict:
        """å¤šæ¬¡è¿è¡Œå®éªŒå–å¹³å‡å€¼"""
        
        print(f"ğŸ”„ è¿è¡Œ {num_runs} æ¬¡å®éªŒå–å¹³å‡...")
        
        all_runs = []
        for run_id in range(num_runs):
            print(f"  ğŸ“Š ç¬¬ {run_id + 1}/{num_runs} è½®...")
            
            try:
                run_results = runner.run_all_strategies(
                    df=df,
                    ticker=ticker,
                    train_ratio=0.7,
                    selected_strategies=strategies
                )
                all_runs.append(run_results)
            except Exception as e:
                print(f"    âŒ ç¬¬ {run_id + 1} è½®å¤±è´¥: {e}")
                continue
        
        # è®¡ç®—å¹³å‡ç»“æœ
        if not all_runs:
            return {}
        
        averaged_results = {}
        for strategy in strategies:
            strategy_metrics = []
            
            for run_result in all_runs:
                if strategy in run_result and run_result[strategy]['success']:
                    metrics = run_result[strategy]['metrics']
                    if metrics is not None:
                        strategy_metrics.append(metrics)
            
            if strategy_metrics:
                # è®¡ç®—å¹³å‡æŒ‡æ ‡
                avg_metrics = pd.concat(strategy_metrics, axis=1).mean(axis=1)
                std_metrics = pd.concat(strategy_metrics, axis=1).std(axis=1)
                
                averaged_results[strategy] = {
                    'metrics': avg_metrics,
                    'metrics_std': std_metrics,
                    'success': True,
                    'num_successful_runs': len(strategy_metrics),
                    'description': f"{strategy} (å¹³å‡ {len(strategy_metrics)} æ¬¡è¿è¡Œ)"
                }
            else:
                averaged_results[strategy] = {
                    'metrics': None,
                    'success': False,
                    'description': f"{strategy} (æ‰€æœ‰è¿è¡Œå‡å¤±è´¥)"
                }
        
        return averaged_results
    
    def _get_stock_data(self, ticker: str) -> Optional[pd.DataFrame]:
        """è·å–è‚¡ç¥¨æ•°æ® (æ¨¡æ‹Ÿå®ç°)"""
        try:
            # è¿™é‡Œåº”è¯¥å®ç°çœŸå®çš„æ•°æ®è·å–é€»è¾‘
            # å¯ä»¥ä»EATAé¡¹ç›®çš„æ•°æ®æºè·å–ï¼Œæˆ–ä½¿ç”¨yfinanceç­‰
            
            # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ (å®é™…ä½¿ç”¨æ—¶åº”æ›¿æ¢ä¸ºçœŸå®æ•°æ®)
            np.random.seed(hash(ticker) % 2**32)
            n_days = 500
            
            dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')
            
            # ç”Ÿæˆæ¨¡æ‹Ÿçš„è‚¡ä»·æ•°æ®
            returns = np.random.normal(0.001, 0.02, n_days)
            prices = 100 * np.cumprod(1 + returns)
            
            df = pd.DataFrame({
                'date': dates,
                'open': prices * (1 + np.random.normal(0, 0.005, n_days)),
                'high': prices * (1 + np.abs(np.random.normal(0, 0.01, n_days))),
                'low': prices * (1 - np.abs(np.random.normal(0, 0.01, n_days))),
                'close': prices,
                'volume': np.random.randint(1000000, 10000000, n_days)
            })
            
            # ç¡®ä¿high >= close >= low
            df['high'] = np.maximum(df['high'], df['close'])
            df['low'] = np.minimum(df['low'], df['close'])
            
            return df
            
        except Exception as e:
            print(f"âŒ è·å– {ticker} æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _generate_quick_report(self, experiment_summary: Dict):
        """ç”Ÿæˆå¿«é€ŸæŠ¥å‘Š"""
        
        print("\n" + "="*80)
        print("ğŸ“‹ å®éªŒç»“æœå¿«é€ŸæŠ¥å‘Š")
        print("="*80)
        
        results = experiment_summary['results']
        config = experiment_summary['experiment_config']
        
        # ç»Ÿè®¡æˆåŠŸçš„å®éªŒ
        total_experiments = 0
        successful_experiments = 0
        strategy_performance = {}
        
        for ticker, ticker_results in results.items():
            for strategy, result in ticker_results.items():
                total_experiments += 1
                if result.get('success', False):
                    successful_experiments += 1
                    
                    metrics = result.get('metrics')
                    if metrics is not None and hasattr(metrics, 'get'):
                        annual_return = metrics.get('annualized_return', 0)
                        sharpe_ratio = metrics.get('sharpe_ratio', 0)
                        
                        if strategy not in strategy_performance:
                            strategy_performance[strategy] = {
                                'returns': [],
                                'sharpes': [],
                                'count': 0
                            }
                        
                        strategy_performance[strategy]['returns'].append(annual_return)
                        strategy_performance[strategy]['sharpes'].append(sharpe_ratio)
                        strategy_performance[strategy]['count'] += 1
        
        print(f"ğŸ“Š å®éªŒç»Ÿè®¡:")
        print(f"  æ€»å®éªŒæ•°: {total_experiments}")
        print(f"  æˆåŠŸå®éªŒ: {successful_experiments}")
        print(f"  æˆåŠŸç‡: {successful_experiments/total_experiments*100:.1f}%")
        
        print(f"\nğŸ† ç­–ç•¥æ€§èƒ½æ’å (æŒ‰å¹³å‡å¹´åŒ–æ”¶ç›Š):")
        
        # è®¡ç®—å¹³å‡æ€§èƒ½å¹¶æ’åº
        strategy_avg_performance = []
        for strategy, perf in strategy_performance.items():
            if perf['count'] > 0:
                avg_return = np.mean(perf['returns'])
                avg_sharpe = np.mean(perf['sharpes'])
                strategy_avg_performance.append({
                    'strategy': strategy,
                    'avg_return': avg_return,
                    'avg_sharpe': avg_sharpe,
                    'count': perf['count']
                })
        
        # æŒ‰å¹´åŒ–æ”¶ç›Šæ’åº
        strategy_avg_performance.sort(key=lambda x: x['avg_return'], reverse=True)
        
        print(f"{'æ’å':<4} {'ç­–ç•¥':<20} {'å¹´åŒ–æ”¶ç›Š':<12} {'å¤æ™®æ¯”ç‡':<10} {'å®éªŒæ¬¡æ•°':<8}")
        print("-" * 60)
        
        for i, perf in enumerate(strategy_avg_performance[:10]):  # æ˜¾ç¤ºå‰10å
            rank = i + 1
            strategy = perf['strategy']
            avg_return = perf['avg_return']
            avg_sharpe = perf['avg_sharpe']
            count = perf['count']
            
            print(f"{rank:<4} {strategy:<20} {avg_return:>10.2%} {avg_sharpe:>8.3f} {count:>6}")
        
        # EATAæ€§èƒ½åˆ†æ
        if 'eata' in strategy_performance:
            eata_perf = strategy_performance['eata']
            if eata_perf['count'] > 0:
                eata_rank = next((i+1 for i, p in enumerate(strategy_avg_performance) 
                                if p['strategy'] == 'eata'), None)
                
                print(f"\nğŸ¯ EATAæ€§èƒ½åˆ†æ:")
                print(f"  æ’å: {eata_rank}/{len(strategy_avg_performance)}")
                print(f"  å¹³å‡å¹´åŒ–æ”¶ç›Š: {np.mean(eata_perf['returns']):.2%}")
                print(f"  å¹³å‡å¤æ™®æ¯”ç‡: {np.mean(eata_perf['sharpes']):.3f}")
                print(f"  æˆåŠŸå®éªŒæ•°: {eata_perf['count']}")
        
        print(f"\nğŸ“ è¯¦ç»†ç»“æœæ–‡ä»¶: {self.results_dir}")
        print("ğŸ’¡ ä½¿ç”¨ experiment_pipeline.py ç”Ÿæˆå®Œæ•´çš„å­¦æœ¯æŠ¥å‘Š")
    
    def generate_academic_report(self, results_file: str):
        """ç”Ÿæˆå­¦æœ¯è®ºæ–‡çº§åˆ«çš„æŠ¥å‘Š"""
        
        print("ğŸ“ ç”Ÿæˆå­¦æœ¯æŠ¥å‘Š...")
        
        # ä½¿ç”¨ç°æœ‰çš„å®éªŒç®¡é“ç”ŸæˆæŠ¥å‘Š
        pipeline = ExperimentPipeline(str(self.base_dir))
        
        try:
            # å°†FLAG-TRADERç»“æœè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            self._convert_results_format(results_file)
            
            # è¿è¡Œå®Œæ•´çš„æŠ¥å‘Šç”Ÿæˆæµç¨‹
            df, summary_df = pipeline.run_full_pipeline()
            
            print("âœ… å­¦æœ¯æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return df, summary_df
            
        except Exception as e:
            print(f"âŒ å­¦æœ¯æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return None, None
    
    def _convert_results_format(self, results_file: str):
        """å°†FLAG-TRADERç»“æœè½¬æ¢ä¸ºæ ‡å‡†å®éªŒç®¡é“æ ¼å¼"""
        # è¿™é‡Œéœ€è¦å®ç°æ ¼å¼è½¬æ¢é€»è¾‘
        # å°†FLAG-TRADERçš„JSONç»“æœè½¬æ¢ä¸ºexperiment_pipeline.pyæœŸæœ›çš„æ ¼å¼
        pass


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='FLAG-TRADERé£æ ¼å¯¹æ¯”å®éªŒ')
    parser.add_argument('--experiment_type', 
                       choices=['full', 'finrl_focus', 'llm_focus', 'academic'],
                       default='academic', help='å®éªŒç±»å‹')
    parser.add_argument('--ticker_set', 
                       choices=['tech_growth', 'finance', 'diverse'],
                       default='diverse', help='è‚¡ç¥¨é›†åˆ')
    parser.add_argument('--tickers', nargs='+', help='è‡ªå®šä¹‰è‚¡ç¥¨åˆ—è¡¨')
    parser.add_argument('--num_runs', type=int, default=3, help='æ¯ä¸ªé…ç½®è¿è¡Œæ¬¡æ•°')
    parser.add_argument('--lookback', type=int, default=50, help='å›æœ›çª—å£')
    parser.add_argument('--lookahead', type=int, default=10, help='é¢„æµ‹çª—å£')
    parser.add_argument('--generate_report', action='store_true', help='ç”Ÿæˆå­¦æœ¯æŠ¥å‘Š')
    parser.add_argument('--base_dir', default='/Users/zjt/Desktop/EATA-RL-main', help='é¡¹ç›®æ ¹ç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒè¿è¡Œï¿½ï¿½ï¿½
    runner = FlagTraderExperimentRunner(args.base_dir)
    
    # è¿è¡Œå®éªŒ
    results = runner.run_experiment_suite(
        experiment_type=args.experiment_type,
        ticker_set=args.ticker_set,
        custom_tickers=args.tickers,
        num_runs=args.num_runs,
        lookback=args.lookback,
        lookahead=args.lookahead
    )
    
    # ç”Ÿæˆå­¦æœ¯æŠ¥å‘Š
    if args.generate_report:
        results_file = runner.results_dir / f"flag_trader_results_{args.experiment_type}_*.json"
        runner.generate_academic_report(str(results_file))


if __name__ == "__main__":
    main()
