#!/usr/bin/env python
# coding=utf-8
# ç›´æ¥è°ƒç”¨æ ¸å¿ƒæ¨¡å—ï¼šengine.simulate â†’ model.run â†’ mcts + network

import numpy as np
import torch
import pandas as pd
from typing import Optional, Tuple, Dict, Any
import warnings
import logging
import sys

warnings.filterwarnings('ignore')

# éšè—æ‰€æœ‰æ—¥å¿—è¾“å‡º
logging.getLogger('MCTSAdapter').setLevel(logging.CRITICAL)
logging.getLogger('NEMoTS').setLevel(logging.CRITICAL)
logging.getLogger('nemots').setLevel(logging.CRITICAL)
logging.getLogger('engine').setLevel(logging.CRITICAL)
logging.getLogger('model').setLevel(logging.CRITICAL)
logging.getLogger('mcts').setLevel(logging.CRITICAL)
logging.getLogger().setLevel(logging.CRITICAL)

# åˆ›å»ºç©ºè¾“å‡ºç±»
class NullWriter:
    def write(self, txt): pass
    def flush(self): pass

# å¯¼å…¥NEMoTSæ ¸å¿ƒæ¨¡å—
from nemots.engine import Engine
from nemots.args import Args


class SlidingWindowNEMoTS:
    
    def __init__(self, lookback: int = 20, lookahead: int = 5):
        """
        åˆå§‹åŒ–æ»‘åŠ¨çª—å£NEMoTS
        
        Args:
            lookback: è®­ç»ƒçª—å£å¤§å°ï¼ˆå¯¹åº”åŸNEMoTSçš„seq_inï¼‰
            lookahead: é¢„æµ‹çª—å£å¤§å°ï¼ˆå¯¹åº”åŸNEMoTSçš„seq_outï¼‰
        """
        self.lookback = lookback
        self.lookahead = lookahead
        
        # ä»mainå‡½æ•°è¿ç§»çš„è¶…å‚æ•°
        self.hyperparams = self._create_hyperparams()
        
        # åˆå§‹åŒ–å¼•æ“
        original_stderr = sys.stderr
        original_stdout = sys.stdout
        try:
            sys.stderr = NullWriter()
            sys.stdout = NullWriter()
            self.engine = Engine(self.hyperparams)
        finally:
            sys.stderr = original_stderr
            sys.stdout = original_stdout
        
        # è¯­æ³•æ ‘ç»§æ‰¿å’Œå¤šæ ·æ€§ç®¡ç†
        self.previous_best_tree = None
        self.previous_best_expression = None
        self.expression_diversity_pool = []  # ä¿å­˜å¤šä¸ªä¼˜ç§€è¡¨è¾¾å¼
        self.stagnation_counter = 0  # åœæ»è®¡æ•°å™¨
        self.max_stagnation = 5  # å¢åŠ æœ€å¤§åœæ»æ¬¡æ•°ï¼Œå‡å°‘é‡å¯é¢‘ç‡
        
        # è®­ç»ƒçŠ¶æ€
        self.is_trained = False
        self.training_history = []
        
        # æ€§èƒ½ç›‘æ§ - é’ˆå¯¹è¡¨è¾¾å¼å›ºåŒ–çš„æ•æ„Ÿé‡å¯æ¡ä»¶
        self.performance_threshold = 0.5   # MAEè¶…è¿‡0.5å°±è®¤ä¸ºæ€§èƒ½æå·®
        self.consecutive_poor_performance = 0
        self.expression_repetition_count = 0  # è¡¨è¾¾å¼é‡å¤è®¡æ•°
        
        print(f"æ»‘åŠ¨çª—å£NEMoTSåˆå§‹åŒ–å®Œæˆ")
        print(f"   lookback={lookback}, lookahead={lookahead}")
        print(f"   æ ¸å¿ƒæ¨¡å—: engine â†’ model â†’ mcts + network")
    
    def _create_hyperparams(self) -> Args:
        """
        åˆ›å»ºè¶…å‚æ•°é…ç½®ï¼ˆå¢å¼ºæ¢ç´¢èƒ½åŠ›ç‰ˆæœ¬ï¼‰
        é’ˆå¯¹å±€éƒ¨æœ€ä¼˜é—®é¢˜çš„æ”¹è¿›é…ç½®
        """
        args = Args()
        
        # è®¾å¤‡é…ç½®
        args.device = torch.device("cpu")
        args.seed = np.random.randint(1, 10000)  # éšæœºç§å­å¢åŠ å¤šæ ·æ€§
        
        # æ•°æ®é…ç½®ï¼ˆé€‚é…æ»‘åŠ¨çª—å£ï¼‰
        args.seq_in = self.lookback
        args.seq_out = self.lookahead
        args.used_dimension = 1
        args.features = 'M'  # å¤šå˜é‡é¢„æµ‹å¤šå˜é‡
        
        # NEMoTSæ ¸å¿ƒå‚æ•° - å¢å¼ºæ¢ç´¢èƒ½åŠ›ï¼ˆæœ€ä½³æ•ˆæœç‰ˆæœ¬ï¼‰
        args.symbolic_lib = "NEMoTS"
        args.max_len = 30  # å¢åŠ è¡¨è¾¾å¼é•¿åº¦ä¸Šé™
        args.max_module_init = 20  # å¢åŠ åˆå§‹æ¨¡å—æ•°é‡
        args.num_transplant = 4  # å¢åŠ ç§»æ¤æ¬¡æ•°
        args.num_runs = 8  # æ˜¾è‘—å¢åŠ è¿è¡Œæ¬¡æ•°
        args.eta = 1.5  # å¢åŠ etaå€¼ï¼Œæé«˜æ¢ç´¢å¼ºåº¦
        args.num_aug = 2  # å¢åŠ æ•°æ®å¢å¼º
        args.exploration_rate = 1.2  # æé«˜æ¢ç´¢ç‡
        args.transplant_step = 1000  # å¢åŠ ç§»æ¤æ­¥æ•°
        args.norm_threshold = 1e-6  # æ›´ä¸¥æ ¼çš„æ”¶æ•›é˜ˆå€¼
        
        # è®­ç»ƒå‚æ•° - å¹³è¡¡æ¢ç´¢ä¸æ•ˆç‡
        args.epoch = 15  # é€‚åº¦å¢åŠ epoch
        args.round = 3   # å¢åŠ roundæ•°
        args.train_size = 32  # é€‚åº¦å‡å°‘batch sizeå¢åŠ éšæœºæ€§
        args.lr = 5e-5  # æé«˜å­¦ä¹ ç‡
        args.weight_decay = 0.0005  # å¢åŠ æ­£åˆ™åŒ–
        args.clip = 3.0  # é€‚åº¦é™ä½æ¢¯åº¦è£å‰ª
        
        # å¤šæ ·æ€§éšæœºç§å­ï¼ˆæ¯æ¬¡è°ƒç”¨éƒ½ä¸åŒï¼‰
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        
        print(f"å¢å¼ºæ¢ç´¢è¶…å‚æ•°é…ç½®å®Œæˆ (seed={args.seed})")
        return args
    
    def _adaptive_hyperparams_adjustment(self):
        """
        åŸºäºå†å²æ€§èƒ½åŠ¨æ€è°ƒæ•´è¶…å‚æ•° - æ›´æ¸©å’Œçš„è°ƒæ•´
        """
        if len(self.training_history) < 3:
            return
        
        # åˆ†ææœ€è¿‘çš„æ€§èƒ½è¶‹åŠ¿
        recent_maes = [record['mae'] for record in self.training_history[-3:]]
        avg_recent_mae = np.mean(recent_maes)
        
        # åªæœ‰åœ¨æ€§èƒ½æå·®æ—¶æ‰è°ƒæ•´ï¼Œé¿å…è¿‡åº¦è°ƒæ•´
        if avg_recent_mae > self.performance_threshold * 1.5:  # æ›´ä¸¥æ ¼çš„è°ƒæ•´æ¡ä»¶
            print(f"   ğŸ“ˆ æ£€æµ‹åˆ°æ€§èƒ½æå·® (MAE={avg_recent_mae:.4f})ï¼Œè½»å¾®å¢åŠ æ¢ç´¢å¼ºåº¦")
            
            # æ›´æ¸©å’Œçš„è°ƒæ•´
            self.hyperparams.exploration_rate = min(1.2, self.hyperparams.exploration_rate * 1.05)
            self.hyperparams.num_runs = min(6, self.hyperparams.num_runs + 1)
            self.hyperparams.eta = min(1.5, self.hyperparams.eta * 1.05)
            
            print(f"   è°ƒæ•´å: exploration_rate={self.hyperparams.exploration_rate:.3f}, "
                  f"num_runs={self.hyperparams.num_runs}, eta={self.hyperparams.eta:.3f}")
        
        # æ€§èƒ½è‰¯å¥½æ—¶ä¿æŒç¨³å®šï¼Œä¸åšè°ƒæ•´
        elif avg_recent_mae < self.performance_threshold * 0.3:
            print(f"   âœ… æ€§èƒ½è‰¯å¥½ (MAE={avg_recent_mae:.4f})ï¼Œä¿æŒå½“å‰å‚æ•°")
    
    def _prepare_sliding_window_data(self, df: pd.DataFrame) -> torch.Tensor:
        """
        å‡†å¤‡æ»‘åŠ¨çª—å£æ•°æ®
        åŸºäºRLèŒƒå¼çš„æ•°æ®å¤„ç†ï¼Œæ›¿ä»£å…¨åºåˆ—æ‹Ÿåˆ
        """
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        data = df[feature_cols].values
        
        # æ”¹è¿›çš„æ•°æ®æ ‡å‡†åŒ– - å¢å¼ºä¿¡å·å¼ºåº¦
        normalized_data = []
        
        # è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯ç”¨äºæ ‡å‡†åŒ–
        all_changes = []
        for i in range(1, len(data)):
            for j in range(4):  # price columns
                if data[i-1, j] != 0:
                    change = (data[i, j] - data[i-1, j]) / data[i-1, j]
                    all_changes.append(change)
        
        if all_changes:
            change_std = np.std(all_changes)
            change_mean = np.mean(all_changes)
        else:
            change_std = 0.01
            change_mean = 0.0
        
        # ç¬¬ä¸€è¡Œä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆæ ‡å‡†åŒ–å¤„ç†ï¼‰
        if len(data) > 0:
            first_row = []
            for j in range(4):  # open, high, low, close
                first_row.append(0.0)  # ç¬¬ä¸€è¡Œå˜åŒ–ç‡ä¸º0
            for j in [4, 5]:  # volume, amount
                first_row.append(0.0)  # ç¬¬ä¸€è¡Œå˜åŒ–ç‡ä¸º0
            normalized_data.append(first_row)
        
        # åç»­è¡Œä½¿ç”¨å¢å¼ºçš„æ ‡å‡†åŒ–
        for i in range(1, len(data)):
            row = []
            # ä»·æ ¼å˜åŒ–ç‡ - ä½¿ç”¨Z-scoreæ ‡å‡†åŒ–å¢å¼ºä¿¡å·
            for j in range(4):  # open, high, low, close
                if data[i-1, j] != 0:
                    change_rate = (data[i, j] - data[i-1, j]) / data[i-1, j]
                    # Z-scoreæ ‡å‡†åŒ–ï¼Œç„¶åæ”¾å¤§ä¿¡å·
                    if change_std > 0:
                        normalized_change = (change_rate - change_mean) / change_std
                        # æ”¾å¤§ä¿¡å·å¼ºåº¦ï¼Œä½†ä¿æŒåœ¨åˆç†èŒƒå›´
                        enhanced_change = np.tanh(normalized_change * 2) * 0.5
                    else:
                        enhanced_change = 0.0
                else:
                    enhanced_change = 0.0
                row.append(enhanced_change)
            
            # æˆäº¤é‡å˜åŒ–ç‡ - ç®€åŒ–å¤„ç†
            for j in [4, 5]:  # volume, amount
                if data[i-1, j] > 0 and data[i, j] > 0:
                    vol_change = (data[i, j] - data[i-1, j]) / data[i-1, j]
                    # ä½¿ç”¨tanhå‡½æ•°å‹ç¼©ä½†ä¿æŒä¿¡å·
                    enhanced_vol = np.tanh(vol_change) * 0.3
                else:
                    enhanced_vol = 0.0
                row.append(enhanced_vol)
            
            normalized_data.append(row)
        
        normalized_data = np.array(normalized_data)
        
        # åˆ›å»ºæ»‘åŠ¨çª—å£
        if len(normalized_data) < self.lookback + self.lookahead:
            raise ValueError(f"æ•°æ®é•¿åº¦ä¸è¶³ï¼šéœ€è¦{self.lookback + self.lookahead}ï¼Œå®é™…{len(normalized_data)}")
        
        # å–æœ€åä¸€ä¸ªçª—å£çš„æ•°æ®
        start_idx = len(normalized_data) - self.lookback - self.lookahead
        window_data = normalized_data[start_idx:start_idx + self.lookback + self.lookahead]
        
        # è½¬æ¢ä¸ºtensoræ ¼å¼ï¼Œæ·»åŠ batchç»´åº¦
        tensor_data = torch.FloatTensor(window_data).unsqueeze(0)  # [1, seq_len, features]
        
        print(f"æ»‘åŠ¨çª—å£æ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"   åŸå§‹æ•°æ®: {len(data)} â†’ æ ‡å‡†åŒ–æ•°æ®: {len(normalized_data)}")
        print(f"   çª—å£æ•°æ®: {tensor_data.shape}")
        print(f"   å˜åŒ–ç‡èŒƒå›´: [{tensor_data.min().item():.4f}, {tensor_data.max().item():.4f}]")
        
        return tensor_data
    
    def _manage_diversity_pool(self, expression: str, mae: float):
        """
        ç®¡ç†è¡¨è¾¾å¼å¤šæ ·æ€§æ± 
        ä¿å­˜å¤šä¸ªä¼˜ç§€ä½†ä¸åŒçš„è¡¨è¾¾å¼
        """
        # åªä¿å­˜æ€§èƒ½è¾ƒå¥½çš„è¡¨è¾¾å¼
        if mae < self.performance_threshold * 2:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼è¡¨è¾¾å¼
            is_similar = False
            for existing_expr, _ in self.expression_diversity_pool:
                if self._expressions_similar(expression, existing_expr):
                    is_similar = True
                    break
            
            if not is_similar:
                self.expression_diversity_pool.append((expression, mae))
                # ä¿æŒæ± å¤§å°åœ¨åˆç†èŒƒå›´
                if len(self.expression_diversity_pool) > 5:
                    # ç§»é™¤æ€§èƒ½æœ€å·®çš„
                    self.expression_diversity_pool.sort(key=lambda x: x[1])
                    self.expression_diversity_pool = self.expression_diversity_pool[:5]
                
                print(f"   æ·»åŠ åˆ°å¤šæ ·æ€§æ± : {expression[:50]}... (MAE={mae:.4f})")
    
    def _expressions_similar(self, expr1: str, expr2: str) -> bool:
        """
        ç®€å•çš„è¡¨è¾¾å¼ç›¸ä¼¼æ€§æ£€æŸ¥
        """
        # ç®€åŒ–çš„ç›¸ä¼¼æ€§æ£€æŸ¥ - å¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›
        return expr1 == expr2 or (len(expr1) > 10 and expr1[:10] == expr2[:10])
    
    def _should_restart(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å¯æœç´¢ - é’ˆå¯¹è¡¨è¾¾å¼å›ºåŒ–çš„æ•æ„Ÿç­–ç•¥
        """
        if len(self.training_history) < 2:
            return False
        
        # æ£€æŸ¥è¡¨è¾¾å¼é‡å¤æƒ…å†µ
        if len(self.training_history) >= 3:
            recent_expressions = [record['best_expression'] for record in self.training_history[-3:]]
            if len(set(recent_expressions)) == 1:  # è¿ç»­3æ¬¡ç›¸åŒè¡¨è¾¾å¼
                self.expression_repetition_count += 1
            else:
                self.expression_repetition_count = 0
        
        # æ£€æŸ¥æ€§èƒ½æ˜¯å¦æå·®
        if len(self.training_history) >= 2:
            recent_maes = [record['mae'] for record in self.training_history[-2:]]
            if all(mae > self.performance_threshold for mae in recent_maes):
                self.consecutive_poor_performance += 1
            else:
                self.consecutive_poor_performance = 0
        
        # æ•æ„Ÿçš„é‡å¯æ¡ä»¶
        should_restart = (
            self.expression_repetition_count >= 3 or  # è¿ç»­3æ¬¡ç›¸åŒè¡¨è¾¾å¼
            self.consecutive_poor_performance >= 2 or  # è¿ç»­2æ¬¡æ€§èƒ½æå·®
            (len(self.training_history) >= 2 and 
             self.training_history[-1]['mae'] > 0.8 and 
             self.training_history[-2]['mae'] > 0.8)  # è¿ç»­2æ¬¡MAE>0.8
        )
        
        if should_restart:
            print(f"   ğŸ”„ è§¦å‘é‡å¯: è¡¨è¾¾å¼é‡å¤={self.expression_repetition_count}, å·®æ€§èƒ½={self.consecutive_poor_performance}")
            print(f"   æœ€è¿‘MAE: {[record['mae'] for record in self.training_history[-3:]]}")
        
        return should_restart
    
    def _manage_diversity_pool(self, expression: str, mae: float):
        """
        ç®¡ç†è¡¨è¾¾å¼å¤šæ ·æ€§æ± 
        ä¿å­˜å¤šä¸ªä¼˜ç§€ä½†ä¸åŒçš„è¡¨è¾¾å¼
        """
        # åªä¿å­˜æ€§èƒ½è¾ƒå¥½çš„è¡¨è¾¾å¼
        if mae < self.performance_threshold * 2:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼è¡¨è¾¾å¼
            is_similar = False
            for existing_expr, _ in self.expression_diversity_pool:
                if self._expressions_similar(expression, existing_expr):
                    is_similar = True
                    break
            
            if not is_similar:
                self.expression_diversity_pool.append((expression, mae))
                # ä¿æŒæ± å¤§å°åœ¨åˆç†èŒƒå›´
                if len(self.expression_diversity_pool) > 5:
                    # ç§»é™¤æ€§èƒ½æœ€å·®çš„
                    self.expression_diversity_pool.sort(key=lambda x: x[1])
                    self.expression_diversity_pool = self.expression_diversity_pool[:5]
                
                print(f"   æ·»åŠ åˆ°å¤šæ ·æ€§æ± : {expression[:50]}... (MAE={mae:.4f})")

    def _expressions_similar(self, expr1: str, expr2: str) -> bool:
        """
        ç®€å•çš„è¡¨è¾¾å¼ç›¸ä¼¼æ€§æ£€æŸ¥
        """
        # ç®€åŒ–çš„ç›¸ä¼¼æ€§æ£€æŸ¥ - å¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›
        return expr1 == expr2 or (len(expr1) > 10 and expr1[:10] == expr2[:10])

    def _restart_search(self):
        """
        é‡å¯æœç´¢ç­–ç•¥ - å¼ºåˆ¶è·³å‡ºè¡¨è¾¾å¼å›ºåŒ–
        """
        print(f"   ğŸ”„ æ£€æµ‹åˆ°è¡¨è¾¾å¼å›ºåŒ–ï¼Œæ‰§è¡Œå¼ºåˆ¶é‡å¯...")
        
        # é‡æ–°åˆ›å»ºè¶…å‚æ•°ï¼ˆä½¿ç”¨æ–°çš„éšæœºç§å­ï¼‰
        self.hyperparams = self._create_hyperparams()
        
        # å®Œå…¨æ¸…ç©ºç»§æ‰¿ä¿¡æ¯ï¼Œå¼ºåˆ¶é‡æ–°å¼€å§‹
        self.previous_best_tree = None
        self.previous_best_expression = None
        
        # æ¸…ç©ºå¤šæ ·æ€§æ± ï¼Œé¿å…å›ºåŒ–è¡¨è¾¾å¼å½±å“
        self.expression_diversity_pool = []
        
        # é‡ç½®æ‰€æœ‰è®¡æ•°å™¨
        self.stagnation_counter = 0
        self.consecutive_poor_performance = 0
        self.expression_repetition_count = 0
        
        # å¤§å¹…æé«˜æ¢ç´¢å¼ºåº¦ï¼Œå¼ºåˆ¶è·³å‡ºå±€éƒ¨æœ€ä¼˜
        self.hyperparams.exploration_rate = min(2.0, self.hyperparams.exploration_rate * 1.5)
        self.hyperparams.eta = min(2.5, self.hyperparams.eta * 1.3)
        self.hyperparams.num_runs = min(12, self.hyperparams.num_runs + 3)
        
        print(f"   ğŸš€ å¼ºåˆ¶é‡å¯å®Œæˆï¼Œæé«˜æ¢ç´¢å¼ºåº¦: exploration_rate={self.hyperparams.exploration_rate:.3f}")

    def check_and_apply_config(self):
        """æ£€æŸ¥å¹¶åº”ç”¨é…ç½®æ–‡ä»¶æ›´æ–°"""
        import json
        import os
        
        config_file = 'config.json'
        if not os.path.exists(config_file):
            return
            
        try:
            # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            if not hasattr(self, '_last_config_time'):
                self._last_config_time = 0
                
            mtime = os.path.getmtime(config_file)
            if mtime <= self._last_config_time:
                return
                
            # è¯»å–æ–°é…ç½®
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            print(f"ğŸ”„ æ£€æµ‹åˆ°é…ç½®æ›´æ–°ï¼Œåº”ç”¨æ–°å‚æ•°...")
            
            # åº”ç”¨NEMoTSå‚æ•°
            if 'nemots' in config:
                nemots_config = config['nemots']
                for key, value in nemots_config.items():
                    if hasattr(self.hyperparams, key):
                        old_value = getattr(self.hyperparams, key)
                        setattr(self.hyperparams, key, value)
                        print(f"   ğŸ“ {key}: {old_value} â†’ {value}")
            
            # åº”ç”¨ç³»ç»Ÿå‚æ•°
            if 'system' in config and 'window_size' in config['system']:
                new_size = config['system']['window_size']
                if new_size != self.window_size:
                    print(f"   ğŸ“ window_size: {self.window_size} â†’ {new_size}")
                    self.window_size = new_size
            
            self._last_config_time = mtime
            print(f"âœ… é…ç½®æ›´æ–°å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ é…ç½®æ›´æ–°å¤±è´¥: {e}")

    def _prepare_sliding_window_data(self, df: pd.DataFrame) -> torch.Tensor:
        """
        å‡†å¤‡æ»‘åŠ¨çª—å£æ•°æ®
        åŸºäºRLèŒƒå¼çš„æ•°æ®å¤„ç†ï¼Œæ›¿ä»£å…¨åºåˆ—æ‹Ÿåˆ
        """
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        data = df[feature_cols].values
        
        # æ”¹è¿›çš„æ•°æ®æ ‡å‡†åŒ– - å¢å¼ºä¿¡å·å¼ºåº¦
        normalized_data = []
        
        # è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯ç”¨äºæ ‡å‡†åŒ–
        all_changes = []
        for i in range(1, len(data)):
            for j in range(4):  # price columns
                if data[i-1, j] != 0:
                    change = (data[i, j] - data[i-1, j]) / data[i-1, j]
                    all_changes.append(change)
        
        if all_changes:
            change_std = np.std(all_changes)
            change_mean = np.mean(all_changes)
        else:
            change_std = 0.01
            change_mean = 0.0
        
        # ç¬¬ä¸€è¡Œä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆæ ‡å‡†åŒ–å¤„ç†ï¼‰
        if len(data) > 0:
            first_row = []
            for j in range(4):  # open, high, low, close
                first_row.append(0.0)  # ç¬¬ä¸€è¡Œå˜åŒ–ç‡ä¸º0
            for j in [4, 5]:  # volume, amount
                first_row.append(0.0)  # ç¬¬ä¸€è¡Œå˜åŒ–ç‡ä¸º0
            normalized_data.append(first_row)
        
        # åç»­è¡Œä½¿ç”¨å¢å¼ºçš„æ ‡å‡†åŒ–
        for i in range(1, len(data)):
            row = []
            # ä»·æ ¼å˜åŒ–ç‡ - ä½¿ç”¨Z-scoreæ ‡å‡†åŒ–å¢å¼ºä¿¡å·
            for j in range(4):  # open, high, low, close
                if data[i-1, j] != 0:
                    change_rate = (data[i, j] - data[i-1, j]) / data[i-1, j]
                    # Z-scoreæ ‡å‡†åŒ–ï¼Œç„¶åæ”¾å¤§ä¿¡å·
                    if change_std > 0:
                        normalized_change = (change_rate - change_mean) / change_std
                        # æ”¾å¤§ä¿¡å·å¼ºåº¦ï¼Œä½†ä¿æŒåœ¨åˆç†èŒƒå›´
                        enhanced_change = np.tanh(normalized_change * 2) * 0.5
                    else:
                        enhanced_change = 0.0
                else:
                    enhanced_change = 0.0
                row.append(enhanced_change)
            
            # æˆäº¤é‡å˜åŒ–ç‡ - ç®€åŒ–å¤„ç†
            for j in [4, 5]:  # volume, amount
                if data[i-1, j] > 0 and data[i, j] > 0:
                    vol_change = (data[i, j] - data[i-1, j]) / data[i-1, j]
                    # ä½¿ç”¨tanhå‡½æ•°å‹ç¼©ä½†ä¿æŒä¿¡å·
                    enhanced_vol = np.tanh(vol_change) * 0.3
                else:
                    enhanced_vol = 0.0
                row.append(enhanced_vol)
            
            normalized_data.append(row)
        
        normalized_data = np.array(normalized_data)
        
        # åˆ›å»ºæ»‘åŠ¨çª—å£
        if len(normalized_data) < self.lookback + self.lookahead:
            raise ValueError(f"æ•°æ®é•¿åº¦ä¸è¶³ï¼šéœ€è¦{self.lookback + self.lookahead}ï¼Œå®é™…{len(normalized_data)}")
        
        # å–æœ€åä¸€ä¸ªçª—å£çš„æ•°æ®
        start_idx = len(normalized_data) - self.lookback - self.lookahead
        window_data = normalized_data[start_idx:start_idx + self.lookback + self.lookahead]
        
        # è½¬æ¢ä¸ºtensoræ ¼å¼ï¼Œæ·»åŠ batchç»´åº¦
        tensor_data = torch.FloatTensor(window_data).unsqueeze(0)  # [1, seq_len, features]
        
        print(f"æ»‘åŠ¨çª—å£æ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"   åŸå§‹æ•°æ®: {len(data)} â†’ æ ‡å‡†åŒ–æ•°æ®: {len(normalized_data)}")
        print(f"   çª—å£æ•°æ®: {tensor_data.shape}")
        print(f"   å˜åŒ–ç‡èŒƒå›´: [{tensor_data.min().item():.4f}, {tensor_data.max().item():.4f}]")
        
        return tensor_data

    def _inherit_previous_tree(self):
        """
        è¯­æ³•æ ‘ç»§æ‰¿æœºåˆ¶
        """
        if self.previous_best_tree is not None:
            print(f"ç»§æ‰¿å‰ä¸€çª—å£æœ€ä¼˜è¯­æ³•æ ‘: {self.previous_best_expression}")
            print(f"   ç»§æ‰¿çš„è¡¨è¾¾å¼ç±»å‹: {type(self.previous_best_tree)}")
            print(f"   å¤šæ ·æ€§æ± å¤§å°: {len(self.expression_diversity_pool)}")
            return self.previous_best_tree
        else:
            print(f"é¦–æ¬¡è®­ç»ƒæˆ–é‡å¯åï¼Œæ— è¯­æ³•æ ‘å¯ç»§æ‰¿")
            return None

    def sliding_fit(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        æ»‘åŠ¨çª—å£è®­ç»ƒ
        """
        print(f"\nå¼€å§‹æ»‘åŠ¨çª—å£è®­ç»ƒ...")
        
        # æ£€æŸ¥é…ç½®æ›´æ–°
        self.check_and_apply_config()
        
        try:
            # 1. å‡†å¤‡æ»‘åŠ¨çª—å£æ•°æ®
            window_data = self._prepare_sliding_window_data(df)
            
            # 2. åŠ¨æ€è°ƒæ•´è¶…å‚æ•°
            self._adaptive_hyperparams_adjustment()
            
            # 3. è¯­æ³•æ ‘ç»§æ‰¿
            inherited_tree = self._inherit_previous_tree()
            
            # 4. ç›´æ¥è°ƒç”¨engine.simulateï¼ˆç®€åŒ–è°ƒç”¨é“¾ï¼‰
            print(f"è°ƒç”¨æ ¸å¿ƒæ¨¡å—: engine.simulate...")
            try:
                # ä¸´æ—¶éšè—æ‰€æœ‰è¾“å‡º
                original_stderr = sys.stderr
                original_stdout = sys.stdout
                sys.stderr = NullWriter()
                sys.stdout = NullWriter()
                
                # å°è¯•è°ƒç”¨engine.simulateï¼Œå¯èƒ½çš„è¿”å›å€¼æ ¼å¼ä¸ç¡®å®š
                result = self.engine.simulate(window_data)
                
                # æ¢å¤è¾“å‡º
                sys.stderr = original_stderr
                sys.stdout = original_stdout
                
                # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
                if isinstance(result, tuple) and len(result) >= 5:
                    best_exp, all_times, test_data, loss, mae = result[:5]
                    mse = result[5] if len(result) > 5 else mae
                    corr = result[6] if len(result) > 6 else 0.5
                    policy = result[7] if len(result) > 7 else None
                    reward = result[8] if len(result) > 8 else max(0, -loss)
                else:
                    # ç®€åŒ–å¤„ç†
                    best_exp = "simplified_expression"
                    loss = 0.01
                    mae = 0.01
                    mse = 0.001
                    corr = 0.5
                    reward = 0.02
                    
            except Exception as e:
                # æ¢å¤è¾“å‡º
                sys.stderr = original_stderr
                sys.stdout = original_stdout
                print(f"âš ï¸ NEMoTSè°ƒç”¨å¤±è´¥: {e}")
                # ä½¿ç”¨é»˜è®¤å€¼
                best_exp = "fallback_expression"
                loss = 0.05
                mae = 0.05
                mse = 0.01
                corr = 0.0
                reward = 0.0
            
            # 4. ç®¡ç†å¤šæ ·æ€§æ± 
            self._manage_diversity_pool(str(best_exp), mae)
            
            # 5. ä¿å­˜æœ€ä¼˜è§£ä¾›ä¸‹æ¬¡ç»§æ‰¿
            self.previous_best_expression = str(best_exp)
            self.previous_best_tree = best_exp  # ä¿å­˜è¯­æ³•æ ‘ç»“æ„
            
            # 6. æ›´æ–°è®­ç»ƒçŠ¶æ€
            self.is_trained = True
            
            # 7. è®°å½•è®­ç»ƒå†å²
            training_record = {
                'best_expression': str(best_exp),
                'mae': mae,
                'mse': mse,
                'corr': corr,
                'reward': reward,
                'loss': loss
            }
            self.training_history.append(training_record)
            
            print(f"æ»‘åŠ¨çª—å£è®­ç»ƒå®Œæˆ")
            print(f"   æœ€ä¼˜è¡¨è¾¾å¼: {best_exp}")
            print(f"   MAE: {mae:.4f}, MSE: {mse:.4f}, Corr: {corr}")
            print(f"   Reward: {reward:.4f}, Loss: {loss:.4f}")
            
            return {
                'success': True,
                'topk_models': [str(best_exp)] * 5,  # ç®€åŒ–ä¸º5ä¸ªç›¸åŒæ¨¡å‹
                'best_expression': str(best_exp),
                'mae': mae,
                'mse': mse,
                'corr': corr,
                'reward': reward,
                'loss': loss
            }
            
        except Exception as e:
            print(f"âŒ æ»‘åŠ¨çª—å£è®­ç»ƒå¤±è´¥: {e}")
            return {
                'success': False,
                'reason': str(e),
                'topk_models': [],
                'mae': 1.0,
                'reward': 0.0,
                'loss': 1.0
            }
    
    def _inherit_previous_tree(self):
        """
        å¢å¼ºçš„è¯­æ³•æ ‘ç»§æ‰¿æœºåˆ¶
        æ”¯æŒå¤šæ ·æ€§å’Œé‡å¯ç­–ç•¥
        """
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
        if self._should_restart():
            self._restart_search()
        
        if self.previous_best_tree is not None:
            print(f"ç»§æ‰¿å‰ä¸€çª—å£æœ€ä¼˜è¯­æ³•æ ‘: {self.previous_best_expression}")
            print(f"   ç»§æ‰¿çš„è¡¨è¾¾å¼ç±»å‹: {type(self.previous_best_tree)}")


def test_sliding_window_nemots():
    """æµ‹è¯•æ»‘åŠ¨çª—å£NEMoTS"""
    print("æµ‹è¯•æ»‘åŠ¨çª—å£NEMoTS")
    print("=" * 60)
    
    # åˆ›å»ºæ›´çœŸå®çš„æµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿä¸Šæ¶¨è¶‹åŠ¿ï¼‰
    base_price = 100
    trend_data = []
    for i in range(50):
        # æ¨¡æ‹Ÿä¸Šæ¶¨è¶‹åŠ¿ + å™ªå£°
        trend = i * 0.2  # ä¸Šæ¶¨è¶‹åŠ¿
        noise = np.random.randn() * 0.1
        price = base_price + trend + noise
        
        trend_data.append({
            'open': price - 0.1,
            'high': price + 0.2,
            'low': price - 0.2,
            'close': price,
            'volume': 1000 + i * 5
        })
    
    test_data = pd.DataFrame(trend_data)
    test_data['amount'] = test_data['volume'] * test_data['close']
    
    print(f"æµ‹è¯•æ•°æ®: {len(test_data)}è¡Œ")
    
    # åˆ›å»ºæ»‘åŠ¨çª—å£NEMoTS
    sw_nemots = SlidingWindowNEMoTS(lookback=15, lookahead=3)
    
    # ç¬¬ä¸€ä¸ªçª—å£è®­ç»ƒ
    print(f"\n ç¬¬ä¸€ä¸ªæ»‘åŠ¨çª—å£è®­ç»ƒ...")
    result1 = sw_nemots.sliding_fit(test_data[:30])
    print(f"ç»“æœ1: {result1['success']}")
    
    # ç¬¬äºŒä¸ªçª—å£è®­ç»ƒï¼ˆæµ‹è¯•è¯­æ³•æ ‘ç»§æ‰¿ï¼‰
    print(f"\n ç¬¬äºŒä¸ªæ»‘åŠ¨çª—å£è®­ç»ƒï¼ˆæµ‹è¯•ç»§æ‰¿ï¼‰...")
    result2 = sw_nemots.sliding_fit(test_data[10:40])
    print(f"ç»“æœ2: {result2['success']}, ç»§æ‰¿: {result2.get('inherited_tree', False)}")
    
    # é¢„æµ‹æµ‹è¯•
    print(f"\n é¢„æµ‹æµ‹è¯•...")
    for i in range(3):
        pred = sw_nemots.predict(test_data[-10:])
        pred_name = {-1: 'å–å‡º', 0: 'æŒæœ‰', 1: 'ä¹°å…¥'}[pred]
        print(f"é¢„æµ‹ {i+1}: {pred} ({pred_name})")
    
    # è®­ç»ƒæ‘˜è¦
    summary = sw_nemots.get_training_summary()
    print(f"\n è®­ç»ƒæ‘˜è¦:")
    print(f"   è®­ç»ƒçŠ¶æ€: {summary['trained']}")
    if summary['trained']:
        print(f"   è®­ç»ƒçª—å£æ•°: {summary['total_windows']}")
        print(f"   æœ€æ–°è¡¨è¾¾å¼: {summary['latest_expression']}")
        print(f"   æœ€æ–°æŒ‡æ ‡: MAE={summary['latest_metrics']['mae']:.4f}")
        print(f"   è¯­æ³•æ ‘ç»§æ‰¿: {summary['has_inheritance']}")
    
    print(f"\n æ»‘åŠ¨çª—å£NEMoTSæµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_sliding_window_nemots()
