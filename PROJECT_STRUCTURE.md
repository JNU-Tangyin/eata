# EATA-RL Project Structure

## ğŸ“ Project Overview
Enhanced Adaptive Trading Agent with Reinforcement Learning - A sophisticated algorithmic trading system that combines neural networks, Monte Carlo Tree Search (MCTS), and evolutionary algorithms for stock market prediction and trading.

## ğŸ—ï¸ Directory Structure

```
EATA-RL/
â”œâ”€â”€ ğŸ“‚ core/                    # Core system components
â”‚   â”œâ”€â”€ agent.py               # Main trading agent implementation
â”‚   â”œâ”€â”€ env.py                 # Trading environment
â”‚   â”œâ”€â”€ data.py                # Data processing utilities
â”‚   â”œâ”€â”€ globals.py             # Global configurations
â”‚   â”œâ”€â”€ utils.py               # Utility functions
â”‚   â”œâ”€â”€ performance_metrics.py # Performance evaluation metrics
â”‚   â””â”€â”€ eata_agent/            # EATA-specific agent components
â”‚       â”œâ”€â”€ engine.py          # Training engine
â”‚       â”œâ”€â”€ model.py           # Neural network models
â”‚       â”œâ”€â”€ network.py         # PVNet implementation
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“‚ experiments/            # All experimental frameworks
â”‚   â”œâ”€â”€ ablation_study/        # Ablation study experiments
â”‚   â”‚   â”œâ”€â”€ run_ablation_study.py
â”‚   â”‚   â”œâ”€â”€ variants/          # Different model variants
â”‚   â”‚   â”œâ”€â”€ configs/           # Configuration files
â”‚   â”‚   â””â”€â”€ results/           # Experimental results
â”‚   â”œâ”€â”€ comparison_experiments/ # Algorithm comparison studies
â”‚   â””â”€â”€ comparison_results/    # Comparison results
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                   # Documentation
â”‚   â”œâ”€â”€ README.md              # Project overview
â”‚   â”œâ”€â”€ EXPERIMENT_GUIDE.md    # Experiment setup guide
â”‚   â”œâ”€â”€ FINRL_INVESTORBENCH_GUIDE.md
â”‚   â””â”€â”€ SETUP.md               # Installation guide
â”‚
â”œâ”€â”€ ğŸ“‚ data/                   # Data storage
â”œâ”€â”€ ğŸ“‚ figures/                # Generated plots and visualizations
â”œâ”€â”€ ğŸ“‚ tables/                 # Result tables
â”‚
â”œâ”€â”€ ğŸ“„ main.py                 # Main entry point
â”œâ”€â”€ ğŸ“„ predict.py              # Prediction pipeline
â”œâ”€â”€ ğŸ“„ backtest.py             # Backtesting utilities
â”œâ”€â”€ ğŸ“„ evaluate.py             # Model evaluation
â”œâ”€â”€ ğŸ“„ preprocess.py           # Data preprocessing
â”œâ”€â”€ ğŸ“„ visualize.py            # Visualization tools
â”œâ”€â”€ ğŸ“„ requirements.txt        # Dependencies
â””â”€â”€ ğŸ“„ .gitignore              # Git ignore rules
```

## ğŸ¯ Key Components

### Core System (`core/`)
- **agent.py**: Main trading agent with MCTS and neural network integration
- **eata_agent/**: Enhanced agent components with evolutionary algorithms
- **env.py**: Trading environment simulation
- **data.py**: Data loading and processing utilities

### Experiments (`experiments/`)
- **ablation_study/**: Systematic component removal studies
  - 6 variants: Full, NoNN, NoMem, Simple, NoExplore, NoMCTS
  - 20 stock dataset for comprehensive evaluation
- **comparison_experiments/**: Baseline algorithm comparisons

### Documentation (`docs/`)
- Complete setup and usage guides
- Experimental protocols and methodologies
- Performance benchmarking results

## ğŸš€ Quick Start

1. **Installation**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Run Ablation Study**:
   ```bash
   cd experiments/ablation_study
   python run_ablation_study.py
   ```

3. **Single Stock Prediction**:
   ```bash
   python main.py
   ```

## ğŸ“Š Experimental Framework

The project supports multiple experimental setups:
- **Ablation Studies**: Component-wise performance analysis
- **Baseline Comparisons**: Against traditional ML/RL methods
- **Multi-stock Validation**: 20 diverse stocks for robust evaluation
- **Performance Metrics**: Sharpe ratio, annual return, max drawdown, win rate

## ğŸ”§ Configuration

All configurations are centralized in:
- `experiments/ablation_study/configs/` for ablation studies
- Individual experiment scripts for specific setups

## ğŸ“ˆ Results

Results are automatically saved in structured formats:
- CSV files for quantitative metrics
- JSON files for detailed experiment logs
- Markdown reports for human-readable summaries
