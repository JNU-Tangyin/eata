import math
import math
import random
from collections import defaultdict

import numpy as np
import torch
import torch.nn.functional as F
import torch.optim as op
from scipy.stats import pearsonr
from torch.distributions import Categorical

from .model import Model
from .tracker import Tracker


class Engine(object):
    def __init__(self, args):
        self.args = args
        self.model = Model(args)
        self.model.p_v_net_ctx.pv_net = self.model.p_v_net_ctx.pv_net.to(self.args.device)
        self.optimizer = op.Adam(self.model.p_v_net_ctx.pv_net.parameters(), lr=self.args.lr,
                                 weight_decay=self.args.weight_decay)
        self.tracker = Tracker()
        self.global_train_step = 0

    def simulate(self, data, inherited_tree=None):
        X, y = data[:, :self.args.seq_in], data[:, -self.args.seq_out:]
        all_eqs, all_times, test_scores, test_data, policy, reward = self.model.run(X, y, inherited_tree=inherited_tree)
        print(f"ğŸ” è°ƒç”¨OptimizedMetrics.metrics:")
        print(f"   all_eqs: {all_eqs}")
        print(f"   test_scores: {test_scores}")
        print(f"   test_dataç±»å‹: {type(test_data)}")
        if hasattr(test_data, 'shape'):
            print(f"   test_dataå½¢çŠ¶: {test_data.shape}")
        else:
            print(f"   test_dataå†…å®¹: {test_data}")
        
        mae, mse, corr, best_exp = OptimizedMetrics.metrics(all_eqs, test_scores, test_data)
        
        print(f"ğŸ” OptimizedMetrics.metricsè¿”å›:")
        print(f"   mae: {mae}, mse: {mse}, corr: {corr}")
        print(f"   best_exp: {best_exp}")
        
        # ä¿å­˜æœ€è¿‘çš„è®­ç»ƒç»“æœä¾›trackerä½¿ç”¨
        self._last_reward = reward if reward is not None else 0.0
        self._last_corr = corr if corr is not None else 0.0
        self._last_best_score = max(test_scores) if test_scores and len(test_scores) > 0 else 0.0
        
        if len(self.model.data_buffer) > self.args.train_size:
            loss = self.train()
            return best_exp, all_times, test_data, loss, mae, mse, corr, policy, reward
        return best_exp, all_times, test_data, 0, mae, mse, corr, policy, reward

    def train(self):
        self.model.p_v_net_ctx.pv_net.train()
        print("start train neural networks...")
        cumulative_loss = 0
        for epoch in range(self.args.epoch):
            self.optimizer.zero_grad()
            state_batch, seq_batch, policy_batch, value_batch, length_indices = self.preprocess_data()
            value_batch = torch.Tensor(value_batch)
            print(f"[DEBUG] state_batch len: {len(state_batch)}, seq_batch len: {len(seq_batch)}")
            if len(state_batch) == 0 or len(seq_batch) == 0:
                raise ValueError("[DEBUG] state_batchæˆ–seq_batchä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®é‡‡æ ·æˆ–ç»éªŒæ± å¡«å……é€»è¾‘ï¼")
            raw_dis_out, value_out = self.model.p_v_net_ctx.policy_value_batch(seq_batch, state_batch)
            value_batch[torch.isnan(value_batch)] = 0.
            value_loss = F.mse_loss(value_out, value_batch.to(value_out.device))
            dist_loss = []
            for length, sample_id in length_indices.items():
                try:
                    # æ£€æŸ¥sample_idæ˜¯å¦ä¸ºç©º
                    if len(sample_id) == 0:
                        continue
                    
                    # æ£€æŸ¥policy_batchä¸­çš„æ•°æ®
                    valid_policies = []
                    valid_raw_outs = []
                    for i in sample_id:
                        if i < len(policy_batch) and i < len(raw_dis_out):
                            policy = policy_batch[i]
                            if policy is not None and len(policy) > 0:
                                valid_policies.append(policy)
                                valid_raw_outs.append(raw_dis_out[i])
                    
                    if len(valid_policies) == 0:
                        continue
                        
                    out_policy = F.softmax(torch.stack(valid_raw_outs)[:, :length], dim=-1)
                    gt_policy = torch.Tensor(valid_policies).to(out_policy.device)
                    
                    # ç¡®ä¿å½¢çŠ¶åŒ¹é…
                    if gt_policy.shape != out_policy.shape:
                        min_len = min(gt_policy.shape[1], out_policy.shape[1])
                        gt_policy = gt_policy[:, :min_len]
                        out_policy = out_policy[:, :min_len]
                    
                    dist_target = Categorical(probs=gt_policy)
                    dist_out = Categorical(probs=out_policy)
                    dist_loss.append(torch.distributions.kl_divergence(dist_target, dist_out).mean())
                    
                except Exception as e:
                    print(f"ç­–ç•¥åˆ†å¸ƒè®¡ç®—é”™è¯¯ (length={length}): {e}")
                    continue
            total_loss = value_loss + sum(dist_loss)
            cumulative_loss += total_loss.item()
            total_loss.backward(retain_graph=True)
            if self.args.clip is not None:
                torch.nn.utils.clip_grad_norm_(self.model.p_v_net_ctx.pv_net.parameters(), self.args.clip)
            self.optimizer.step()

            # ===== é‡‡é›†trackeræŒ‡æ ‡ =====
            # alphaã€policy_entropyã€policy_maxprobã€valueã€rewardã€corrã€best_scoreã€train_step
            # alphaç”±model.data_bufferé•¿åº¦å†³å®š
            alpha = min(1.0, len(self.model.data_buffer) / self.model.data_buffer.maxlen)
            # policyåˆ†å¸ƒç”¨ä¸€ä¸ªbatchçš„ç¬¬ä¸€ä¸ªpolicyä¸ºä»£è¡¨
            if len(policy_batch) > 0:
                policy = policy_batch[0]
            else:
                policy = None
            # valueç”¨å½“å‰batchå‡å€¼
            value = value_batch.mean().item() if len(value_batch) > 0 else None
            # rewardã€corrã€best_scoreç”¨æœ€è¿‘ä¸€æ¬¡simulateçš„ç»“æœ
            # ä»å®ä¾‹å˜é‡ä¸­è·å–æœ€è¿‘çš„è®­ç»ƒç»“æœ
            reward = getattr(self, '_last_reward', 0.0)
            corr = getattr(self, '_last_corr', 0.0) 
            best_score = getattr(self, '_last_best_score', 0.0)
            self.tracker.update(
                step=self.global_train_step,
                alpha=alpha,
                policy=policy,
                value=value,
                reward=reward,
                corr=corr,
                best_score=best_score
            )
            self.global_train_step += 1
        print("end train neural networks...")
        self.tracker.plot()
        self.tracker.save_npz()
        return cumulative_loss / self.args.epoch

    def obtain_policy_length(self, policy):
        length_indices = defaultdict(list)
        for idx, sublist in enumerate(policy):
            length_indices[len(sublist)].append(idx)
        return dict(length_indices)

    def preprocess_data(self):
        non_nan_indices = [index for index, value in enumerate(self.model.data_buffer) if not math.isnan(value[3])]
        sampled_idx = random.sample(non_nan_indices, min(len(non_nan_indices), self.args.train_size))
        mini_batch = [self.model.data_buffer[i] for i in sampled_idx]
        state_batch = [data[0] for data in mini_batch]
        seq_batch = [data[1][1] for data in mini_batch]
        policy_batch = [data[2] for data in mini_batch]
        value_batch = [data[3] for data in mini_batch]
        length_indices = self.obtain_policy_length(policy_batch)
        return state_batch, seq_batch, policy_batch, value_batch, length_indices

    def eval(self, data):
        pass


class OptimizedMetrics:
    @staticmethod
    def metrics(exps, scores, data):
        # ä¿®å¤tuple index out of rangeé”™è¯¯
        if len(scores) == 0 or len(exps) == 0:
            return 0.0, 0.0, 0.0, "x0"
        
        best_index = np.argmax(scores)
        if best_index >= len(exps):
            best_index = 0
        best_exp = exps[best_index]
        
        # å®‰å…¨åœ°è§£åŒ…data
        try:
            if isinstance(data, tuple) and len(data) >= 2:
                span, gt = data[0], data[1]
            elif isinstance(data, np.ndarray) and data.shape[0] >= 2:
                # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œç¬¬ä¸€è¡Œæ˜¯è¾“å…¥ï¼Œç¬¬äºŒè¡Œæ˜¯ç›®æ ‡
                span, gt = data[0], data[1]
                print(f"ğŸ” æ•°æ®è§£åŒ…æˆåŠŸ: span={span}, gt={gt}")
            else:
                # å¦‚æœdataæ ¼å¼ä¸å¯¹ï¼Œè¿”å›é»˜è®¤å€¼
                print(f"ğŸ” æ•°æ®æ ¼å¼ä¸æ”¯æŒ: {type(data)}, shape={getattr(data, 'shape', 'N/A')}")
                return 0.0, 0.0, 0.0, str(best_exp)
        except (ValueError, IndexError) as e:
            print(f"æ•°æ®è§£åŒ…é”™è¯¯: {e}")
            return 0.0, 0.0, 0.0, str(best_exp)

        # ç¡®ä¿spanå’Œgtæ˜¯numpyæ•°ç»„ä¸”å½¢çŠ¶åŒ¹é…
        try:
            span = np.asarray(span)
            gt = np.asarray(gt)
            
            if span.shape != gt.shape:
                min_len = min(len(span), len(gt))
                span = span[:min_len]
                gt = gt[:min_len]
        except Exception as e:
            print(f"æ•°ç»„å¤„ç†é”™è¯¯: {e}")
            return 0.0, 0.0, 0.0, str(best_exp)

        # Replacing the lambdify function with the new lambda function
        try:
            corrected_expression = str(best_exp).replace("exp", "np.exp").replace("cos", "np.cos").replace("sin",
                                                                                                      "np.sin").replace(
                "sqrt", "np.sqrt").replace("log", "np.log")
            
            print(f"ğŸ” è¯„ä¼°è¡¨è¾¾å¼: {corrected_expression}")
            print(f"   spanå½¢çŠ¶: {span.shape if hasattr(span, 'shape') else type(span)}")
            print(f"   gtå½¢çŠ¶: {gt.shape if hasattr(gt, 'shape') else type(gt)}")
            
            # è®¾ç½®å˜é‡x0, x1, x2ç­‰ä¾›è¡¨è¾¾å¼ä½¿ç”¨
            for i in range(len(span)):
                globals()[f'x{i}'] = span[i]
            
            # å¦‚æœè¡¨è¾¾å¼ä¸­åŒ…å«x0ä½†spané•¿åº¦ä¸å¤Ÿï¼Œä½¿ç”¨span[0]
            if 'x0' in corrected_expression and len(span) > 0:
                globals()['x0'] = span[0]
            
            f = lambda x: eval(corrected_expression)
            prediction = f(span)
            
            print(f"   é¢„æµ‹ç»“æœ: {prediction}")
            print(f"   çœŸå®å€¼: {gt}")
            
            # ç¡®ä¿predictionæ˜¯æ•°ç»„ä¸”å½¢çŠ¶æ­£ç¡®
            prediction = np.asarray(prediction)
            if prediction.shape != gt.shape:
                if prediction.size == 1:
                    prediction = np.full_like(gt, prediction.item())
                else:
                    min_len = min(len(prediction), len(gt))
                    prediction = prediction[:min_len]
                    gt = gt[:min_len]
                    
        except Exception as e:
            print(f"è¡¨è¾¾å¼è¯„ä¼°é”™è¯¯: {e}")
            return 0.0, 0.0, 0.0, str(best_exp)

        mae = np.mean(np.abs(prediction - gt))
        mse = np.mean((prediction - gt) ** 2)
        corr = 0.0  # å¢åŠ é»˜è®¤å€¼ï¼Œé˜²æ­¢å¼‚å¸¸åˆ†æ”¯ä¸‹æœªèµ‹å€¼
        
        try:
            # ç¡®ä¿predictionå’Œgtéƒ½æ˜¯1ç»´æ•°ç»„ä¸”é•¿åº¦ç›¸åŒ
            pred_flat = prediction.flatten()
            gt_flat = gt.flatten()
            
            if len(pred_flat) != len(gt_flat):
                min_len = min(len(pred_flat), len(gt_flat))
                pred_flat = pred_flat[:min_len]
                gt_flat = gt_flat[:min_len]
            
            if len(pred_flat) > 1:  # pearsonréœ€è¦è‡³å°‘2ä¸ªæ•°æ®ç‚¹
                corr, _ = pearsonr(pred_flat, gt_flat)
            else:
                corr = 0.0
                
        except (ValueError, IndexError) as e:
            print(f"ç›¸å…³æ€§è®¡ç®—é”™è¯¯: {e}")
            if (np.isnan(prediction) | np.isinf(prediction)).any():
                corr = 0.
            elif (np.isnan(gt) | np.isinf(gt)).any():
                try:
                    valid_indices = np.where(~np.isnan(gt) & ~np.isinf(gt))[0]
                    if len(valid_indices) > 1:
                        valid_gt = gt[valid_indices]
                        valid_pred = prediction[valid_indices]
                        corr, _ = pearsonr(valid_pred, valid_gt)
                    else:
                        corr = 0.0
                except:
                    corr = 0.0
        except TypeError:
            if type(prediction) is float:
                corr = 0.

        return mae, mse, corr, best_exp

# Example usage (assuming exps, scores, and data are defined)
# metrics = OptimizedMetrics.metrics(exps, scores, data)
