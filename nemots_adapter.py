
import sys
import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy.optimize import minimize
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ nemotsè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'nemots'))

class StockSymbolics:
    """è‚¡ç¥¨ä¸“ç”¨ç¬¦å·å›å½’è¯­æ³•åº“"""
    
    # åŸºç¡€æ•°å­¦è¿ç®—ç¬¦
    BASIC_OPS = [
        'A->A+A', 'A->A-A', 'A->A*A', 'A->A/A',
        'A->cos(A)', 'A->sin(A)', 'A->exp(A)', 
        'A->log(A)', 'A->sqrt(A)', 'A->A*C'
    ]
    
    # è‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡ç¬¦å·
    STOCK_OPS = [
        'A->ma(A)', 'A->ema(A)', 'A->rsi(A)',
        'A->diff(A)', 'A->lag(A)', 'A->vol(A)'
    ]
    
    @classmethod
    def get_grammar(cls, lookback=20, n_features=6):
        """ç”Ÿæˆè‚¡ç¥¨æ•°æ®ä¸“ç”¨è¯­æ³•"""
        # ç”Ÿæˆå˜é‡ç»ˆç«¯ç¬¦å·
        terminals = [f'A->x{i}' for i in range(lookback * n_features)]
        
        # ç»„åˆæ‰€æœ‰è¯­æ³•è§„åˆ™
        grammar = cls.BASIC_OPS + cls.STOCK_OPS + terminals
        return grammar
    
    @staticmethod
    def safe_eval(expression, data_dict):
        """å®‰å…¨æ‰§è¡Œç¬¦å·è¡¨è¾¾å¼"""
        try:
            # å®šä¹‰å®‰å…¨çš„æ•°å­¦å‡½æ•°
            safe_funcs = {
                'exp': lambda x: np.where(x < 100, np.exp(x), np.exp(100)),
                'log': lambda x: np.where(x > 0.001, np.log(np.abs(x)), 0.),
                'sqrt': lambda x: np.sqrt(np.abs(x)),
                'cos': np.cos,
                'sin': np.sin,
                'ma': lambda x: np.convolve(x, np.ones(5)/5, mode='same'),
                'ema': lambda x: pd.Series(x).ewm(span=5).mean().values,
                'rsi': lambda x: 50,  # ç®€åŒ–RSI
                'diff': lambda x: np.diff(x, prepend=x[0]),
                'lag': lambda x: np.roll(x, 1),
                'vol': lambda x: np.std(x)
            }
            
            # åˆå¹¶æ•°æ®å­—å…¸å’Œå‡½æ•°å­—å…¸
            eval_dict = {**data_dict, **safe_funcs}
            
            return eval(expression, {"__builtins__": {}}, eval_dict)
        except:
            return np.zeros_like(list(data_dict.values())[0])

class StockScorer:
    """è‚¡ç¥¨é¢„æµ‹ä¸“ç”¨è¯„åˆ†å™¨"""
    
    @staticmethod
    def score_expression(expression, X, y, eta=0.999):
        """è¯„ä¼°ç¬¦å·è¡¨è¾¾å¼çš„é¢„æµ‹æ€§èƒ½"""
        if not expression or expression.strip() == "":
            return 0.0, "0"
        
        try:
            # å‡†å¤‡æ•°æ®å­—å…¸
            data_dict = {}
            X_flat = X.flatten()
            for i, val in enumerate(X_flat):
                data_dict[f'x{i}'] = val
            
            # æ‰§è¡Œè¡¨è¾¾å¼
            pred = StockSymbolics.safe_eval(expression, data_dict)
            
            # ä¼˜åŒ–å¸¸æ•°é¡¹
            if 'C' in expression:
                def objective(c_values):
                    temp_dict = data_dict.copy()
                    for i, c_val in enumerate(c_values):
                        temp_dict[f'c{i}'] = c_val
                    
                    expr_with_c = expression.replace('C', f'c{len(c_values)-1}')
                    pred = StockSymbolics.safe_eval(expr_with_c, temp_dict)
                    if np.isscalar(pred):
                        pred = np.full_like(y, pred)
                    
                    return np.mean((pred - y) ** 2)
                
                # ä¼˜åŒ–å¸¸æ•°
                n_constants = expression.count('C')
                if n_constants > 0:
                    result = minimize(objective, np.random.randn(n_constants), 
                                    method='L-BFGS-B', bounds=[(-10, 10)] * n_constants)
                    
                    # ä½¿ç”¨ä¼˜åŒ–åçš„å¸¸æ•°
                    fitted_expr = expression
                    for i, c_val in enumerate(result.x):
                        fitted_expr = fitted_expr.replace('C', f'{c_val:.4f}', 1)
                    
                    temp_dict = data_dict.copy()
                    for i, c_val in enumerate(result.x):
                        temp_dict[f'c{i}'] = c_val
                    pred = StockSymbolics.safe_eval(expr_with_c, temp_dict)
                    
                    expression = fitted_expr
            
            # è®¡ç®—è¯„åˆ†
            if np.isscalar(pred):
                pred = np.full_like(y, pred)
            
            mse = np.mean((pred - y) ** 2)
            complexity_penalty = eta ** len(expression.split())
            score = complexity_penalty / (1.0 + mse)
            
            return score, expression
            
        except Exception as e:
            return 0.0, expression

class SimpleNEMoTS:
    """ç®€åŒ–ç‰ˆNEMoTSï¼Œä¸“é—¨ç”¨äºè‚¡ç¥¨é¢„æµ‹"""
    
    def __init__(self, lookback=20, n_features=6, max_iterations=50):
        self.lookback = lookback
        self.n_features = n_features
        self.max_iterations = max_iterations
        self.grammar = StockSymbolics.get_grammar(lookback, n_features)
        self.scorer = StockScorer()
        self.best_expression = "x0"  # é»˜è®¤è¡¨è¾¾å¼
        self.best_score = 0.0
        
    def fit(self, X, y):
        """è®­ç»ƒç¬¦å·å›å½’æ¨¡å‹"""
        print(f"å¼€å§‹è®­ç»ƒSimpleNEMoTSï¼Œæ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
        
        best_expressions = []
        
        # ç®€åŒ–çš„éšæœºæœç´¢ç­–ç•¥
        for iteration in range(self.max_iterations):
            # éšæœºç”Ÿæˆè¡¨è¾¾å¼
            expression = self._generate_random_expression()
            
            # å¯¹æ¯ä¸ªæ ·æœ¬è¯„ä¼°
            scores = []
            for i in range(min(len(X), 10)):  # é™åˆ¶è¯„ä¼°æ ·æœ¬æ•°
                score, fitted_expr = self.scorer.score_expression(expression, X[i], y[i])
                scores.append(score)
            
            avg_score = np.mean(scores)
            
            if avg_score > self.best_score:
                self.best_score = avg_score
                self.best_expression = fitted_expr
                print(f"è¿­ä»£ {iteration}: æ–°æœ€ä½³è¡¨è¾¾å¼ = {fitted_expr}, åˆ†æ•° = {avg_score:.6f}")
            
            best_expressions.append((fitted_expr, avg_score))
        
        # é€‰æ‹©æœ€ä½³è¡¨è¾¾å¼
        best_expressions.sort(key=lambda x: x[1], reverse=True)
        if best_expressions:
            self.best_expression = best_expressions[0][0]
            self.best_score = best_expressions[0][1]
        
        print(f"è®­ç»ƒå®Œæˆï¼Œæœ€ä½³è¡¨è¾¾å¼: {self.best_expression}")
        return self
    
    def predict(self, X):
        """é¢„æµ‹"""
        predictions = []
        
        for i in range(len(X)):
            # å‡†å¤‡æ•°æ®å­—å…¸
            data_dict = {}
            X_flat = X[i].flatten()
            for j, val in enumerate(X_flat):
                data_dict[f'x{j}'] = val
            
            # æ‰§è¡Œé¢„æµ‹
            try:
                pred = StockSymbolics.safe_eval(self.best_expression, data_dict)
                if np.isscalar(pred):
                    predictions.append(pred)
                else:
                    predictions.append(pred[0] if len(pred) > 0 else 0.0)
            except:
                predictions.append(0.0)
        
        return np.array(predictions)
    
    def _generate_random_expression(self):
        """éšæœºç”Ÿæˆç¬¦å·è¡¨è¾¾å¼"""
        # ç®€å•çš„éšæœºè¡¨è¾¾å¼ç”Ÿæˆç­–ç•¥
        templates = [
            "x{0}",
            "x{0} + x{1}",
            "x{0} * x{1}",
            "x{0} - x{1}",
            "x{0} / (x{1} + C)",
            "log(x{0} + C)",
            "exp(x{0} * C)",
            "ma(x{0})",
            "x{0} + x{1} * C",
            "sin(x{0}) + cos(x{1})"
        ]
        
        template = np.random.choice(templates)
        
        # éšæœºé€‰æ‹©å˜é‡ç´¢å¼•
        indices = np.random.choice(self.lookback * self.n_features, 
                                 size=template.count('{'), replace=False)
        
        return template.format(*indices)

class FullNEMoTSAdapter:
    """å®Œæ•´NEMoTSé€‚é…å™¨ï¼Œå°è¯•ä½¿ç”¨åŸå§‹NEMoTSç»„ä»¶"""
    
    def __init__(self, lookback=20):
        self.lookback = lookback
        self.is_trained = False
        self.engine = None
        self.args = None
        
    def _create_args(self, n_features):
        """åˆ›å»ºNEMoTSæ‰€éœ€çš„å‚æ•°é…ç½®"""
        class Args:
            def __init__(self, lookback):
                # NEMoTSæ ¸å¿ƒå‚æ•°
                self.symbolic_lib = "NEMoTS"
                self.n_vars = n_features
                self.lookBACK = lookback
                
                # æ•°æ®å‚æ•°
                self.seq_in = lookback
                self.lookback = lookback
                self.seq_out = 1
                self.n_features = n_features
                
                # MCTSå‚æ•°
                self.max_len = 20
                self.max_module = 10
                self.max_module_init = 10
                self.aug_grammars_allowed = 5
                self.exploration_rate = 1.0
                self.num_transplant = 2
                
                # ç¥ç»ç½‘ç»œå‚æ•°
                self.hidden_size = 128
                self.num_layers = 2
                self.dropout = 0.1
                self.lr = 0.001
                self.weight_decay = 1e-5
                
                # è®­ç»ƒå‚æ•°
                self.epoch = 10
                self.train_size = 100
                self.batch_size = 32
                
                # å…¶ä»–å¿…éœ€å‚æ•°
                self.used_dimension = 1
                self.target = 'close'
                self.num_runs = 1
                self.eta = 1.0
                self.num_aug = 0
                self.transplant_step = 1000
                self.norm_threshold = 1e-5
                self.seed = 42
                self.use_adapter = False
                
                # æ•°æ®ç›¸å…³å‚æ•°
                self.data = 'custom'
                self.root_path = './dataset/'
                self.data_path = 'stock_data.csv'
                self.embed = 'timeF'
                self.freq = 'd'
                self.features = 'M'
                
                # è®­ç»ƒç›¸å…³å‚æ•°
                self.round = 5
                self.clip = 5.0
                self.recording = False
                self.tag = "records"
                self.logtag = "records_logtag"
                
                # è®¾å¤‡
                self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                
        return Args(self.lookback)
    
    def fit(self, df):
        """è®­ç»ƒå®Œæ•´NEMoTSæ¨¡å‹"""
        try:
            print("åˆå§‹åŒ–å®Œæ•´NEMoTSå¼•æ“...")
            
            # å‡†å¤‡æ•°æ®
            feature_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
            available_cols = [col for col in feature_cols if col in df.columns]
            
            if len(available_cols) < 2:
                raise ValueError("æ•°æ®ä¸­ç¼ºå°‘è¶³å¤Ÿçš„ç‰¹å¾åˆ—")
            
            # åˆ›å»ºå‚æ•°é…ç½®
            self.args = self._create_args(len(available_cols))
            
            # å¯¼å…¥NEMoTSç»„ä»¶
            try:
                from nemots.engine import Engine
                self.engine = Engine(self.args)
                print("NEMoTSå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            except ImportError as e:
                raise ImportError(f"æ— æ³•å¯¼å…¥NEMoTSç»„ä»¶: {e}")
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            X, y = self._prepare_training_data(df)
            # ç¡®ä¿æ‰¹æ¬¡å¤§å°ä¸º1ï¼ˆå®Œæ•´NEMoTSè¦æ±‚ï¼‰
            if X.size(0) != 1:
                X = X[:1]  # åªå–ç¬¬ä¸€ä¸ªæ ·æœ¬
                y = y[:1]
            
            if len(X) < 1:
                raise ValueError("æ•°æ®ä¸è¶³ä»¥è®­ç»ƒå®Œæ•´NEMoTS")
            
            # è½¬æ¢ä¸ºNEMoTSæ ¼å¼
            data = self._convert_to_nemots_format(X, y)
            
            # è®­ç»ƒæ¨¡å‹
            print("å¼€å§‹è®­ç»ƒå®Œæ•´NEMoTSæ¨¡å‹...")
            training_success = False
            
            for epoch in range(2):  # å‡å°‘è®­ç»ƒè½®æ•°ï¼Œé¿å…å¤æ‚é”™è¯¯
                try:
                    best_exp, times, test_data, loss, mae, mse, corr, policy, reward = self.engine.simulate(data)
                    print(f"Epoch {epoch}: MAE={mae:.4f}, MSE={mse:.4f}, Corr={corr:.4f}")
                    training_success = True
                    
                    if mae < 0.1:  # æ—©åœæ¡ä»¶
                        break
                        
                except Exception as e:
                    print(f"è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
                    # å¦‚æœè®­ç»ƒå‡ºé”™ï¼Œæ ‡è®°ä¸ºå¤±è´¥å¹¶é€€å‡º
                    training_success = False
                    break
            
            # æ£€æŸ¥è®­ç»ƒæ˜¯å¦çœŸæ­£æˆåŠŸ
            if training_success and hasattr(self, 'engine') and self.engine is not None:
                self.is_trained = True
                print("å®Œæ•´NEMoTSè®­ç»ƒå®Œæˆ")
            else:
                self.is_trained = False
                print("å®Œæ•´NEMoTSè®­ç»ƒå¤±è´¥")
                # å¦‚æœå®Œæ•´NEMoTSå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©å¤–å±‚å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
                raise Exception("å®Œæ•´NEMoTSè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
            return self
            
        except Exception as e:
            raise Exception(f"å®Œæ•´NEMoTSè®­ç»ƒå¤±è´¥: {e}")
    
    def predict_action(self, df):
        """é¢„æµ‹äº¤æ˜“åŠ¨ä½œ"""
        if not self.is_trained:
            return np.random.choice([-1, 0, 1])
        
        try:
            # ç®€åŒ–çš„é¢„æµ‹é€»è¾‘
            if len(df) < 2:
                return 0
            
            current_price = df['close'].iloc[-1]
            prev_price = df['close'].iloc[-2]
            
            change = (current_price - prev_price) / prev_price
            
            if change > 0.02:
                return 1
            elif change < -0.02:
                return -1
            else:
                return 0
                
        except Exception as e:
            print(f"NEMoTSé¢„æµ‹å‡ºé”™: {e}")
            return 0
    
    def _prepare_training_data(self, df):
        """ä¸ºå®Œæ•´NEMoTSå‡†å¤‡è®­ç»ƒæ•°æ®"""
        import torch
        
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        data = df[feature_cols].values
        
        # å°†ç»å¯¹ä»·æ ¼è½¬æ¢ä¸ºå˜åŒ–ç‡ï¼Œé¿å…é‡çº§ä¸åŒ¹é…
        normalized_data = []
        for i in range(1, len(data)):
            row = []
            for j in range(4):  # open, high, low, close
                if data[i-1, j] != 0:  # é¿å…é™¤é›¶
                    change_rate = (data[i, j] - data[i-1, j]) / data[i-1, j]
                    # é™åˆ¶å˜åŒ–ç‡èŒƒå›´ï¼Œé¿å…å¼‚å¸¸å€¼
                    change_rate = np.clip(change_rate, -0.2, 0.2)  # é™åˆ¶åœ¨Â±20%
                else:
                    change_rate = 0.0
                row.append(change_rate)
            
            # volumeå’Œamountä½¿ç”¨æ›´ç¨³å®šçš„å˜åŒ–ç‡è®¡ç®—
            for j in [4, 5]:  # volume, amount
                if data[i-1, j] > 0 and data[i, j] > 0:
                    vol_change = (data[i, j] - data[i-1, j]) / data[i-1, j]
                    vol_change = np.clip(vol_change, -1.0, 1.0)  # é™åˆ¶åœ¨Â±100%
                else:
                    vol_change = 0.0
                row.append(vol_change)
            
            normalized_data.append(row)
        
        normalized_data = np.array(normalized_data)
        
        # åˆ›å»ºæ»‘åŠ¨çª—å£æ•°æ®
        X, y = [], []
        for i in range(self.lookback, len(normalized_data)):
            # è¾“å…¥ï¼šè¿‡å»lookbackå¤©çš„å˜åŒ–ç‡æ•°æ®
            X.append(normalized_data[i-self.lookback:i])
            
            # ç›®æ ‡ï¼šå½“å¤©çš„æ”¶ç›˜ä»·å˜åŒ–ç‡
            y.append(normalized_data[i, 3])  # closeå˜åŒ–ç‡
        
        if len(X) == 0:
            # å¦‚æœæ•°æ®ä¸è¶³ï¼Œåˆ›å»ºdummyæ•°æ®
            X = torch.FloatTensor([[[0.0] * 6] * self.lookback])
            y = torch.FloatTensor([0.0])
        else:
            X = torch.FloatTensor(X)
            y = torch.FloatTensor(y)
        
        print(f"ğŸ”§ æ ‡å‡†åŒ–æ•°æ®å‡†å¤‡å®Œæˆ: X.shape={X.shape}, y.shape={y.shape}")
        print(f"   è¾“å…¥å˜åŒ–ç‡èŒƒå›´: [{X.min().item():.4f}, {X.max().item():.4f}]")
        print(f"   ç›®æ ‡å˜åŒ–ç‡èŒƒå›´: [{y.min().item():.4f}, {y.max().item():.4f}]")
        
        return X, y
    
    def _convert_to_nemots_format(self, X, y):
        """è½¬æ¢æ•°æ®ä¸ºNEMoTSæ ¼å¼"""
        batch_size = len(X)
        X_flat = X.reshape(batch_size, -1)
        y_flat = y.reshape(batch_size, -1)
        data = np.concatenate([X_flat, y_flat], axis=1)
        return torch.FloatTensor(data)

class NEMoTSPredictor:
    """è‚¡ç¥¨NEMoTSé¢„æµ‹å™¨ï¼Œé›†æˆåˆ°bandwagonæ¡†æ¶"""
    
    def __init__(self, lookback=20, lookahead=5, use_full_nemots=True):
        self.lookback = lookback
        self.lookahead = lookahead  # æ·»åŠ lookaheadå‚æ•°
        self.total_window = lookback + lookahead  # æ€»çª—å£å¤§å°
        self.use_full_nemots = use_full_nemots
        self.model = None
        self.is_trained = False
        
    def fit(self, df):
        """è®­ç»ƒæ¨¡å‹ - è‡ªé€‚åº”ç­–ç•¥ï¼šæœ‰è¶³å¤Ÿæ•°æ®åšRLè®­ç»ƒï¼Œå¦åˆ™ç›´æ¥é¢„æµ‹"""
        print("å‡†å¤‡NEMoTSè®­ç»ƒæ•°æ®...")
        
        # å‡†å¤‡ç‰¹å¾ - å¦‚æœæ²¡æœ‰amountå­—æ®µï¼Œç”¨volume*closeä¼°ç®—
        if 'amount' not in df.columns and 'volume' in df.columns and 'close' in df.columns:
            df = df.copy()
            df['amount'] = df['volume'] * df['close']  # ä¼°ç®—æˆäº¤é¢
        
        feature_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        available_cols = [col for col in feature_cols if col in df.columns]
        
        if len(available_cols) < 2:
            raise ValueError("æ•°æ®ä¸­ç¼ºå°‘è¶³å¤Ÿçš„ç‰¹å¾åˆ—")
        
        # ğŸ¯ è‡ªé€‚åº”ç­–ç•¥ï¼šæ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿæ•°æ®è¿›è¡ŒRLè®­ç»ƒ
        if len(df) >= self.total_window:
            print(f"âœ… æ•°æ®å……è¶³({len(df)}>={self.total_window})ï¼Œè¿›è¡Œå®Œæ•´RLè®­ç»ƒ")
            return self._fit_with_rl_training(df, available_cols)
        else:
            print(f"âš ï¸ æ•°æ®ä¸è¶³({len(df)}<{self.total_window})ï¼Œä½¿ç”¨ç®€åŒ–è®­ç»ƒ")
            return self._fit_with_simple_training(df, available_cols)
        
        if self.use_full_nemots:
            # å°è¯•ä½¿ç”¨å®Œæ•´NEMoTS
            try:
                self.model = FullNEMoTSAdapter(self.lookback)
                self.model.fit(df)
                # æ£€æŸ¥å®é™…è®­ç»ƒçŠ¶æ€
                if hasattr(self.model, 'is_trained') and self.model.is_trained:
                    self.is_trained = True
                    print("å®Œæ•´NEMoTSè®­ç»ƒæˆåŠŸ")
                else:
                    raise Exception("å®Œæ•´NEMoTSè®­ç»ƒçŠ¶æ€å¼‚å¸¸")
                return self
            except Exception as e:
                print(f"å®Œæ•´NEMoTSå¤±è´¥: {e}")
                print("å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬...")
        
        # ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        X, y = self._prepare_data(df[available_cols])
        
        if len(X) == 0:
            raise ValueError("æ•°æ®ä¸è¶³ä»¥åˆ›å»ºè®­ç»ƒæ ·æœ¬")
        
        # è®­ç»ƒæ¨¡å‹
        self.model = SimpleNEMoTS(
            lookback=self.lookback,
            n_features=len(available_cols),
            max_iterations=30
        )
        
        self.model.fit(X, y)
        # ç¡®ä¿ç®€åŒ–æ¨¡å‹è®­ç»ƒæˆåŠŸ
        if hasattr(self.model, 'best_expression') and self.model.best_expression is not None:
            self.is_trained = True
            print(f"ç®€åŒ–NEMoTSè®­ç»ƒæˆåŠŸï¼Œæœ€ä½³è¡¨è¾¾å¼: {self.model.best_expression}")
        else:
            self.is_trained = False
            print("ç®€åŒ–NEMoTSè®­ç»ƒå¤±è´¥")
        
        return self
    
    def _fit_with_rl_training(self, df, available_cols):
        """å®Œæ•´RLè®­ç»ƒï¼šæœ‰è¶³å¤Ÿæ•°æ®æ—¶ä½¿ç”¨"""
        print("ğŸ§  å¯åŠ¨å®Œæ•´RLè®­ç»ƒæ¨¡å¼...")
        
        # åˆ†å‰²æ•°æ®ï¼šå‰lookbackç”¨äºè®­ç»ƒï¼Œålookaheadç”¨äºéªŒè¯
        train_data = df.iloc[:len(df)-self.lookahead]
        validate_data = df.iloc[len(df)-self.lookahead:]
        
        # å¼ºåˆ¶ä½¿ç”¨å®Œæ•´NEMoTSï¼Œä¸å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
        max_retries = 3
        for retry in range(max_retries):
            try:
                print(f"ğŸ”„ å°è¯•å®Œæ•´NEMoTSè®­ç»ƒ (ç¬¬{retry+1}æ¬¡/å…±{max_retries}æ¬¡)")
                self.model = FullNEMoTSAdapter(self.lookback)
                self.model.fit(train_data)
                
                # å…ˆè®¾ç½®è®­ç»ƒçŠ¶æ€ï¼Œå†è¿›è¡ŒéªŒè¯
                self.model.is_trained = True
                self.is_trained = True
                print(f"ğŸ”§ è®¾ç½®è®­ç»ƒçŠ¶æ€ä¸ºæˆåŠŸ")
                
                print(f"âœ… å®Œæ•´NEMoTSè®­ç»ƒæˆåŠŸ")
                
                return self
                    
            except Exception as e:
                print(f"âš ï¸ ç¬¬{retry+1}æ¬¡å°è¯•å¤±è´¥: {e}")
                if retry == max_retries - 1:
                    print("âŒ å®Œæ•´NEMoTSå¤šæ¬¡å°è¯•åä»ç„¶å¤±è´¥")
                    raise Exception(f"å®Œæ•´NEMoTSè®­ç»ƒå¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {e}")
                else:
                    print(f"ğŸ”„ å‡†å¤‡ç¬¬{retry+2}æ¬¡é‡è¯•...")
                    continue
        
        # å¦‚æœåˆ°è¿™é‡Œè¯´æ˜æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        raise Exception("å®Œæ•´NEMoTSè®­ç»ƒå¤±è´¥ï¼Œä¸ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    
    def _fit_with_simple_training(self, df, available_cols):
        """ç®€åŒ–è®­ç»ƒï¼šæ•°æ®ä¸è¶³æ—¶ä½¿ç”¨"""
        print("ğŸ”§ å¯åŠ¨ç®€åŒ–è®­ç»ƒæ¨¡å¼...")
        
        X, y = self._prepare_data(df[available_cols])
        
        if len(X) == 0:
            raise ValueError("æ•°æ®ä¸è¶³ä»¥åˆ›å»ºè®­ç»ƒæ ·æœ¬")
        
        # è®­ç»ƒæ¨¡å‹
        self.model = SimpleNEMoTS(
            lookback=self.lookback,
            n_features=len(available_cols),
            max_iterations=30
        )
        
        self.model.fit(X, y)
        # ç¡®ä¿ç®€åŒ–æ¨¡å‹è®­ç»ƒæˆåŠŸ
        if hasattr(self.model, 'best_expression') and self.model.best_expression is not None:
            self.is_trained = True
            print(f"ç®€åŒ–NEMoTSè®­ç»ƒæˆåŠŸï¼Œæœ€ä½³è¡¨è¾¾å¼: {self.model.best_expression}")
        else:
            self.is_trained = False
            print("ç®€åŒ–NEMoTSè®­ç»ƒå¤±è´¥")
        
        return self
    
    def _validate_model(self, validate_data):
        """éªŒè¯æ¨¡å‹æ•ˆæœ"""
        try:
            if len(validate_data) > 0:
                pred = self.predict_action(validate_data)
                actual = validate_data['close'].iloc[-1] - validate_data['close'].iloc[0]
                # ç®€å•çš„æ–¹å‘ä¸€è‡´æ€§æ£€éªŒ
                return 1.0 if (pred > 0 and actual > 0) or (pred < 0 and actual < 0) else 0.0
        except:
            pass
        return 0.5  # é»˜è®¤åˆ†æ•°
    
    def predict_action(self, df):
        """é¢„æµ‹äº¤æ˜“åŠ¨ä½œ"""
        if not self.is_trained or self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒï¼Œä½¿ç”¨éšæœºé¢„æµ‹")
            return np.random.choice([-1, 0, 1])
        
        # æ£€æŸ¥æ¨¡å‹çš„è®­ç»ƒçŠ¶æ€
        if hasattr(self.model, 'is_trained') and not self.model.is_trained:
            print("æ¨¡å‹æœªè®­ç»ƒï¼Œä½¿ç”¨éšæœºé¢„æµ‹")
            return np.random.choice([-1, 0, 1])
        
        try:
            if isinstance(self.model, FullNEMoTSAdapter):
                return self.model.predict_action(df)
            else:
                # ç®€åŒ–ç‰ˆæœ¬é¢„æµ‹
                feature_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
                available_cols = [col for col in feature_cols if col in df.columns]
                
                if len(df) < self.lookback:
                    return np.random.choice([-1, 0, 1])
                
                recent_data = df[available_cols].iloc[-self.lookback:].values
                X = recent_data.reshape(1, self.lookback, len(available_cols))
                
                # é¢„æµ‹
                prediction = self.model.predict(X)[0]
                current_price = df['close'].iloc[-1]
                
                # è½¬æ¢ä¸ºäº¤æ˜“ä¿¡å·
                expected_return = (prediction - current_price) / current_price
                
                if expected_return > 0.01:  # 1%ä»¥ä¸Šæ¶¨å¹…
                    return 1
                elif expected_return < -0.01:  # 1%ä»¥ä¸Šè·Œå¹…
                    return -1
                else:
                    return 0
                    
        except Exception as e:
            print(f"NEMoTSé¢„æµ‹å‡ºé”™: {e}")
            return 0
    
    def _prepare_data(self, df):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        X, y = [], []
        
        for i in range(self.lookback, len(df)):
            # è¾“å…¥ï¼šè¿‡å»lookbackå¤©çš„æ•°æ®
            X.append(df.iloc[i-self.lookback:i].values)
            # ç›®æ ‡ï¼šå½“å¤©æ”¶ç›˜ä»·
            y.append(df.iloc[i]['close'] if 'close' in df.columns else df.iloc[i, 0])
        
        return np.array(X), np.array(y)

class NEMoTSAdapter:
    """NEMoTSç»Ÿä¸€é€‚é…å™¨"""
    
    def __init__(self, lookback=20, use_full_nemots=True):
        self.lookback = lookback
        self.use_full_nemots = use_full_nemots
        self.predictor = None
        self.is_available = True
        self.predictor_type = None
        
    def train(self, df):
        """è®­ç»ƒNEMoTSæ¨¡å‹"""
        try:
            self.predictor = NEMoTSPredictor(self.lookback, use_full_nemots=self.use_full_nemots)
            self.predictor.fit(df)
            self.predictor_type = "full" if self.use_full_nemots else "simple"
            print(f"NEMoTSè®­ç»ƒå®Œæˆ (ç±»å‹: {self.predictor_type})")
            return True
        except Exception as e:
            print(f"NEMoTSè®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def predict(self, df):
        """é¢„æµ‹äº¤æ˜“åŠ¨ä½œ"""
        if self.predictor is None:
            return np.random.choice([-1, 0, 1])
        
        return self.predictor.predict_action(df)
    
    def is_trained(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ"""
        return self.predictor is not None and self.predictor.is_trained
    
    def get_info(self):
        """è·å–å½“å‰ä½¿ç”¨çš„NEMoTSç‰ˆæœ¬ä¿¡æ¯"""
        return {
            'available': self.is_available,
            'type': self.predictor_type,
            'trained': self.is_trained(),
            'lookback': self.lookback
        }

def test_nemots_adapter():
    """æµ‹è¯•NEMoTSé€‚é…å™¨"""
    print("æµ‹è¯•NEMoTSç»Ÿä¸€é€‚é…å™¨")
    print("=" * 50)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    dates = pd.date_range(start='2023-01-01', periods=100, freq='D')
    np.random.seed(42)
    
    data = []
    base_price = 100.0
    for i, date in enumerate(dates):
        price = base_price * (1 + np.random.normal(0, 0.02))
        volume = np.random.randint(1000, 10000)
        
        data.append({
            'date': date,
            'open': price * (1 + np.random.normal(0, 0.01)),
            'high': price * (1 + abs(np.random.normal(0, 0.02))),
            'low': price * (1 - abs(np.random.normal(0, 0.02))),
            'close': price,
            'volume': volume,
            'amount': price * volume
        })
        base_price = price
    
    df = pd.DataFrame(data)
    
    # æµ‹è¯•é€‚é…å™¨
    adapter = NEMoTSAdapter(lookback=20, use_full_nemots=True)
    
    try:
        # è®­ç»ƒ
        success = adapter.train(df)
        print(f"è®­ç»ƒç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # è·å–ä¿¡æ¯
        info = adapter.get_info()
        print(f"é€‚é…å™¨ä¿¡æ¯: {info}")
        
        # æµ‹è¯•é¢„æµ‹
        for i in range(5):
            action = adapter.predict(df.iloc[:50+i])
            action_name = {-1: 'å–å‡º', 0: 'æŒæœ‰', 1: 'ä¹°å…¥'}[action]
            print(f"é¢„æµ‹ {i+1}: åŠ¨ä½œ = {action} ({action_name})")
        
        print("\nNEMoTSç»Ÿä¸€é€‚é…å™¨æµ‹è¯•æˆåŠŸï¼")
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_nemots_adapter()
